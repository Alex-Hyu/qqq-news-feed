import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import requests
import datetime
from datetime import timedelta
import pytz
import feedparser
from io import StringIO
from transformers import pipeline
from streamlit_autorefresh import st_autorefresh
from scipy.stats import norm
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# --- 0. å…¨å±€é…ç½® ---
st.set_page_config(page_title="QQQ å®è§‚æˆ˜æƒ…å®¤ Pro Max", layout="wide", page_icon="ğŸ¦…")

st.markdown("""
    <style>
    .metric-card {background-color: #f9f9f9; border-radius: 5px; padding: 10px; border: 1px solid #e0e0e0;}
    .news-card {padding: 10px; margin-bottom: 5px; border-radius: 5px; border-left: 5px solid #ccc;}
    .news-bull {background-color: #e6fffa; border-left-color: #00c04b;}
    .news-bear {background-color: #fff5f5; border-left-color: #ff4b4b;}
    .news-neutral {background-color: #f8f9fa; border-left-color: #6c757d;}
    .summary-box {padding: 15px; border-radius: 10px; margin-bottom: 20px;}
    .summary-bull {background-color: #d4edda; color: #155724; border: 1px solid #c3e6cb;}
    .summary-bear {background-color: #f8d7da; color: #721c24; border: 1px solid #f5c6cb;}
    .summary-neutral {background-color: #e2e3e5; color: #383d41; border: 1px solid #d6d8db;}
    .calendar-urgent {background-color: #fff3cd; border-left: 4px solid #ffc107; padding: 8px; margin: 4px 0; border-radius: 4px;}
    .calendar-soon {background-color: #e7f3ff; border-left: 4px solid #0d6efd; padding: 8px; margin: 4px 0; border-radius: 4px;}
    .calendar-normal {background-color: #f8f9fa; border-left: 4px solid #6c757d; padding: 8px; margin: 4px 0; border-radius: 4px;}
    .importance-5 {color: #dc3545; font-weight: bold;}
    .importance-4 {color: #fd7e14; font-weight: bold;}
    .importance-3 {color: #0d6efd;}
    .importance-2 {color: #6c757d;}
    .category-tag {display: inline-block; padding: 2px 8px; border-radius: 12px; font-size: 0.75em; margin-right: 5px;}
    .tag-fed {background-color: #dc3545; color: white;}
    .tag-boj {background-color: #fd7e14; color: white;}
    .tag-ai {background-color: #6f42c1; color: white;}
    .tag-mag7 {background-color: #0d6efd; color: white;}
    .tag-crypto {background-color: #ffc107; color: black;}
    .tag-macro {background-color: #198754; color: white;}
    .regime-box {padding: 15px; border-radius: 10px; margin: 10px 0;}
    .regime-risk-on {background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); border: 2px solid #28a745;}
    .regime-risk-off {background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%); border: 2px solid #dc3545;}
    .regime-neutral {background: linear-gradient(135deg, #e2e3e5 0%, #d6d8db 100%); border: 2px solid #6c757d;}
    .export-box {background-color: #f0f7ff; border: 1px dashed #0d6efd; padding: 15px; border-radius: 8px; margin: 10px 0;}
    </style>
    """, unsafe_allow_html=True)

# --- [ä¾§è¾¹æ ] ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    av_api_key = st.text_input("AlphaVantage API Key", value="UMWB63OXOOCIZHXR", type="password")
    
    st.divider()
    st.subheader("ğŸ”„ åˆ·æ–°æ§åˆ¶")
    
    # å…¨å±€åˆ·æ–° (æ‰€æœ‰æ•°æ®)
    if st.button("ğŸ”„ å…¨å±€åˆ·æ–° (æ‰€æœ‰æ•°æ®)", use_container_width=True):
        st.cache_data.clear()
        st.rerun()
    
    st.caption("âš ï¸ å…¨å±€åˆ·æ–°è¾ƒæ…¢ï¼Œå»ºè®®ä»…åœ¨å¼€ç›˜å‰ä½¿ç”¨")
    
    st.divider()
    
    # åˆ†ç±»åˆ·æ–°
    st.markdown("**æŒ‰éœ€åˆ·æ–°ï¼š**")
    
    col_ref1, col_ref2 = st.columns(2)
    with col_ref1:
        if st.button("ğŸ“Š GEX/æœŸæƒ", use_container_width=True, help="åˆ·æ–°æœŸæƒé“¾å’ŒGEXè®¡ç®—"):
            # æ¸…é™¤æœŸæƒç›¸å…³ç¼“å­˜
            calculate_gex_profile.clear()
            get_qqq_options_data.clear()
            get_derivatives_structure.clear()
            st.rerun()
    
    with col_ref2:
        if st.button("ğŸ“ˆ æ—¥å†…æ•°æ®", use_container_width=True, help="åˆ·æ–°VWAPå’Œç›˜ä¸­æ•°æ®"):
            get_intraday_tactics.clear()
            st.rerun()
    
    col_ref3, col_ref4 = st.columns(2)
    with col_ref3:
        if st.button("ğŸ“° æ–°é—»", use_container_width=True, help="åˆ·æ–°æ–°é—»å’Œæƒ…ç»ªåˆ†æ"):
            get_multi_source_news.clear()
            st.rerun()
    
    with col_ref4:
        if st.button("ğŸ’§ æµåŠ¨æ€§", use_container_width=True, help="åˆ·æ–°SOFR/RRP/TGA"):
            get_sofr_repo_history.clear()
            get_rrp_tga_history.clear()
            get_ny_fed_data.clear()
            get_fed_liquidity.clear()
            st.rerun()
    
    st.divider()
    st.subheader("ğŸ“‹ ç¼“å­˜ç­–ç•¥")
    st.caption("""
    â€¢ æµåŠ¨æ€§/å®è§‚: 4å°æ—¶  
    â€¢ ç¾å€º/æ±‡ç‡: 2å°æ—¶  
    â€¢ æ–°é—»: 2å°æ—¶  
    â€¢ æœŸæƒ/GEX: 1å°æ—¶  
    â€¢ æ—¥å†…VWAP: 5åˆ†é’Ÿ
    """)

# ============================================================
# 1. æ ¸å¿ƒæ•°æ®è·å–å‡½æ•°
# ============================================================

@st.cache_resource
def load_ai_model():
    return pipeline("sentiment-analysis", model="ProsusAI/finbert")

# --- SOFR/Repo å†å²æ•°æ® (30å¤©) ---
@st.cache_data(ttl=14400)  # 4å°æ—¶ç¼“å­˜ (å®è§‚æ•°æ®å˜åŒ–æ…¢)
def get_sofr_repo_history():
    """è·å– SOFR å’Œ Repo åˆ©ç‡çš„30å¤©å†å²æ•°æ®"""
    result = {
        'dates': [],
        'sofr': [],
        'tgcr': [],
        'spread': [],
        'current_sofr': 5.33,
        'current_tgcr': 5.32
    }
    try:
        # NY Fed API for historical rates
        end_date = datetime.date.today()
        start_date = end_date - timedelta(days=45)  # å¤šå–ä¸€äº›ç¡®ä¿æœ‰30ä¸ªäº¤æ˜“æ—¥
        
        url = f"https://markets.newyorkfed.org/api/rates/secured/sofr/search.json?startDate={start_date}&endDate={end_date}"
        r = requests.get(url, timeout=10)
        if r.status_code == 200:
            data = r.json()
            sofr_data = {}
            for item in data.get('refRates', []):
                date = item.get('effectiveDate', '')
                rate = item.get('percentRate', 0)
                sofr_data[date] = float(rate)
        
        # TGCR (Tri-Party General Collateral Rate)
        url_tgcr = f"https://markets.newyorkfed.org/api/rates/secured/tgcr/search.json?startDate={start_date}&endDate={end_date}"
        r2 = requests.get(url_tgcr, timeout=10)
        tgcr_data = {}
        if r2.status_code == 200:
            data2 = r2.json()
            for item in data2.get('refRates', []):
                date = item.get('effectiveDate', '')
                rate = item.get('percentRate', 0)
                tgcr_data[date] = float(rate)
        
        # åˆå¹¶æ•°æ®
        all_dates = sorted(set(sofr_data.keys()) & set(tgcr_data.keys()))[-30:]
        for date in all_dates:
            result['dates'].append(date)
            result['sofr'].append(sofr_data.get(date, 0))
            result['tgcr'].append(tgcr_data.get(date, 0))
            result['spread'].append(sofr_data.get(date, 0) - tgcr_data.get(date, 0))
        
        if result['sofr']:
            result['current_sofr'] = result['sofr'][-1]
            result['current_tgcr'] = result['tgcr'][-1]
            
    except Exception as e:
        st.warning(f"SOFR/Repo å†å²æ•°æ®è·å–å¤±è´¥: {e}")
    
    return result

# --- RRP/TGA å†å²æ•°æ® (30å¤©) ---
@st.cache_data(ttl=14400)  # 4å°æ—¶ç¼“å­˜ (æ¯å¤©æ›´æ–°ä¸€æ¬¡çš„æ•°æ®)
def get_rrp_tga_history():
    """è·å– RRP å’Œ TGA çš„30å¤©å†å²æ•°æ®"""
    result = {
        'dates': [],
        'rrp': [],
        'tga': [],
        'current_rrp': 0,
        'current_tga': 0,
        'rrp_chg': 0,
        'tga_chg': 0
    }
    try:
        # RRP (Overnight Reverse Repo)
        rrp_url = "https://fred.stlouisfed.org/graph/fredgraph.csv?id=RRPONTSYD"
        rrp_df = pd.read_csv(rrp_url)
        
        # è‡ªåŠ¨æ£€æµ‹æ—¥æœŸåˆ—å (å¯èƒ½æ˜¯ 'DATE' æˆ– 'date' æˆ–ç¬¬ä¸€åˆ—)
        date_col = None
        for col in rrp_df.columns:
            if col.upper() == 'DATE' or 'date' in col.lower():
                date_col = col
                break
        if date_col is None:
            date_col = rrp_df.columns[0]  # ä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºæ—¥æœŸ
        
        # æ•°æ®åˆ—
        rrp_col = 'RRPONTSYD' if 'RRPONTSYD' in rrp_df.columns else rrp_df.columns[1]
        
        rrp_df = rrp_df.dropna().tail(35)
        rrp_df[date_col] = pd.to_datetime(rrp_df[date_col])
        
        # TGA (Treasury General Account)
        tga_url = "https://fred.stlouisfed.org/graph/fredgraph.csv?id=WTREGEN"
        tga_df = pd.read_csv(tga_url)
        
        # è‡ªåŠ¨æ£€æµ‹ TGA åˆ—å
        tga_date_col = None
        for col in tga_df.columns:
            if col.upper() == 'DATE' or 'date' in col.lower():
                tga_date_col = col
                break
        if tga_date_col is None:
            tga_date_col = tga_df.columns[0]
        
        tga_col = 'WTREGEN' if 'WTREGEN' in tga_df.columns else tga_df.columns[1]
        
        tga_df = tga_df.dropna().tail(35)
        tga_df[tga_date_col] = pd.to_datetime(tga_df[tga_date_col])
        
        # å–æœ€è¿‘30å¤©
        result['dates'] = rrp_df[date_col].dt.strftime('%Y-%m-%d').tolist()[-30:]
        result['rrp'] = rrp_df[rrp_col].tolist()[-30:]
        
        # TGA æ˜¯å‘¨åº¦æ•°æ®ï¼Œéœ€è¦å¯¹é½ (ä½¿ç”¨å‰å‘å¡«å……)
        tga_dict = dict(zip(tga_df[tga_date_col].dt.strftime('%Y-%m-%d'), tga_df[tga_col]))
        result['tga'] = []
        last_tga = list(tga_dict.values())[-1] if tga_dict else 0
        for d in result['dates']:
            if d in tga_dict:
                last_tga = tga_dict[d]
            result['tga'].append(last_tga)
        
        if result['rrp']:
            result['current_rrp'] = result['rrp'][-1]
            result['rrp_chg'] = result['rrp'][-1] - result['rrp'][-2] if len(result['rrp']) > 1 else 0
        if result['tga']:
            result['current_tga'] = result['tga'][-1]
            result['tga_chg'] = result['tga'][-1] - result['tga'][-2] if len(result['tga']) > 1 else 0
            
    except Exception as e:
        # é™é»˜å¤±è´¥ï¼Œä¸æ˜¾ç¤ºè­¦å‘Šï¼Œè¿”å›ç©ºç»“æœ
        pass
    
    return result

@st.cache_data(ttl=14400)  # 4å°æ—¶ç¼“å­˜
def get_ny_fed_data():
    try:
        url = "https://markets.newyorkfed.org/api/rates/all/latest.json"
        r = requests.get(url, timeout=5).json()
        rates = {'SOFR': 5.3, 'TGCR': 5.3} 
        for item in r.get('refRates', []):
            if item['type'] == 'SOFR': rates['SOFR'] = float(item['percentRate'])
            if item['type'] == 'TGCR': rates['TGCR'] = float(item['percentRate'])
        return rates
    except: return {'SOFR': 5.33, 'TGCR': 5.32}

@st.cache_data(ttl=14400)  # 4å°æ—¶ç¼“å­˜
def get_fed_liquidity():
    res = {"RRP": 0, "RRP_Chg": 0, "TGA": 0, "TGA_Chg": 0}
    try:
        rrp_df = pd.read_csv("https://fred.stlouisfed.org/graph/fredgraph.csv?id=RRPONTSYD")
        res['RRP'] = rrp_df.iloc[-1]['RRPONTSYD']
        res['RRP_Chg'] = res['RRP'] - rrp_df.iloc[-2]['RRPONTSYD']
        tga_df = pd.read_csv("https://fred.stlouisfed.org/graph/fredgraph.csv?id=WTREGEN")
        res['TGA'] = tga_df.iloc[-1]['WTREGEN']
        res['TGA_Chg'] = res['TGA'] - tga_df.iloc[-2]['WTREGEN']
    except: pass
    return res

@st.cache_data(ttl=7200)  # 2å°æ—¶ç¼“å­˜
def get_credit_spreads():
    try:
        data = yf.download(["HYG", "LQD"], period="5d", progress=False)['Close']
        if isinstance(data.columns, pd.MultiIndex): data.columns = data.columns.get_level_values(0)
        ratio = data['HYG'] / data['LQD']
        curr = ratio.iloc[-1]
        pct = ((curr - ratio.iloc[-2]) / ratio.iloc[-2]) * 100
        return curr, pct
    except: return 0, 0

@st.cache_data(ttl=7200)  # 2å°æ—¶ç¼“å­˜
def get_rates_and_fx():
    tickers = ["^IRX", "^TNX", "DX-Y.NYB", "JPY=X", "^MOVE"] 
    res = {'Yield_Short': 0, 'Yield_10Y': 0, 'Inversion': 0, 'DXY': 0, 'USDJPY': 0, 'MOVE': 0, 'USDJPY_Chg': 0}
    
    try:
        df = yf.download(tickers, period="1mo", group_by='ticker', progress=False)
        
        try:
            tnx_series = df['^TNX']['Close'].dropna()
            if not tnx_series.empty:
                res['Yield_10Y'] = tnx_series.iloc[-1]
        except: pass

        try:
            irx_series = df['^IRX']['Close'].dropna()
            if not irx_series.empty:
                res['Yield_Short'] = irx_series.iloc[-1]
        except: pass
        
        try:
            move_series = df['^MOVE']['Close']
            move_series = move_series.ffill().dropna()
            if not move_series.empty:
                res['MOVE'] = move_series.iloc[-1]
            else:
                res['MOVE'] = 0
        except: pass

        try:
            if not df['DX-Y.NYB']['Close'].dropna().empty: 
                res['DXY'] = df['DX-Y.NYB']['Close'].dropna().iloc[-1]
            jpy_series = df['JPY=X']['Close'].dropna()
            if not jpy_series.empty: 
                res['USDJPY'] = jpy_series.iloc[-1]
                if len(jpy_series) > 1:
                    res['USDJPY_Chg'] = jpy_series.iloc[-1] - jpy_series.iloc[-2]
        except: pass

        if res['Yield_10Y'] and res['Yield_Short']:
            res['Inversion'] = res['Yield_10Y'] - res['Yield_Short']

    except Exception as e:
        print(f"Rates Error: {e}")
        
    return res

@st.cache_data(ttl=3600)  # 1å°æ—¶ç¼“å­˜
def get_volatility_indices():
    data = {}
    try:
        vix = yf.Ticker("^VIX").history(period="2d")['Close'].iloc[-1]
        data['VIX'] = vix
    except: data['VIX'] = 15.0
    try:
        r = requests.get("https://api.alternative.me/fng/").json()
        data['Crypto_Val'] = int(r['data'][0]['value'])
        data['Crypto_Text'] = r['data'][0]['value_classification']
    except: data['Crypto_Val'] = 50; data['Crypto_Text'] = "Unknown"
    return data

@st.cache_data(ttl=3600)  # 1å°æ—¶ç¼“å­˜
def get_derivatives_structure():
    res = {
        "Futures_Basis": 0, "Basis_Status": "Normal", 
        "GEX_Net": "Neutral", "Call_Wall": 0, "Put_Wall": 0, 
        "Vanna_Status": "Neutral", "Current_Price": 0
    }
    try:
        market_data = yf.download(["NQ=F", "^NDX", "QQQ", "^VIX"], period="2d", progress=False)['Close']
        if isinstance(market_data.columns, pd.MultiIndex): market_data.columns = market_data.columns.get_level_values(0)
        
        fut = market_data['NQ=F'].iloc[-1]
        spot = market_data['^NDX'].iloc[-1]
        qqq_price = market_data['QQQ'].iloc[-1]
        res['Current_Price'] = qqq_price
        
        basis = fut - spot
        res['Futures_Basis'] = basis
        if basis < -15: res['Basis_Status'] = "ğŸ”´ Backwardation (æåº¦çœ‹ç©º)"
        elif basis > 60: res['Basis_Status'] = "ğŸŸ¢ Contango (æ­£å¸¸)"
        else: res['Basis_Status'] = "âšª Neutral"
        
        qqq = yf.Ticker("QQQ")
        expirations = qqq.options[:3] 
        all_calls = []; all_puts = []
        for date in expirations:
            try:
                chain = qqq.option_chain(date)
                c = chain.calls.fillna(0); p = chain.puts.fillna(0)
                c = c[c['openInterest'] > 100]; p = p[p['openInterest'] > 100]
                all_calls.append(c[['strike', 'openInterest']])
                all_puts.append(p[['strike', 'openInterest']])
            except: continue
        
        if all_calls:
            df_calls = pd.concat(all_calls).groupby('strike')['openInterest'].sum()
            df_puts = pd.concat(all_puts).groupby('strike')['openInterest'].sum()
            res['Call_Wall'] = df_calls.idxmax()
            res['Put_Wall'] = df_puts.idxmax()
            
            range_min = qqq_price * 0.98; range_max = qqq_price * 1.02
            calls_atm = df_calls[(df_calls.index >= range_min) & (df_calls.index <= range_max)].sum()
            puts_atm = df_puts[(df_puts.index >= range_min) & (df_puts.index <= range_max)].sum()
            gamma_ratio = puts_atm / max(1, calls_atm)
            
            if qqq_price < res['Put_Wall']: res['GEX_Net'] = "ğŸ”´ Negative Gamma (Crash Risk)"
            elif qqq_price > res['Call_Wall']: res['GEX_Net'] = "ğŸŸ¢ Positive Gamma (Breakout)"
            else:
                if gamma_ratio > 1.2: res['GEX_Net'] = "ğŸŸ  Weak Negative (éœ‡è¡åå¼±)"
                else: res['GEX_Net'] = "ğŸŸ¢ Positive Gamma (éœ‡è¡åå¼º)"

        ndx_chg = spot - market_data['^NDX'].iloc[-2]
        vix_chg = market_data['^VIX'].iloc[-1] - market_data['^VIX'].iloc[-2]
        if ndx_chg > 0 and vix_chg < 0: res['Vanna_Status'] = "ğŸŸ¢ Tailwind (åŠ©æ¶¨)"
        elif ndx_chg < 0 and vix_chg > 0: res['Vanna_Status'] = "ğŸ”´ Headwind (åŠ©è·Œ)"
    except: pass
    return res

@st.cache_data(ttl=3600)  # 1å°æ—¶ç¼“å­˜
def get_qqq_options_data():
    qqq = yf.Ticker("QQQ")
    res = {"PCR": 0.0, "Unusual": []}
    try:
        expirations = qqq.options[:3]
        total_c_vol = 0; total_p_vol = 0; unusual = []
        for date in expirations:
            try:
                chain = qqq.option_chain(date)
                calls = chain.calls.fillna(0); puts = chain.puts.fillna(0)
                total_c_vol += calls['volume'].sum(); total_p_vol += puts['volume'].sum()
                for opt_type, df, icon in [("CALL", calls, "ğŸŸ¢"), ("PUT", puts, "ğŸ”´")]:
                    hot = df[(df['volume'] > 2000) & (df['volume'] > df['openInterest'] * 1.2)]
                    for _, row in hot.iterrows():
                        unusual.append({
                            "Type": f"{icon} {opt_type}", "Strike": row['strike'], "Exp": date,
                            "Vol": int(row['volume']), "OI": int(row['openInterest']),
                            "Ratio": round(row['volume'] / (row['openInterest']+1), 1)
                        })
            except: continue
        if total_c_vol > 0: res['PCR'] = round(total_p_vol / total_c_vol, 2)
        res['Unusual'] = sorted(unusual, key=lambda x: x['Vol'], reverse=True)[:10]
    except: pass
    return res

@st.cache_data(ttl=300)  # 5åˆ†é’Ÿç¼“å­˜ (æ—¥å†…æ•°æ®éœ€è¦è¾ƒæ–°)
def get_intraday_tactics():
    res = {
        "VWAP": 0, "Price": 0, "Trend": "Neutral",
        "Exp_Move": 0, "Upper_Band": 0, "Lower_Band": 0,
        "0DTE_Call_Vol": 0, "0DTE_Put_Vol": 0, "0DTE_Sentiment": "Neutral",
        "Last_Update": datetime.datetime.now().strftime("%H:%M:%S")
    }
    try:
        df = yf.download("QQQ", period="1d", interval="1m", progress=False)
        if not df.empty:
            if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
            df['TP'] = (df['High'] + df['Low'] + df['Close']) / 3
            df['PV'] = df['TP'] * df['Volume']
            vwap = df['PV'].sum() / df['Volume'].sum() if df['Volume'].sum() > 0 else 0
            
            current_price = df['Close'].iloc[-1]
            res['VWAP'] = vwap
            res['Price'] = current_price
            
            if vwap > 0:
                if current_price > vwap * 1.001: res['Trend'] = "ğŸŸ¢ å¤šå¤´å¼ºåŠ¿"
                elif current_price < vwap * 0.999: res['Trend'] = "ğŸ”´ ç©ºå¤´å‹åˆ¶"
                else: res['Trend'] = "âšª éœ‡è¡"
            
        vix = yf.Ticker("^VIX").history(period="1d")['Close'].iloc[-1]
        exp_move = res['Price'] * ((vix/16)/100)
        res['Exp_Move'] = exp_move
        res['Upper_Band'] = res['Price'] + exp_move
        res['Lower_Band'] = res['Price'] - exp_move
        
        qqq = yf.Ticker("QQQ")
        target_date = qqq.options[0]
        chain = qqq.option_chain(target_date)
        c_vol = chain.calls['volume'].sum()
        p_vol = chain.puts['volume'].sum()
        res['0DTE_Call_Vol'] = c_vol
        res['0DTE_Put_Vol'] = p_vol
        
        ratio = p_vol / c_vol if c_vol > 0 else 1
        if ratio < 0.8: res['0DTE_Sentiment'] = "ğŸŸ¢ Call ä¸»å¯¼"
        elif ratio > 1.2: res['0DTE_Sentiment'] = "ğŸ”´ Put ä¸»å¯¼"
        else: res['0DTE_Sentiment'] = "âšª å¹³è¡¡"
        
        res['Expiry_Date'] = target_date
    except Exception as e: pass
    return res

# ============================================================
# 2. æ–°é—»ç³»ç»Ÿ (å¤šæº + é‡è¦æ€§è¯„åˆ†)
# ============================================================

# å…³é”®è¯é‡è¦æ€§æƒé‡
IMPORTANCE_WEIGHTS = {
    # æœ€é«˜ä¼˜å…ˆçº§ - å¤®è¡Œæ”¿ç­– (æƒé‡ 5)
    "FOMC": 5, "rate decision": 5, "Powell": 5, "Ueda": 5, "Kuroda": 5,
    "rate cut": 5, "rate hike": 5, "QT": 5, "QE": 5, "tapering": 5,
    "Fed": 4, "BOJ": 4, "ECB": 4, "Bank of Japan": 4,
    
    # é«˜ä¼˜å…ˆçº§ - å®è§‚æ•°æ® (æƒé‡ 4)
    "CPI": 4, "inflation": 4, "employment": 4, "GDP": 4, "PCE": 4,
    "payroll": 4, "unemployment": 4, "Treasury": 4, "yield": 3,
    
    # ä¸­é«˜ä¼˜å…ˆçº§ - ä¸ƒå·¨å¤´ (æƒé‡ 3)
    "NVIDIA": 3, "NVDA": 3, "Apple": 3, "AAPL": 3, 
    "Microsoft": 3, "MSFT": 3, "Google": 3, "Alphabet": 3, "GOOGL": 3,
    "Amazon": 3, "AMZN": 3, "Meta": 3, "META": 3, 
    "Tesla": 3, "TSLA": 3,
    
    # ä¸­ä¼˜å…ˆçº§ - AI (æƒé‡ 3)
    "OpenAI": 3, "ChatGPT": 3, "GPT-5": 4, "AI chip": 3, "GPU": 3,
    "artificial intelligence": 3, "machine learning": 2, "LLM": 3,
    "Anthropic": 3, "Claude": 2,
    
    # åŠ å¯†è´§å¸ (æƒé‡ 2)
    "Bitcoin": 2, "BTC": 2, "Ethereum": 2, "ETH": 2, "crypto": 2,
    
    # ä¸€èˆ¬è´¢ç» (æƒé‡ 1-2)
    "earnings": 2, "revenue": 2, "guidance": 2,
    "stock": 1, "market": 1, "trading": 1
}

# æ–°é—»åˆ†ç±»
NEWS_CATEGORIES = {
    "fed": ["Fed", "FOMC", "Powell", "rate cut", "rate hike", "QT", "QE", "Treasury", "Federal Reserve"],
    "boj": ["BOJ", "Bank of Japan", "Ueda", "Kuroda", "yen", "JPY"],
    "ai": ["OpenAI", "ChatGPT", "GPT", "AI chip", "artificial intelligence", "LLM", "Anthropic", "Claude", "machine learning"],
    "mag7": ["NVIDIA", "NVDA", "Apple", "AAPL", "Microsoft", "MSFT", "Google", "Alphabet", "GOOGL", "Amazon", "AMZN", "Meta", "META", "Tesla", "TSLA"],
    "crypto": ["Bitcoin", "BTC", "Ethereum", "ETH", "crypto", "cryptocurrency"],
    "macro": ["CPI", "inflation", "GDP", "employment", "payroll", "unemployment", "PCE"]
}

def categorize_news(title: str) -> list:
    """å¯¹æ–°é—»è¿›è¡Œåˆ†ç±»"""
    categories = []
    title_lower = title.lower()
    for cat, keywords in NEWS_CATEGORIES.items():
        for kw in keywords:
            if kw.lower() in title_lower:
                categories.append(cat)
                break
    return list(set(categories)) if categories else ["general"]

def score_news_importance(title: str) -> int:
    """è®¡ç®—æ–°é—»é‡è¦æ€§è¯„åˆ†"""
    score = 0
    title_lower = title.lower()
    for keyword, weight in IMPORTANCE_WEIGHTS.items():
        if keyword.lower() in title_lower:
            score = max(score, weight)  # å–æœ€é«˜æƒé‡è€Œéç´¯åŠ 
    return score

@st.cache_data(ttl=7200)  # 2å°æ—¶ç¼“å­˜ (æ–°é—» + FinBERT åˆ†æè¾ƒæ…¢)
def get_multi_source_news():
    """ä»å¤šä¸ªæ¥æºè·å–æ–°é—»"""
    feeds = [
        # å®è§‚ & ç¾è”å‚¨
        ("Fed", "https://www.federalreserve.gov/feeds/press_all.xml"),
        ("Reuters", "https://feeds.reuters.com/reuters/businessNews"),
        ("CNBC", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=20910258"),
        
        # ç§‘æŠ€ & AI
        ("TechCrunch", "https://techcrunch.com/feed/"),
        
        # åŠ å¯†è´§å¸
        ("CoinDesk", "https://www.coindesk.com/arc/outboundfeeds/rss/"),
    ]
    
    articles = []
    for src, url in feeds:
        try:
            f = feedparser.parse(url)
            for e in f.entries[:8]:  # æ¯ä¸ªæºå–8æ¡
                title = e.get('title', '')
                link = e.get('link', '')
                published = e.get('published', e.get('updated', ''))
                
                importance = score_news_importance(title)
                categories = categorize_news(title)
                
                articles.append({
                    "Title": title,
                    "Link": link,
                    "Source": src,
                    "Published": published,
                    "Importance": importance,
                    "Categories": categories
                })
        except Exception as e:
            continue
    
    # æŒ‰é‡è¦æ€§æ’åº
    articles = sorted(articles, key=lambda x: x['Importance'], reverse=True)
    
    return pd.DataFrame(articles)

# ============================================================
# 3. å®è§‚æ—¥å† (2025 å…³é”®æ—¥æœŸ + å€’è®¡æ—¶)
# ============================================================

MACRO_CALENDAR_2025 = [
    # FOMC ä¼šè®®
    {"date": "2025-01-29", "event": "FOMC åˆ©ç‡å†³è®®", "type": "fed", "importance": 5},
    {"date": "2025-03-19", "event": "FOMC åˆ©ç‡å†³è®® + ç‚¹é˜µå›¾", "type": "fed", "importance": 5},
    {"date": "2025-05-07", "event": "FOMC åˆ©ç‡å†³è®®", "type": "fed", "importance": 5},
    {"date": "2025-06-18", "event": "FOMC åˆ©ç‡å†³è®® + ç‚¹é˜µå›¾", "type": "fed", "importance": 5},
    {"date": "2025-07-30", "event": "FOMC åˆ©ç‡å†³è®®", "type": "fed", "importance": 5},
    {"date": "2025-09-17", "event": "FOMC åˆ©ç‡å†³è®® + ç‚¹é˜µå›¾", "type": "fed", "importance": 5},
    {"date": "2025-11-05", "event": "FOMC åˆ©ç‡å†³è®®", "type": "fed", "importance": 5},
    {"date": "2025-12-17", "event": "FOMC åˆ©ç‡å†³è®® + ç‚¹é˜µå›¾", "type": "fed", "importance": 5},
    
    # CPI æ•°æ® (é€šå¸¸åœ¨æ¯æœˆ10-15æ—¥)
    {"date": "2025-01-15", "event": "CPI (12æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-02-12", "event": "CPI (1æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-03-12", "event": "CPI (2æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-04-10", "event": "CPI (3æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-05-13", "event": "CPI (4æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-06-11", "event": "CPI (5æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-07-11", "event": "CPI (6æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-08-13", "event": "CPI (7æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-09-10", "event": "CPI (8æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-10-10", "event": "CPI (9æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-11-13", "event": "CPI (10æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-12-10", "event": "CPI (11æœˆ)", "type": "inflation", "importance": 4},
    
    # éå†œå°±ä¸š (é€šå¸¸åœ¨æ¯æœˆç¬¬ä¸€ä¸ªå‘¨äº”)
    {"date": "2025-01-10", "event": "éå†œå°±ä¸š (12æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-02-07", "event": "éå†œå°±ä¸š (1æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-03-07", "event": "éå†œå°±ä¸š (2æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-04-04", "event": "éå†œå°±ä¸š (3æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-05-02", "event": "éå†œå°±ä¸š (4æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-06-06", "event": "éå†œå°±ä¸š (5æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-07-03", "event": "éå†œå°±ä¸š (6æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-08-01", "event": "éå†œå°±ä¸š (7æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-09-05", "event": "éå†œå°±ä¸š (8æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-10-03", "event": "éå†œå°±ä¸š (9æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-11-07", "event": "éå†œå°±ä¸š (10æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-12-05", "event": "éå†œå°±ä¸š (11æœˆ)", "type": "employment", "importance": 4},
    
    # BOJ ä¼šè®®
    {"date": "2025-01-24", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-03-14", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-05-01", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-06-13", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-07-31", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-09-19", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-10-31", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-12-19", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    
    # æœŸæƒåˆ°æœŸ
    {"date": "2025-01-17", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-02-21", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-03-21", "event": "ä¸‰å·«æ—¥ (Quad Witching)", "type": "opex", "importance": 4},
    {"date": "2025-04-17", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-05-16", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-06-20", "event": "ä¸‰å·«æ—¥ (Quad Witching)", "type": "opex", "importance": 4},
    {"date": "2025-07-18", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-08-15", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-09-19", "event": "ä¸‰å·«æ—¥ (Quad Witching)", "type": "opex", "importance": 4},
    {"date": "2025-10-17", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-11-21", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-12-19", "event": "ä¸‰å·«æ—¥ (Quad Witching)", "type": "opex", "importance": 4},
]

def get_macro_calendar_with_countdown():
    """è·å–å¸¦å€’è®¡æ—¶çš„å®è§‚æ—¥å†"""
    today = datetime.date.today()
    upcoming = []
    
    for evt in MACRO_CALENDAR_2025:
        evt_date = datetime.datetime.strptime(evt["date"], "%Y-%m-%d").date()
        days_until = (evt_date - today).days
        
        if -1 <= days_until <= 60:  # åŒ…æ‹¬æ˜¨å¤©åˆ°æœªæ¥60å¤©
            countdown = ""
            urgency = "normal"
            
            if days_until < 0:
                countdown = "æ˜¨å¤©"
                urgency = "past"
            elif days_until == 0:
                countdown = "ğŸ”´ ä»Šå¤©!"
                urgency = "urgent"
            elif days_until == 1:
                countdown = "ğŸŸ  æ˜å¤©"
                urgency = "urgent"
            elif days_until <= 3:
                countdown = f"âš ï¸ {days_until}å¤©å"
                urgency = "soon"
            elif days_until <= 7:
                countdown = f"ğŸ“… {days_until}å¤©å"
                urgency = "soon"
            else:
                countdown = f"{days_until}å¤©å"
                urgency = "normal"
            
            upcoming.append({
                **evt,
                "countdown": countdown,
                "urgency": urgency,
                "days_until": days_until
            })
    
    return sorted(upcoming, key=lambda x: x["days_until"])

# ============================================================
# 4. Gamma è®¡ç®—ç³»ç»Ÿ (Black-Scholes)
# ============================================================

def black_scholes_gamma(S, K, T, r, sigma):
    """
    è®¡ç®— Black-Scholes Gamma
    S: ç°è´§ä»·æ ¼
    K: è¡Œæƒä»·
    T: åˆ°æœŸæ—¶é—´ (å¹´)
    r: æ— é£é™©åˆ©ç‡
    sigma: éšå«æ³¢åŠ¨ç‡
    """
    if T <= 0 or sigma <= 0 or S <= 0 or K <= 0:
        return 0
    
    try:
        d1 = (np.log(S/K) + (r + 0.5*sigma**2)*T) / (sigma*np.sqrt(T))
        gamma = norm.pdf(d1) / (S * sigma * np.sqrt(T))
        return gamma
    except:
        return 0

@st.cache_data(ttl=3600)  # 1å°æ—¶ç¼“å­˜ (å¯æ‰‹åŠ¨åˆ·æ–°è·å–æœ€æ–°)
def calculate_gex_profile():
    """
    è®¡ç®—å®Œæ•´çš„ GEX Profile
    è¿”å›æŒ‰ Strike åˆ†å¸ƒçš„ Gamma Exposure
    """
    # è®°å½•è®¡ç®—æ—¶é—´
    calc_time = datetime.datetime.now(pytz.timezone('US/Eastern'))
    
    # è®¡ç®— OI æ•°æ®æ—¥æœŸ (å‰ä¸€ä¸ªäº¤æ˜“æ—¥)
    # ç®€åŒ–å¤„ç†ï¼šå¦‚æœæ˜¯å‘¨ä¸€ï¼ŒOI æ˜¯å‘¨äº”çš„ï¼›å¦åˆ™æ˜¯æ˜¨å¤©çš„
    today = datetime.date.today()
    if today.weekday() == 0:  # å‘¨ä¸€
        oi_date = today - timedelta(days=3)  # å‘¨äº”
    elif today.weekday() == 6:  # å‘¨æ—¥
        oi_date = today - timedelta(days=2)  # å‘¨äº”
    elif today.weekday() == 5:  # å‘¨å…­
        oi_date = today - timedelta(days=1)  # å‘¨äº”
    else:
        oi_date = today - timedelta(days=1)  # æ˜¨å¤©
    
    result = {
        'strikes': [],
        'gex_call': [],
        'gex_put': [],
        'gex_net': [],
        'total_gex': 0,
        'gamma_flip': 0,
        'max_pain': 0,
        'spot_price': 0,
        'put_wall': 0,
        'call_wall': 0,
        'calc_time': calc_time.strftime('%Y-%m-%d %H:%M:%S EST'),
        'oi_date': oi_date.strftime('%Y-%m-%d'),
        'oi_weekday': ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥'][oi_date.weekday()]
    }
    
    try:
        # è·å– QQQ æ•°æ®
        qqq = yf.Ticker("QQQ")
        hist = qqq.history(period="1d")
        if hist.empty:
            return result
        spot = float(hist['Close'].iloc[-1])
        result['spot_price'] = spot
        
        # è·å–æ— é£é™©åˆ©ç‡ (3ä¸ªæœˆå›½å€º)
        try:
            irx_hist = yf.Ticker("^IRX").history(period="1d")
            if not irx_hist.empty:
                irx = float(irx_hist['Close'].iloc[-1]) / 100
            else:
                irx = 0.05
        except:
            irx = 0.05
        
        # æ”¶é›†æ‰€æœ‰æœŸæƒé“¾æ•°æ®
        try:
            expirations = qqq.options[:4]  # å–å‰4ä¸ªåˆ°æœŸæ—¥
        except:
            return result
            
        all_options = []
        
        for exp_date in expirations:
            try:
                chain = qqq.option_chain(exp_date)
                
                # è®¡ç®—åˆ°æœŸæ—¶é—´
                exp_dt = datetime.datetime.strptime(exp_date, "%Y-%m-%d")
                today = datetime.datetime.now()
                days_to_exp = (exp_dt - today).days
                T = max(days_to_exp / 365, 0.001)
                
                # å¤„ç† Calls
                for _, row in chain.calls.iterrows():
                    try:
                        oi = row.get('openInterest', 0)
                        if pd.isna(oi):
                            oi = 0
                        oi = float(oi)
                        
                        if oi > 50:
                            iv = row.get('impliedVolatility', 0.3)
                            if pd.isna(iv) or iv <= 0 or iv > 5:  # IV è¶…è¿‡ 500% è§†ä¸ºå¼‚å¸¸
                                iv = 0.3
                            iv = float(iv)
                            
                            strike = float(row['strike'])
                            all_options.append({
                                'strike': strike,
                                'oi': oi,
                                'iv': iv,
                                'T': T,
                                'type': 'call'
                            })
                    except:
                        continue
                
                # å¤„ç† Puts
                for _, row in chain.puts.iterrows():
                    try:
                        oi = row.get('openInterest', 0)
                        if pd.isna(oi):
                            oi = 0
                        oi = float(oi)
                        
                        if oi > 50:
                            iv = row.get('impliedVolatility', 0.3)
                            if pd.isna(iv) or iv <= 0 or iv > 5:
                                iv = 0.3
                            iv = float(iv)
                            
                            strike = float(row['strike'])
                            all_options.append({
                                'strike': strike,
                                'oi': oi,
                                'iv': iv,
                                'T': T,
                                'type': 'put'
                            })
                    except:
                        continue
            except:
                continue
        
        if not all_options:
            return result
        
        # è®¡ç®—æ¯ä¸ª Strike çš„ GEX
        gex_by_strike = {}
        
        for opt in all_options:
            try:
                strike = opt['strike']
                gamma = black_scholes_gamma(spot, strike, opt['T'], irx, opt['iv'])
                
                # GEX = Gamma Ã— OI Ã— 100 Ã— SpotÂ² / 1e9 (è½¬æ¢ä¸ºåäº¿ç¾å…ƒ)
                gex = gamma * opt['oi'] * 100 * (spot ** 2) / 1e9
                
                if strike not in gex_by_strike:
                    gex_by_strike[strike] = {'call': 0, 'put': 0}
                
                if opt['type'] == 'call':
                    gex_by_strike[strike]['call'] += gex
                else:
                    gex_by_strike[strike]['put'] += gex
            except:
                continue
        
        if not gex_by_strike:
            return result
        
        # è¿‡æ»¤å¹¶æ’åº - åªä¿ç•™ç°ä»·é™„è¿‘ Â±10% çš„ strikes
        valid_strikes = [s for s in gex_by_strike.keys() if spot * 0.9 <= s <= spot * 1.1]
        valid_strikes = sorted(valid_strikes)
        
        if not valid_strikes:
            return result
        
        for strike in valid_strikes:
            result['strikes'].append(strike)
            result['gex_call'].append(gex_by_strike[strike]['call'])
            result['gex_put'].append(-gex_by_strike[strike]['put'])  # Put GEX ä¸ºè´Ÿ
            result['gex_net'].append(gex_by_strike[strike]['call'] - gex_by_strike[strike]['put'])
        
        # è®¡ç®—æ€» GEX
        result['total_gex'] = sum(result['gex_net'])
        
        # æ‰¾ Gamma Flip Point (å‡€ GEX ä»æ­£å˜è´Ÿæˆ–ä»è´Ÿå˜æ­£çš„ç‚¹)
        for i in range(len(result['strikes']) - 1):
            current_gex = result['gex_net'][i]
            next_gex = result['gex_net'][i+1]
            if (current_gex > 0 and next_gex < 0) or (current_gex < 0 and next_gex > 0):
                result['gamma_flip'] = (result['strikes'][i] + result['strikes'][i+1]) / 2
                break
        
        # æ‰¾ Put Wall å’Œ Call Wall (æœ€å¤§ GEX é›†ä¸­ä½ç½®)
        if result['gex_call']:
            max_call_gex = max(result['gex_call'])
            if max_call_gex > 0:
                max_call_idx = result['gex_call'].index(max_call_gex)
                result['call_wall'] = result['strikes'][max_call_idx]
        
        if result['gex_put']:
            min_put_gex = min(result['gex_put'])  # æœ€è´Ÿçš„
            if min_put_gex < 0:
                max_put_idx = result['gex_put'].index(min_put_gex)
                result['put_wall'] = result['strikes'][max_put_idx]
        
        # è®¡ç®— Max Pain (ç®€åŒ–ç‰ˆ - æ‰¾ OI æœ€é›†ä¸­çš„ strike)
        try:
            total_oi_by_strike = {}
            for opt in all_options:
                strike = opt['strike']
                if strike in valid_strikes:
                    if strike not in total_oi_by_strike:
                        total_oi_by_strike[strike] = 0
                    total_oi_by_strike[strike] += opt['oi']
            
            if total_oi_by_strike:
                result['max_pain'] = max(total_oi_by_strike, key=total_oi_by_strike.get)
        except:
            pass
        
    except Exception as e:
        # é™é»˜å¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ
        pass
    
    return result

# ============================================================
# 5. æ™ºèƒ½è§„åˆ™å¼•æ“
# ============================================================

def analyze_market_regime(ny_fed, fed_liq, credit, rates, vol, opt, deriv, rrp_tga_hist):
    """
    æ™ºèƒ½è§„åˆ™å¼•æ“ï¼šåˆ†æå¸‚åœºçŠ¶æ€å¹¶ç”Ÿæˆä¿¡å·
    """
    signals = []
    regime = "neutral"
    score = 0
    
    # ========== æµåŠ¨æ€§åˆ†æ ==========
    # è§„åˆ™1: SOFR-Repo åˆ©å·®
    spread = ny_fed['SOFR'] - ny_fed['TGCR']
    if spread > 0.10:
        signals.append({
            "level": "CRITICAL",
            "category": "æµåŠ¨æ€§",
            "msg": f"ğŸš¨ é“¶è¡Œé—´æµåŠ¨æ€§ç´§ç¼º: SOFR-Repo åˆ©å·® {spread:.3f}% è¶…è¿‡è­¦æˆ’çº¿",
            "action": "å‡ä»“è§‚æœ›ï¼Œå…³æ³¨ Fed ç´§æ€¥æ“ä½œ",
            "score": -2
        })
        score -= 2
    elif spread > 0.05:
        signals.append({
            "level": "WARNING",
            "category": "æµåŠ¨æ€§",
            "msg": f"âš ï¸ æµåŠ¨æ€§åç´§: SOFR-Repo åˆ©å·® {spread:.3f}%",
            "action": "è°¨æ…æŒä»“",
            "score": -1
        })
        score -= 1
    elif spread < 0.02:
        signals.append({
            "level": "POSITIVE",
            "category": "æµåŠ¨æ€§",
            "msg": f"âœ… æµåŠ¨æ€§å……è£•: SOFR-Repo åˆ©å·® {spread:.3f}%",
            "action": "ç¯å¢ƒæœ‰åˆ©äºé£é™©èµ„äº§",
            "score": 1
        })
        score += 1
    
    # è§„åˆ™2: RRP + TGA è”åŠ¨
    rrp_chg = fed_liq['RRP_Chg']
    tga_chg = fed_liq['TGA_Chg']
    
    if rrp_chg < -50 and tga_chg > 30:
        signals.append({
            "level": "CRITICAL",
            "category": "æµåŠ¨æ€§",
            "msg": f"ğŸš¨ åŒé‡æŠ½æ°´: RRP {rrp_chg:.0f}B æµå‡º + TGA å¢åŠ  {tga_chg:.0f}B",
            "action": "ç³»ç»ŸæµåŠ¨æ€§æ€¥å‰§æ”¶ç¼©ï¼Œé«˜åº¦è­¦æƒ•",
            "score": -2
        })
        score -= 2
    elif rrp_chg > 50:
        signals.append({
            "level": "POSITIVE",
            "category": "æµåŠ¨æ€§",
            "msg": f"âœ… RRP æ³¨æ°´: {rrp_chg:.0f}B æµå…¥éš”å¤œé€†å›è´­",
            "action": "æµåŠ¨æ€§æ”¹å–„",
            "score": 1
        })
        score += 1
    
    # è§„åˆ™3: ä¿¡ç”¨åˆ©å·®
    if credit[1] < -1.0:
        signals.append({
            "level": "CRITICAL",
            "category": "é£é™©åå¥½",
            "msg": f"ğŸš¨ ä¿¡ç”¨é£é™©é£™å‡: HYG/LQD å•æ—¥ä¸‹è·Œ {credit[1]:.2f}%",
            "action": "èµ„é‡‘æ’¤ç¦»åƒåœ¾å€ºï¼ŒRisk-Off æ¨¡å¼",
            "score": -2
        })
        score -= 2
    elif credit[1] < -0.3:
        signals.append({
            "level": "WARNING",
            "category": "é£é™©åå¥½",
            "msg": f"âš ï¸ ä¿¡ç”¨åç´§: HYG/LQD ä¸‹è·Œ {credit[1]:.2f}%",
            "action": "å…³æ³¨ä¿¡ç”¨å¸‚åœºåŠ¨æ€",
            "score": -1
        })
        score -= 1
    elif credit[1] > 0.5:
        signals.append({
            "level": "POSITIVE",
            "category": "é£é™©åå¥½",
            "msg": f"âœ… é£é™©åå¥½å›å‡: HYG/LQD ä¸Šæ¶¨ {credit[1]:.2f}%",
            "action": "Risk-On ç¯å¢ƒ",
            "score": 1
        })
        score += 1
    
    # ========== ç¾å€ºåˆ†æ ==========
    # è§„åˆ™4: 10Y æ”¶ç›Šç‡
    if rates['Yield_10Y'] > 5.0:
        signals.append({
            "level": "CRITICAL",
            "category": "ç¾å€º",
            "msg": f"ğŸš¨ åˆ©ç‡é£æš´: 10Y æ”¶ç›Šç‡ {rates['Yield_10Y']:.2f}% çªç ´ 5%",
            "action": "ç§‘æŠ€è‚¡ä¼°å€¼æ‰¿å‹ï¼Œå‡æŒé«˜ä¹…æœŸèµ„äº§",
            "score": -2
        })
        score -= 2
    elif rates['Yield_10Y'] > 4.5:
        signals.append({
            "level": "WARNING",
            "category": "ç¾å€º",
            "msg": f"âš ï¸ åˆ©ç‡å‹åŠ›: 10Y æ”¶ç›Šç‡ {rates['Yield_10Y']:.2f}%",
            "action": "å…³æ³¨æˆé•¿è‚¡è¡¨ç°",
            "score": -1
        })
        score -= 1
    
    # è§„åˆ™5: MOVE æŒ‡æ•°
    if rates['MOVE'] > 130:
        signals.append({
            "level": "CRITICAL",
            "category": "ç¾å€º",
            "msg": f"ğŸš¨ å€ºå¸‚ææ…Œ: MOVE {rates['MOVE']:.0f} æç«¯æ³¢åŠ¨",
            "action": "æµåŠ¨æ€§å±æœºé£é™©ï¼Œç°é‡‘ä¸ºç‹",
            "score": -2
        })
        score -= 2
    elif rates['MOVE'] > 110:
        signals.append({
            "level": "WARNING",
            "category": "ç¾å€º",
            "msg": f"âš ï¸ å€ºå¸‚æ³¢åŠ¨: MOVE {rates['MOVE']:.0f}",
            "action": "æ³¨æ„æŠµæŠ¼å“ä»·å€¼æ³¢åŠ¨",
            "score": -1
        })
        score -= 1
    
    # è§„åˆ™6: æ”¶ç›Šç‡æ›²çº¿
    if rates['Inversion'] < -1.0:
        signals.append({
            "level": "WARNING",
            "category": "ç¾å€º",
            "msg": f"âš ï¸ æ·±åº¦å€’æŒ‚: 10Y-3M = {rates['Inversion']:.2f}%",
            "action": "ç»æµè¡°é€€å‰ç»æŒ‡æ ‡äº®ç¯",
            "score": -0.5
        })
        score -= 0.5
    
    # ========== æ—¥å…ƒå¥—åˆ©åˆ†æ ==========
    # è§„åˆ™7: USDJPY + VIX è”åŠ¨
    if rates.get('USDJPY_Chg', 0) < -2 and vol['VIX'] > 20:
        signals.append({
            "level": "CRITICAL",
            "category": "æ±‡ç‡",
            "msg": f"ğŸš¨ æ—¥å…ƒå¥—åˆ©å¹³ä»“: USDJPY æ€¥è·Œ + VIX {vol['VIX']:.1f}",
            "action": "å…¨çƒ Risk-Offï¼Œå‡æŒé£é™©èµ„äº§",
            "score": -2
        })
        score -= 2
    
    # ========== ææ…ŒæŒ‡æ ‡ ==========
    # è§„åˆ™8: VIX
    if vol['VIX'] > 30:
        signals.append({
            "level": "CRITICAL",
            "category": "ææ…Œ",
            "msg": f"ğŸš¨ VIX ææ…Œ: {vol['VIX']:.1f}",
            "action": "å¸‚åœºæåº¦ææ…Œï¼Œå¯èƒ½æ˜¯åå¼¹æœºä¼š",
            "score": -1  # ææ…Œæ—¶åè€Œå¯èƒ½è§åº•
        })
        score -= 1
    elif vol['VIX'] > 25:
        signals.append({
            "level": "WARNING",
            "category": "ææ…Œ",
            "msg": f"âš ï¸ VIX å‡é«˜: {vol['VIX']:.1f}",
            "action": "æ³¢åŠ¨åŠ å‰§ï¼Œæ§åˆ¶ä»“ä½",
            "score": -1
        })
        score -= 1
    elif vol['VIX'] < 12:
        signals.append({
            "level": "WARNING",
            "category": "ææ…Œ",
            "msg": f"âš ï¸ VIX è¿‡ä½: {vol['VIX']:.1f} (è‡ªæ»¡ä¿¡å·)",
            "action": "å¸‚åœºè¿‡äºä¹è§‚ï¼Œæ³¨æ„çªå‘é£é™©",
            "score": -0.5
        })
        score -= 0.5
    
    # è§„åˆ™9: å¸åœˆææ…Œè´ªå©ª
    if vol['Crypto_Val'] < 20:
        signals.append({
            "level": "POSITIVE",
            "category": "æƒ…ç»ª",
            "msg": f"âœ… å¸åœˆæåº¦ææ…Œ: {vol['Crypto_Val']} ({vol['Crypto_Text']})",
            "action": "åå‘æŒ‡æ ‡ï¼Œå¯èƒ½æ˜¯ä¹°å…¥æ—¶æœº",
            "score": 0.5
        })
        score += 0.5
    elif vol['Crypto_Val'] > 80:
        signals.append({
            "level": "WARNING",
            "category": "æƒ…ç»ª",
            "msg": f"âš ï¸ å¸åœˆæåº¦è´ªå©ª: {vol['Crypto_Val']} ({vol['Crypto_Text']})",
            "action": "è¿‡çƒ­ä¿¡å·ï¼Œè°¨æ…è¿½é«˜",
            "score": -0.5
        })
        score -= 0.5
    
    # ========== äº¤æ˜“ç»“æ„ ==========
    # è§„åˆ™10: Gamma ç¯å¢ƒ
    if "Negative" in deriv['GEX_Net'] or "Crash" in deriv['GEX_Net']:
        signals.append({
            "level": "WARNING",
            "category": "ç»“æ„",
            "msg": f"âš ï¸ è´Ÿ Gamma ç¯å¢ƒ: {deriv['GEX_Net']}",
            "action": "åšå¸‚å•†è¿½æ¶¨æ€è·Œï¼Œæ³¢åŠ¨æ”¾å¤§",
            "score": -1
        })
        score -= 1
    elif "Positive" in deriv['GEX_Net']:
        signals.append({
            "level": "POSITIVE",
            "category": "ç»“æ„",
            "msg": f"âœ… æ­£ Gamma ç¯å¢ƒ: {deriv['GEX_Net']}",
            "action": "åšå¸‚å•†é«˜æŠ›ä½å¸ï¼Œæ³¢åŠ¨æ”¶æ•›",
            "score": 1
        })
        score += 1
    
    # è§„åˆ™11: æœŸè´§åŸºå·®
    if "Backwardation" in deriv['Basis_Status']:
        signals.append({
            "level": "CRITICAL",
            "category": "ç»“æ„",
            "msg": f"ğŸš¨ æœŸè´§è´´æ°´: åŸºå·® {deriv['Futures_Basis']:.1f}",
            "action": "æåº¦ææ…Œæˆ–å¼ºçƒˆå¯¹å†²éœ€æ±‚",
            "score": -2
        })
        score -= 2
    
    # ========== ç¡®å®šå¸‚åœºçŠ¶æ€ ==========
    if score >= 3:
        regime = "risk_on"
    elif score <= -3:
        regime = "risk_off"
    else:
        regime = "neutral"
    
    return {
        "signals": signals,
        "regime": regime,
        "score": score
    }

# ============================================================
# 6. å®è§‚è¯„åˆ†è®¡ç®— (ä¿ç•™åŸæœ‰é€»è¾‘)
# ============================================================

def calculate_macro_score(ny_fed, fed_liq, credit, rates, vol, opt, deriv, news_score_val):
    score = 0; flags = []
    
    # æµåŠ¨æ€§
    liq_score = 0
    spread = ny_fed['SOFR'] - ny_fed['TGCR']
    if spread > 0.05: liq_score -= 1.0; flags.append("ğŸ”´ æµåŠ¨æ€§ç´§ç¼º (SOFR > Repo)")
    elif spread < 0.02: liq_score += 0.5
    if fed_liq['RRP_Chg'] > 20: liq_score -= 0.5; flags.append("ğŸ”´ RRP æŠ½æ°´")
    if fed_liq['TGA_Chg'] > 20: liq_score -= 0.5; flags.append("ğŸ”´ TGA æŠ½æ°´")
    if credit[1] < -0.5: liq_score -= 0.5; flags.append("ğŸ”´ HYG/LQD é¿é™©æ¨¡å¼ (Credit Stress)")
    elif credit[1] > 0.2: liq_score += 0.5
    score += max(-2.5, min(2.5, liq_score))
    
    # ç¾å€º
    bond_score = 0
    if rates['Yield_10Y'] > 4.5: bond_score -= 1.0; flags.append("ğŸ”´ 10Y æ”¶ç›Šç‡è¿‡é«˜ (>4.5%)")
    elif rates['Yield_10Y'] < 4.0: bond_score += 1.0
    if rates['MOVE'] > 110: bond_score -= 1.5; flags.append("ğŸ”´ MOVE å€ºå¸‚ææ…Œ")
    if rates['Inversion'] < -0.5: flags.append("âš ï¸ æ”¶ç›Šç‡æ·±åº¦å€’æŒ‚ (Recession Risk)")
    score += max(-2.5, min(2.5, bond_score))
    
    # ææ…Œ
    fear_score = 0
    if vol['VIX'] > 25: fear_score -= 1.0; flags.append("ğŸ”´ VIX ææ…Œæ¨¡å¼")
    elif vol['VIX'] < 13: fear_score -= 0.5; flags.append("âš ï¸ VIX è¿‡ä½ (è‡ªæ»¡)")
    if vol['Crypto_Val'] < 20: fear_score += 0.5; flags.append("ğŸŸ¢ å¸åœˆæåº¦ææ…Œ (åå‘åšå¤š)")
    score += fear_score
    
    # äº¤æ˜“
    trade_score = 0
    if opt['PCR'] > 1.2: trade_score -= 0.5; flags.append("ğŸ“‰ PCR æé«˜ (ç©ºå¤´æ‹¥æŒ¤)")
    elif opt['PCR'] < 0.6: trade_score += 0.5; flags.append("ğŸ“ˆ PCR æä½ (å¤šå¤´æ‹¥æŒ¤)")
    if deriv['Basis_Status'].startswith("ğŸ”´"): trade_score -= 1.0; flags.append("ğŸ”´ æœŸè´§è´´æ°´ (Hedging Demand)")
    if "Negative" in deriv['GEX_Net']: trade_score -= 0.5; flags.append("ğŸ”´ è´Ÿ Gamma (é«˜æ³¢åŠ¨é£é™©)")
    if "Headwind" in deriv['Vanna_Status']: flags.append("ğŸ”´ Vanna é˜»åŠ› (VIX Spike)")
    score += max(-2.0, min(2.0, trade_score))
    
    # æ–°é—»
    score += news_score_val * 1.5
    
    final_score = round(score * (10 / 7.5), 1)
    summary = ""
    action = ""
    if final_score > 3:
        summary = "å®è§‚ç¯å¢ƒ **åå¤š (Bullish)**ã€‚æµåŠ¨æ€§ç¯å¢ƒé…åˆï¼Œå¸‚åœºæƒ…ç»ªç¨³å®šã€‚"
        action = "âœ… **æ“ä½œå»ºè®®**: é€¢ä½åšå¤š (Buy Dips)ï¼Œä»¥ Call Wall ä¸ºç›®æ ‡ä½ã€‚"
    elif final_score < -3:
        summary = "å®è§‚ç¯å¢ƒ **åç©º (Bearish)**ã€‚æ£€æµ‹åˆ°æµåŠ¨æ€§å‹åŠ›æˆ–å¸‚åœºææ…ŒæŒ‡æ ‡å¼‚å¸¸ã€‚"
        action = "ğŸ›¡ï¸ **æ“ä½œå»ºè®®**: ç°é‡‘ä¸ºç‹ï¼Œåå¼¹åšç©º (Fade Rallies)ï¼Œå…³æ³¨ Put Wall æ”¯æ’‘ã€‚"
    else:
        summary = "å®è§‚ç¯å¢ƒ **ä¸­æ€§éœ‡è¡ (Neutral)**ã€‚å¤šç©ºä¿¡å·äº¤ç»‡ï¼Œç¼ºä¹æ˜ç¡®å®è§‚é©±åŠ¨ã€‚"
        action = "âš–ï¸ **æ“ä½œå»ºè®®**: åŒºé—´æ“ä½œ (Range Trade)ï¼Œé¿å…è¿½æ¶¨æ€è·Œï¼Œä»¥æ—¥å†…å¾®è§‚ç»“æ„ä¸ºä¸»ã€‚"
    if not flags: flags.append("æš‚æ— æ˜¾è‘—å¼‚å¸¸æŒ‡æ ‡")
    return final_score, flags, summary, action

# ============================================================
# 7. ç”Ÿæˆå¯¼å‡ºåˆ° Claude çš„æ–‡æœ¬
# ============================================================

def generate_claude_export(ny_fed, fed_liq, credit, rates, vol, opt, deriv, gex_data, regime_analysis, processed_news):
    """ç”Ÿæˆå¯å¤åˆ¶åˆ° Claude è¿›è¡Œæ·±åº¦åˆ†æçš„æ–‡æœ¬"""
    
    export_text = f"""# å®è§‚æˆ˜æƒ…å®¤æ•°æ®å¿«ç…§
ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} EST

## ä¸€ã€æµåŠ¨æ€§æŒ‡æ ‡
- SOFR: {ny_fed['SOFR']:.2f}%
- Repo (TGCR): {ny_fed['TGCR']:.2f}%
- SOFR-Repo åˆ©å·®: {(ny_fed['SOFR'] - ny_fed['TGCR']):.3f}%
- RRP: ${fed_liq['RRP']:.0f}B (æ—¥å˜åŒ–: {fed_liq['RRP_Chg']:.0f}B)
- TGA: ${fed_liq['TGA']:.0f}B (æ—¥å˜åŒ–: {fed_liq['TGA_Chg']:.0f}B)
- HYG/LQD: {credit[0]:.3f} (æ—¥å˜åŒ–: {credit[1]:.2f}%)

## äºŒã€ç¾å€ºä¸æ±‡ç‡
- 10Y æ”¶ç›Šç‡: {rates['Yield_10Y']:.2f}%
- 3M æ”¶ç›Šç‡: {rates['Yield_Short']:.2f}%
- 10Y-3M åˆ©å·®: {rates['Inversion']:.2f}%
- MOVE æŒ‡æ•°: {rates['MOVE']:.1f}
- DXY: {rates['DXY']:.2f}
- USDJPY: {rates['USDJPY']:.2f}

## ä¸‰ã€ææ…Œä¸æƒ…ç»ª
- VIX: {vol['VIX']:.2f}
- å¸åœˆææ…Œè´ªå©ª: {vol['Crypto_Val']} ({vol['Crypto_Text']})
- PCR: {opt['PCR']:.2f}

## å››ã€äº¤æ˜“å¾®è§‚ç»“æ„
- æœŸè´§åŸºå·®: {deriv['Futures_Basis']:.1f} ({deriv['Basis_Status']})
- Gamma ç¯å¢ƒ: {deriv['GEX_Net']}
- Vanna çŠ¶æ€: {deriv['Vanna_Status']}
- Put Wall: ${deriv['Put_Wall']:.0f}
- Call Wall: ${deriv['Call_Wall']:.0f}

## äº”ã€GEX åˆ†æ
- å½“å‰ä»·æ ¼: ${gex_data['spot_price']:.2f}
- å‡€ GEX: {gex_data['total_gex']:.2f}B
- Gamma Flip Point: ${gex_data['gamma_flip']:.2f}
- Max Pain: ${gex_data['max_pain']:.2f}
- GEX Put Wall: ${gex_data['put_wall']:.2f}
- GEX Call Wall: ${gex_data['call_wall']:.2f}

## å…­ã€è§„åˆ™å¼•æ“ä¿¡å·
å¸‚åœºçŠ¶æ€: {regime_analysis['regime'].upper()}
ç»¼åˆè¯„åˆ†: {regime_analysis['score']:.1f}

å…³é”®ä¿¡å·:
"""
    
    for sig in regime_analysis['signals']:
        export_text += f"- [{sig['level']}] {sig['msg']}\n"
    
    export_text += "\n## ä¸ƒã€é‡ç‚¹æ–°é—»\n"
    for item in processed_news[:10]:
        cats = ", ".join(item.get('Categories', ['general']))
        export_text += f"- [{cats}] {item['Title']} (é‡è¦æ€§: {item.get('Importance', 0)})\n"
    
    export_text += """
---
è¯·åŸºäºä»¥ä¸Šæ•°æ®è¿›è¡Œæ·±åº¦åˆ†æ:
1. å½“å‰å¸‚åœºå¤„äºä»€ä¹ˆå®è§‚å‘¨æœŸï¼Ÿ
2. æµåŠ¨æ€§ç¯å¢ƒå¯¹é£é™©èµ„äº§çš„å½±å“ï¼Ÿ
3. æœ‰å“ªäº›æ½œåœ¨çš„é£é™©ç‚¹ï¼Ÿ
4. ä»Šæ—¥äº¤æ˜“çš„æœ€ä½³ç­–ç•¥æ˜¯ä»€ä¹ˆï¼Ÿ
"""
    
    return export_text

# ============================================================
# 8. å†å²ç»Ÿè®¡ (ä¿ç•™åŸæœ‰)
# ============================================================

@st.cache_data(ttl=86400)
def get_qqq_historical_stats():
    res = {}
    try:
        df = yf.download("QQQ", period="3y", interval="1d", progress=False)
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        
        df['Range'] = df['High'] - df['Low']
        df['Body'] = df['Close'] - df['Open']
        df['Abs_Body'] = df['Body'].abs()
        df['Efficiency'] = df['Abs_Body'] / df['Range']
        
        conditions = [
            (df['Efficiency'] > 0.5) & (df['Body'] > 0),
            (df['Efficiency'] > 0.5) & (df['Body'] < 0),
            (df['Efficiency'] <= 0.5)
        ]
        choices = ['Trend_Up', 'Trend_Down', 'Choppy']
        df['Type'] = np.select(conditions, choices, default='Choppy')
        
        counts = df['Type'].value_counts()
        total_days = len(df)
        
        res['Up_Days'] = counts.get('Trend_Up', 0)
        res['Down_Days'] = counts.get('Trend_Down', 0)
        res['Chop_Days'] = counts.get('Choppy', 0)
        
        res['Up_Pct'] = round((res['Up_Days'] / total_days) * 100, 1)
        res['Down_Pct'] = round((res['Down_Days'] / total_days) * 100, 1)
        res['Chop_Pct'] = round((res['Chop_Days'] / total_days) * 100, 1)
        
        res['Avg_Range'] = df['Range'].mean()
        res['Avg_Range_Pct'] = (df['Range'] / df['Open']).mean() * 100
        
    except Exception as e: 
        pass
    return res

# ============================================================
# UI æ¸²æŸ“
# ============================================================

# æ•°æ®åŠ è½½
with st.spinner("æ­£åœ¨èšåˆå…¨å¸‚åœºæ•°æ®..."):
    ai_model = load_ai_model()
    ny_fed = get_ny_fed_data()
    fed_liq = get_fed_liquidity()
    credit = get_credit_spreads()
    rates = get_rates_and_fx()
    vol = get_volatility_indices()
    opt = get_qqq_options_data()
    deriv = get_derivatives_structure()
    tactics = get_intraday_tactics()
    
    # æ–°å¢æ•°æ®
    sofr_repo_hist = get_sofr_repo_history()
    rrp_tga_hist = get_rrp_tga_history()
    raw_news = get_multi_source_news()
    calendar_events = get_macro_calendar_with_countdown()
    gex_data = calculate_gex_profile()
    
    # æ–°é—»æƒ…ç»ªåˆ†æ
    processed_news = []
    sentiment_total = 0
    weighted_sentiment = 0
    total_weight = 0
    
    if not raw_news.empty:
        for i, row in raw_news.head(15).iterrows():
            try:
                res = ai_model(row['Title'][:512])[0]
                label = res['label']
                score = res['score']
                sent = "Neutral"; val = 0
                if label == 'positive' and score > 0.5: sent="Bullish"; val=1
                elif label == 'negative' and score > 0.5: sent="Bearish"; val=-1
                
                importance = row.get('Importance', 1)
                weighted_sentiment += val * importance
                total_weight += importance
                sentiment_total += val
                
                processed_news.append({
                    **row.to_dict(), 
                    "Sentiment": sent,
                    "SentimentScore": val
                })
            except: pass
        
        avg_news_score = sentiment_total / max(1, len(processed_news))
        weighted_news_score = weighted_sentiment / max(1, total_weight)
    else: 
        avg_news_score = 0
        weighted_news_score = 0
    
    # è§„åˆ™å¼•æ“åˆ†æ
    regime_analysis = analyze_market_regime(ny_fed, fed_liq, credit, rates, vol, opt, deriv, rrp_tga_hist)
    
    # åŸæœ‰è¯„åˆ†ç³»ç»Ÿ
    final_score, flags, summary, action = calculate_macro_score(ny_fed, fed_liq, credit, rates, vol, opt, deriv, avg_news_score)

# ============================================================
# HEADER
# ============================================================
st.title("ğŸ¦… QQQ å®è§‚æˆ˜æƒ…å®¤ Pro Max")
current_time = datetime.datetime.now(pytz.timezone('US/Eastern')).strftime('%Y-%m-%d %H:%M EST')
st.caption(f"Update: {current_time}")

# æˆ˜æƒ…ç»¼è¿°
summary_class = "summary-bull" if final_score > 3 else "summary-bear" if final_score < -3 else "summary-neutral"
regime_text = "ğŸŸ¢ Risk-On" if regime_analysis['regime'] == 'risk_on' else "ğŸ”´ Risk-Off" if regime_analysis['regime'] == 'risk_off' else "âšª Neutral"

st.markdown(f"""
<div class="summary-box {summary_class}">
    <h3>ğŸ›¡ï¸ æˆ˜æƒ…ç»¼è¿° (Score: {final_score}) | å¸‚åœºçŠ¶æ€: {regime_text}</h3>
    <p style="font-size:1.1em;">{summary}</p>
    <p><strong>ğŸš¨ å¼‚å¸¸æŒ‡æ ‡ç›‘æ§ (Flags):</strong> { '  |  '.join(flags) }</p>
    <hr style="border-top: 1px dashed #ccc;">
    <p style="font-weight:bold;">{action}</p>
</div>
""", unsafe_allow_html=True)

st.divider()

# ============================================================
# 1. æµåŠ¨æ€§ç›‘æ§ (å¸¦å›¾è¡¨)
# ============================================================
st.subheader("1. ğŸ’§ æµåŠ¨æ€§ç›‘æ§")

l1, l2, l3, l4, l5 = st.columns(5)
l1.metric("SOFR", f"{ny_fed['SOFR']:.2f}%", f"Spread: {ny_fed['SOFR'] - ny_fed['TGCR']:.3f}")
l2.metric("Repo (TGCR)", f"{ny_fed['TGCR']:.2f}%")
l3.metric("RRP", f"${fed_liq['RRP']:.0f}B", f"{fed_liq['RRP_Chg']:.0f}B", delta_color="inverse")
l4.metric("TGA", f"${fed_liq['TGA']:.0f}B", f"{fed_liq['TGA_Chg']:.0f}B", delta_color="inverse")
l5.metric("HYG/LQD", f"{credit[0]:.3f}", f"{credit[1]:.2f}%", help="é£é™©åå¥½æŒ‡æ ‡")

with st.expander("ğŸ“Š æµåŠ¨æ€§å†å²å›¾è¡¨ (30å¤©)", expanded=True):
    tab1, tab2 = st.tabs(["SOFR / Repo åˆ©å·®", "RRP / TGA"])
    
    with tab1:
        if sofr_repo_hist['dates']:
            fig = make_subplots(rows=2, cols=1, shared_xaxes=True, 
                               vertical_spacing=0.1,
                               subplot_titles=("SOFR vs Repo åˆ©ç‡", "SOFR-Repo åˆ©å·®"))
            
            fig.add_trace(go.Scatter(x=sofr_repo_hist['dates'], y=sofr_repo_hist['sofr'],
                                    name='SOFR', line=dict(color='#0d6efd', width=2)), row=1, col=1)
            fig.add_trace(go.Scatter(x=sofr_repo_hist['dates'], y=sofr_repo_hist['tgcr'],
                                    name='TGCR (Repo)', line=dict(color='#198754', width=2)), row=1, col=1)
            
            spread_colors = ['#dc3545' if s > 0.05 else '#ffc107' if s > 0.02 else '#198754' for s in sofr_repo_hist['spread']]
            fig.add_trace(go.Bar(x=sofr_repo_hist['dates'], y=sofr_repo_hist['spread'],
                                name='åˆ©å·®', marker_color=spread_colors), row=2, col=1)
            fig.add_hline(y=0.05, line_dash="dash", line_color="red", annotation_text="è­¦æˆ’çº¿", row=2, col=1)
            
            fig.update_layout(height=400, showlegend=True, legend=dict(orientation="h", yanchor="bottom", y=1.02))
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("SOFR/Repo å†å²æ•°æ®æš‚ä¸å¯ç”¨")
    
    with tab2:
        if rrp_tga_hist['dates']:
            fig2 = make_subplots(rows=2, cols=1, shared_xaxes=True,
                                vertical_spacing=0.1,
                                subplot_titles=("RRP (éš”å¤œé€†å›è´­)", "TGA (è´¢æ”¿éƒ¨è´¦æˆ·)"))
            
            fig2.add_trace(go.Scatter(x=rrp_tga_hist['dates'], y=rrp_tga_hist['rrp'],
                                     name='RRP', fill='tozeroy', line=dict(color='#6f42c1', width=2)), row=1, col=1)
            fig2.add_trace(go.Scatter(x=rrp_tga_hist['dates'], y=rrp_tga_hist['tga'],
                                     name='TGA', fill='tozeroy', line=dict(color='#fd7e14', width=2)), row=2, col=1)
            
            fig2.update_layout(height=400, showlegend=True, legend=dict(orientation="h", yanchor="bottom", y=1.02))
            st.plotly_chart(fig2, use_container_width=True)
        else:
            st.info("RRP/TGA å†å²æ•°æ®æš‚ä¸å¯ç”¨")

st.divider()

# ============================================================
# 2. ç¾å€ºä¸æ±‡ç‡
# ============================================================
st.subheader("2. ğŸ“ˆ ç¾å€ºä¸æ±‡ç‡")
r1, r2, r3, r4, r5 = st.columns(5)
r1.metric("10Y æ”¶ç›Šç‡", f"{rates['Yield_10Y']:.2f}%", help="å…¨çƒèµ„äº§å®šä»·ä¹‹é”š")
r2.metric("MOVE", f"{rates['MOVE']:.2f}", help="å€ºå¸‚ææ…ŒæŒ‡æ•°")
r3.metric("10Y/3M å€’æŒ‚", f"{rates['Inversion']:.2f}%", help="æ”¶ç›Šç‡æ›²çº¿")
r4.metric("DXY", f"{rates['DXY']:.2f}")
r5.metric("USDJPY", f"{rates['USDJPY']:.2f}")

st.divider()

# ============================================================
# 3. äº¤æ˜“ç»“æ„ + GEX Profile
# ============================================================
st.subheader("3. ğŸ¯ äº¤æ˜“ä¸å¾®è§‚ç»“æ„")

t1, t2, t3, t4 = st.columns(4)
t1.metric("PCR", f"{opt['PCR']}", help="Put/Call Ratio")
t2.metric("VIX", f"{vol['VIX']:.2f}")
t3.metric("å¸åœˆææ…Œ", f"{vol['Crypto_Val']}", f"{vol['Crypto_Text']}")
t4.metric("åŸºå·®", f"{deriv['Futures_Basis']:.2f}", deriv['Basis_Status'])

g1, g2, g3, g4 = st.columns(4)
g1.metric("Gamma", deriv['GEX_Net'])
g2.metric("Vanna", deriv['Vanna_Status'])
g3.metric("Put Wall", f"${deriv['Put_Wall']}")
g4.metric("Call Wall", f"${deriv['Call_Wall']}")

with st.expander("ğŸ“Š Gamma Exposure (GEX) Profile", expanded=True):
    # æ˜¾ç¤ºæ•°æ®æ—¶é—´æˆ³
    gex_time_col1, gex_time_col2, gex_time_col3 = st.columns(3)
    with gex_time_col1:
        st.caption(f"ğŸ“… OI æ•°æ®æ—¥æœŸ: **{gex_data.get('oi_date', 'N/A')}** ({gex_data.get('oi_weekday', '')})")
    with gex_time_col2:
        st.caption(f"â° è®¡ç®—æ—¶é—´: **{gex_data.get('calc_time', 'N/A')}**")
    with gex_time_col3:
        st.caption("ğŸ’¡ OI æ¯å¤©ç›˜å‰æ›´æ–°ï¼Œåæ˜ å‰ä¸€äº¤æ˜“æ—¥æ”¶ç›˜æŒä»“")
    
    if gex_data['strikes']:
        col_gex1, col_gex2 = st.columns([2, 1])
        
        with col_gex1:
            fig_gex = go.Figure()
            
            fig_gex.add_trace(go.Bar(
                x=gex_data['strikes'],
                y=gex_data['gex_call'],
                name='Call GEX',
                marker_color='#198754',
                opacity=0.7
            ))
            
            fig_gex.add_trace(go.Bar(
                x=gex_data['strikes'],
                y=gex_data['gex_put'],
                name='Put GEX',
                marker_color='#dc3545',
                opacity=0.7
            ))
            
            fig_gex.add_trace(go.Scatter(
                x=gex_data['strikes'],
                y=gex_data['gex_net'],
                name='Net GEX',
                line=dict(color='#0d6efd', width=3)
            ))
            
            fig_gex.add_vline(x=gex_data['spot_price'], line_dash="dash", line_color="yellow",
                             annotation_text=f"ç°ä»· ${gex_data['spot_price']:.2f}")
            
            if gex_data['gamma_flip'] > 0:
                fig_gex.add_vline(x=gex_data['gamma_flip'], line_dash="dot", line_color="orange",
                                 annotation_text=f"Gamma Flip ${gex_data['gamma_flip']:.0f}")
            
            fig_gex.update_layout(
                title="GEX Distribution by Strike",
                xaxis_title="Strike Price",
                yaxis_title="GEX (Billions $)",
                barmode='relative',
                height=400,
                legend=dict(orientation="h", yanchor="bottom", y=1.02)
            )
            
            st.plotly_chart(fig_gex, use_container_width=True)
        
        with col_gex2:
            st.markdown("#### ğŸ“ å…³é”®ä½ç½®")
            st.metric("å½“å‰ä»·æ ¼", f"${gex_data['spot_price']:.2f}")
            st.metric("å‡€ GEX", f"{gex_data['total_gex']:.2f}B", 
                     "æ­£ Gamma âœ…" if gex_data['total_gex'] > 0 else "è´Ÿ Gamma âš ï¸")
            st.metric("Gamma Flip", f"${gex_data['gamma_flip']:.2f}" if gex_data['gamma_flip'] > 0 else "N/A")
            st.metric("Max Pain", f"${gex_data['max_pain']:.2f}" if gex_data['max_pain'] > 0 else "N/A")
            st.metric("GEX Put Wall", f"${gex_data['put_wall']:.2f}" if gex_data['put_wall'] > 0 else "N/A")
            st.metric("GEX Call Wall", f"${gex_data['call_wall']:.2f}" if gex_data['call_wall'] > 0 else "N/A")
            
            st.markdown("---")
            st.markdown("**è§£è¯»:**")
            if gex_data['total_gex'] > 0:
                st.success("æ­£ Gamma: åšå¸‚å•†é«˜æŠ›ä½å¸ï¼Œæ³¢åŠ¨æ”¶æ•›")
            else:
                st.warning("è´Ÿ Gamma: åšå¸‚å•†è¿½æ¶¨æ€è·Œï¼Œæ³¢åŠ¨æ”¾å¤§")
    else:
        st.info("GEX æ•°æ®è®¡ç®—ä¸­...")

with st.expander("ğŸ“š æˆ˜æœ¯æ‰‹å†Œï¼šæŒ‡æ ‡æ·±åº¦è§£è¯»", expanded=False):
    st.markdown("""
    **1. HYG/LQD (ä¿¡è´·è„‰æ)**
    *   **å®šä¹‰**: é«˜æ”¶ç›Šå€º(Junk Bond)ä¸æŠ•èµ„çº§å€º(Corp Bond)çš„ä»·æ ¼æ¯”ç‡ã€‚
    *   **ç”¨æ³•**: å®ƒæ˜¯è‚¡å¸‚çš„å…ˆè¡ŒæŒ‡æ ‡ã€‚å¦‚æœ QQQ åœ¨æ¶¨ï¼Œä½† HYG/LQD åœ¨è·Œï¼ˆèƒŒç¦»ï¼‰ï¼Œè¯´æ˜èªæ˜çš„å€ºåˆ¸èµ„é‡‘æ­£åœ¨æ’¤é€€ã€‚

    **2. MOVE æŒ‡æ•° (å€ºå¸‚ VIX)**
    *   **å®šä¹‰**: è¡¡é‡ç¾å€ºæ”¶ç›Šç‡çš„æ³¢åŠ¨ç‡ã€‚
    *   **ç”¨æ³•**: MOVE æ˜¯é‡‘èç³»ç»Ÿçš„"åº•å±‚ä½“æ¸©"ã€‚å¦‚æœ MOVE é£™å‡ (>110)ï¼Œæ„å‘³ç€æŠµæŠ¼å“ä»·å€¼ä¸ç¨³å®šã€‚

    **3. GEX (Gamma Exposure)**
    *   **å®šä¹‰**: åšå¸‚å•†æŒæœ‰çš„ Gamma æ•å£æ€»é‡ã€‚
    *   **ç”¨æ³•**: æ­£ GEX = ä½æ³¢åŠ¨åŒºé—´éœ‡è¡; è´Ÿ GEX = é«˜æ³¢åŠ¨å•è¾¹è¡Œæƒ…ã€‚
    *   **Gamma Flip**: æ­£è´Ÿ Gamma ç¿»è½¬çš„ä»·æ ¼ç‚¹ï¼Œæ˜¯å…³é”®æ”¯æ’‘/é˜»åŠ›ã€‚

    **4. Vanna & Charm**
    *   **Vanna**: VIX ä¸‹è·Œæ—¶ï¼Œåšå¸‚å•†ä¹°å›å¯¹å†²ç›˜ï¼ŒåŠ©æ¶¨ (Vanna Rally)ã€‚
    *   **Charm**: æœŸæƒåˆ°æœŸæ—¥å‰ï¼Œä»·æ ¼è¢«å¸é™„åœ¨ä¸»åŠ›æŒä»“åŒºã€‚
    """)

with st.expander("æŸ¥çœ‹å¼‚åŠ¨é›·è¾¾", expanded=False):
    if opt['Unusual']: 
        st.dataframe(pd.DataFrame(opt['Unusual']), use_container_width=True)
    else: 
        st.info("æ— æ˜¾è‘—å¼‚åŠ¨")

st.divider()

# ============================================================
# 4. æ™ºèƒ½è§„åˆ™å¼•æ“åˆ†æ
# ============================================================
st.subheader("4. ğŸ§  æ™ºèƒ½è§„åˆ™å¼•æ“åˆ†æ")

signal_categories = {}
for sig in regime_analysis['signals']:
    cat = sig['category']
    if cat not in signal_categories:
        signal_categories[cat] = []
    signal_categories[cat].append(sig)

cols = st.columns(3)
col_idx = 0

for category, signals in signal_categories.items():
    with cols[col_idx % 3]:
        st.markdown(f"**{category}**")
        for sig in signals:
            if sig['level'] == 'CRITICAL':
                st.error(f"{sig['msg']}")
            elif sig['level'] == 'WARNING':
                st.warning(f"{sig['msg']}")
            elif sig['level'] == 'POSITIVE':
                st.success(f"{sig['msg']}")
            else:
                st.info(f"{sig['msg']}")
    col_idx += 1

st.markdown("---")
with st.expander("ğŸ¤– å¯¼å‡ºåˆ° Claude è¿›è¡Œæ·±åº¦åˆ†æ", expanded=False):
    export_text = generate_claude_export(ny_fed, fed_liq, credit, rates, vol, opt, deriv, gex_data, regime_analysis, processed_news)
    
    st.markdown("""
    <div class="export-box">
    <p>ğŸ“‹ ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¤åˆ¶æ‰€æœ‰æ•°æ®ï¼Œç„¶åç²˜è´´åˆ° Claude è¿›è¡Œæ·±åº¦åˆ†æ</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.text_area("æ•°æ®å¿«ç…§ (å¯å¤åˆ¶)", export_text, height=400)
    st.caption("ğŸ’¡ æç¤º: å…¨é€‰æ–‡æœ¬æ¡†å†…å®¹ (Ctrl+A)ï¼Œå¤åˆ¶ (Ctrl+C)ï¼Œç„¶åç²˜è´´åˆ° Claude å¯¹è¯ä¸­")

st.divider()

# ============================================================
# 5. å®è§‚æ–°é—» (å¤šæº + é‡è¦æ€§æ’åº)
# ============================================================
st.subheader("5. ğŸ“° å®è§‚æ–°é—» (å¤šæºèšåˆ)")

col_stat1, col_stat2, col_stat3 = st.columns(3)
col_stat1.metric("æ–°é—»æƒ…ç»ª", f"{avg_news_score:.2f}", "Bullish" if avg_news_score > 0.2 else "Bearish" if avg_news_score < -0.2 else "Neutral")
col_stat2.metric("åŠ æƒæƒ…ç»ª", f"{weighted_news_score:.2f}", help="æŒ‰é‡è¦æ€§åŠ æƒçš„æƒ…ç»ªåˆ†æ•°")
col_stat3.metric("æ–°é—»æ•°é‡", len(processed_news))

def get_category_tag(cat):
    tag_map = {
        'fed': ('<span class="category-tag tag-fed">Fed</span>', 'ğŸ›ï¸'),
        'boj': ('<span class="category-tag tag-boj">BOJ</span>', 'ğŸ‡¯ğŸ‡µ'),
        'ai': ('<span class="category-tag tag-ai">AI</span>', 'ğŸ¤–'),
        'mag7': ('<span class="category-tag tag-mag7">ä¸ƒå·¨å¤´</span>', 'ğŸ’'),
        'crypto': ('<span class="category-tag tag-crypto">Crypto</span>', 'â‚¿'),
        'macro': ('<span class="category-tag tag-macro">Macro</span>', 'ğŸ“Š'),
        'general': ('<span class="category-tag" style="background:#6c757d;color:white;">General</span>', 'ğŸ“°')
    }
    return tag_map.get(cat, tag_map['general'])

if processed_news:
    all_cats = set()
    for item in processed_news:
        all_cats.update(item.get('Categories', ['general']))
    
    selected_cat = st.selectbox("ç­›é€‰åˆ†ç±»", ["å…¨éƒ¨"] + sorted(list(all_cats)))
    
    for item in processed_news[:20]:
        cats = item.get('Categories', ['general'])
        
        if selected_cat != "å…¨éƒ¨" and selected_cat not in cats:
            continue
        
        importance = item.get('Importance', 0)
        sentiment = item.get('Sentiment', 'Neutral')
        
        if sentiment == "Bullish":
            css_class = "news-card news-bull"
        elif sentiment == "Bearish":
            css_class = "news-card news-bear"
        else:
            css_class = "news-card news-neutral"
        
        stars = "â­" * min(importance, 5)
        
        cat_tags = ""
        for cat in cats:
            tag_html, _ = get_category_tag(cat)
            cat_tags += tag_html
        
        st.markdown(f"""
        <div class="{css_class}">
            <div>{cat_tags} {stars}</div>
            <strong>[{sentiment}]</strong> <a href="{item['Link']}" target="_blank">{item['Title']}</a>
            <br><small>æ¥æº: {item['Source']}</small>
        </div>
        """, unsafe_allow_html=True)
else:
    st.write("æš‚æ— æ–°é—»")

st.divider()

# ============================================================
# 6. å®è§‚æ—¥å† (å¸¦å€’è®¡æ—¶)
# ============================================================
st.subheader("6. ğŸ“… å®è§‚æ—¥å†")

if calendar_events:
    urgent_events = [e for e in calendar_events if e['urgency'] == 'urgent']
    soon_events = [e for e in calendar_events if e['urgency'] == 'soon']
    normal_events = [e for e in calendar_events if e['urgency'] == 'normal']
    
    if urgent_events:
        st.markdown("### ğŸ”´ ç´§æ€¥å…³æ³¨")
        for evt in urgent_events:
            st.markdown(f"""
            <div class="calendar-urgent">
                <strong>{evt['countdown']}</strong> | {evt['date']} | {evt['event']}
                <span style="float:right;">{'â­' * evt['importance']}</span>
            </div>
            """, unsafe_allow_html=True)
    
    if soon_events:
        st.markdown("### ğŸŸ  è¿‘æœŸäº‹ä»¶")
        for evt in soon_events:
            st.markdown(f"""
            <div class="calendar-soon">
                <strong>{evt['countdown']}</strong> | {evt['date']} | {evt['event']}
                <span style="float:right;">{'â­' * evt['importance']}</span>
            </div>
            """, unsafe_allow_html=True)
    
    with st.expander(f"ğŸ“‹ æ›´å¤šäº‹ä»¶ ({len(normal_events)} ä¸ª)", expanded=False):
        for evt in normal_events:
            st.markdown(f"""
            <div class="calendar-normal">
                <strong>{evt['countdown']}</strong> | {evt['date']} | {evt['event']}
                <span style="float:right;">{'â­' * evt['importance']}</span>
            </div>
            """, unsafe_allow_html=True)
else:
    st.info("æš‚æ— æ—¥å†æ•°æ®")

st.divider()

# ============================================================
# 7. æ—¥å†…æˆ˜æœ¯
# ============================================================
st.subheader("7. âš”ï¸ æ—¥å†…æˆ˜æœ¯é¢æ¿")
st.caption(f"Snapshot: {tactics['Last_Update']}")

c_day1, c_day2, c_day3, c_day4 = st.columns(4)
c_day1.metric("VWAP", f"${tactics['VWAP']:.2f}", tactics['Trend'], delta_color="off")
c_day2.metric("é¢„æœŸæ³¢åŠ¨", f"Â±${tactics['Exp_Move']:.2f}")
c_day3.metric("0DTE æƒ…ç»ª", tactics['0DTE_Sentiment'])

vwap_val = tactics['VWAP']
delta_str = "N/A"
if vwap_val > 0:
    pct = ((tactics['Price'] - vwap_val) / vwap_val) * 100
    delta_str = f"{pct:.2f}% vs VWAP"

c_day4.metric("QQQ ç°ä»·", f"${tactics['Price']:.2f}", delta_str)

with st.expander("ğŸ¹ æ—¥å†…æŒ‡å—", expanded=True):
    st.write(f"ä¸Šè½¨: ${tactics['Upper_Band']:.2f} | ä¸‹è½¨: ${tactics['Lower_Band']:.2f}")
    st.write("ç­–ç•¥: ä»·æ ¼ > VWAP é€¢ä½å¤š; ä»·æ ¼ < VWAP é€¢é«˜ç©ºã€‚")

st.divider()

# ============================================================
# 8. å†å²ç»Ÿè®¡ (ä¿ç•™åŸæœ‰)
# ============================================================
st.subheader("8. ğŸ“Š ç­–ç•¥å›æµ‹ï¼šè¿‡å»3å¹´ QQQ Kçº¿å½¢æ€ç»Ÿè®¡")

with st.spinner("æ­£åœ¨å›æµ‹è¿‡å» 3 å¹´ K çº¿æ•°æ®..."):
    stats = get_qqq_historical_stats()

if stats:
    c_stat1, c_stat2 = st.columns([1, 2])
    
    with c_stat1:
        st.markdown("#### ğŸ“Š å¸‚åœºæ€§æ ¼ç”»åƒ")
        st.metric("éœ‡è¡/å‡å€¼å›å½’æ¦‚ç‡", f"{stats['Chop_Pct']}%", f"{stats['Chop_Days']} å¤©", delta_color="off")
        st.metric("å•è¾¹ä¸Šæ¶¨æ¦‚ç‡", f"{stats['Up_Pct']}%", f"{stats['Up_Days']} å¤©", delta_color="normal")
        st.metric("å•è¾¹ä¸‹è·Œæ¦‚ç‡", f"{stats['Down_Pct']}%", f"{stats['Down_Days']} å¤©", delta_color="inverse")
        
        st.info(f"ğŸ’¡ **æ—¥å†…å¹³å‡æ³¢å¹… (ATR)**: ${stats['Avg_Range']:.2f} ({stats['Avg_Range_Pct']:.2f}%)")

    with c_stat2:
        st.markdown("#### ğŸ§  é‡åŒ–äº¤æ˜“å¯ç¤ºå½•")
        
        if stats['Chop_Pct'] > 50:
            strategy = "ğŸ›¡ï¸ **é¦–é€‰ç­–ç•¥: å‡å€¼å›å½’ (Mean Reversion)**"
            details = """
            *   **ä¸è¦è¿½æ¶¨æ€è·Œ**: çªç ´ä¹°å…¥çš„èƒœç‡å¾ˆä½ã€‚
            *   **VWAP æˆ˜æ³•**: ä»·æ ¼åç¦» VWAP è¿‡è¿œæ—¶ï¼Œå¤§æ¦‚ç‡ä¼šå›å½’ã€‚
            *   **æœŸæƒ**: é€‚åˆå–æ–¹ç­–ç•¥ (Iron Condor) æˆ–åœ¨å…³é”®æ”¯æ’‘é˜»åŠ›ä½åšåè½¬ã€‚
            """
        else:
            strategy = "ğŸš€ **é¦–é€‰ç­–ç•¥: è¶‹åŠ¿è·Ÿéš (Trend Following)**"
            details = """
            *   **é¡ºåŠ¿è€Œä¸º**: çªç ´å…³é”®ç‚¹ä½åæœæ–­è¿½å•ã€‚
            *   **VWAP æˆ˜æ³•**: å›è¸© VWAP ä¸ç ´æ˜¯æœ€ä½³ä¸Šè½¦ç‚¹ã€‚
            *   **æœŸæƒ**: ä¹°å…¥ Call/Put èµŒå•è¾¹ã€‚
            """
            
        st.success(f"{strategy}")
        st.markdown(details)
        
        st.markdown("""
        ---
        **æ•°æ®è§£è¯»**:
        *   **éœ‡è¡æ—¥ (Choppy)**: æ”¶ç›˜ä»·å›æ’¤ï¼Œç•™æœ‰é•¿å½±çº¿ã€‚é€‚åˆ **é«˜æŠ›ä½å¸**ã€‚
        *   **è¶‹åŠ¿æ—¥ (Trend)**: æ”¶ç›˜ä»·åœ¨å…¨å¤©æœ€é«˜/æœ€ä½é™„è¿‘ã€‚é€‚åˆ **æŒæœ‰åˆ°æ”¶ç›˜**ã€‚
        *   **ç»Ÿè®¡ç»“è®º**: ç¾è‚¡å¤§éƒ¨åˆ†æ—¶é—´ (çº¦ 60%+) å¤„äºéœ‡è¡ä¸­ï¼Œå•è¾¹æš´è·Œæˆ–æš´æ¶¨å…¶å®æ˜¯å°‘æ•°ã€‚**æ—¥å†…äº¤æ˜“åˆ‡å¿Œé¢‘ç¹æ­¢æŸå»èµŒçªç ´ã€‚**
        """)

"""
ES/NQ æ—¥çº¿ç»“æ„ä½åˆ†æå™¨
æ ¹æ®Swing High/Lowç­›é€‰æ¡ä»¶è¯†åˆ«ä¸€çº§å’ŒäºŒçº§ç»“æ„ä½
è¾“å‡ºZoneåŒºé—´ä¾›æ—¥å†…äº¤æ˜“å‚è€ƒ
"""

import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# ============================================================================
# äº§å“é…ç½®
# ============================================================================
PRODUCT_CONFIG = {
    'ES': {
        'name': 'ES (E-mini S&P 500)',
        'default_atr': 20,
        'price_format': '#.00',
        'description': 'ESä»·æ ¼çº¦6000-7000ç‚¹ï¼ŒATRçº¦15-25ç‚¹'
    },
    'NQ': {
        'name': 'NQ (E-mini Nasdaq 100)',
        'default_atr': 80,
        'price_format': '#.00',
        'description': 'NQä»·æ ¼çº¦20000-22000ç‚¹ï¼ŒATRçº¦60-100ç‚¹'
    }
}

# ============================================================================
# æ ¸å¿ƒè®¡ç®—å‡½æ•°
# ============================================================================

def load_and_prepare_data(uploaded_file):
    """åŠ è½½å¹¶å‡†å¤‡æ•°æ®"""
    df = pd.read_csv(uploaded_file)
    
    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
    try:
        df['time'] = pd.to_datetime(df['time'], format='%Y/%m/%d')
    except:
        try:
            df['time'] = pd.to_datetime(df['time'], format='%Y-%m-%d')
        except:
            df['time'] = pd.to_datetime(df['time'])
    
    df = df.sort_values('time').reset_index(drop=True)
    
    # è®¡ç®—ATR(14)
    df['tr'] = np.maximum(
        df['high'] - df['low'],
        np.maximum(
            abs(df['high'] - df['close'].shift(1)),
            abs(df['low'] - df['close'].shift(1))
        )
    )
    df['atr'] = df['tr'].rolling(window=14).mean()
    
    # è®¡ç®—ATRå‡å€¼ï¼ˆç”¨äºåˆ¤æ–­ATRæ‰©å¼ ï¼‰
    df['atr_ma'] = df['atr'].rolling(window=20).mean()
    
    return df


def find_swing_candidates(df, left_bars=3):
    """
    æ‰¾å‡ºå€™é€‰Swingç‚¹
    Swing High: å½“æ—¥High > å‰left_barsæ—¥æ‰€æœ‰High
    Swing Low: å½“æ—¥Low < å‰left_barsæ—¥æ‰€æœ‰Low
    """
    swing_highs = []
    swing_lows = []
    
    for i in range(left_bars, len(df)):
        # æ£€æŸ¥Swing High
        current_high = df.iloc[i]['high']
        is_swing_high = True
        for j in range(1, left_bars + 1):
            if df.iloc[i - j]['high'] >= current_high:
                is_swing_high = False
                break
        if is_swing_high:
            swing_highs.append(i)
        
        # æ£€æŸ¥Swing Low
        current_low = df.iloc[i]['low']
        is_swing_low = True
        for j in range(1, left_bars + 1):
            if df.iloc[i - j]['low'] <= current_low:
                is_swing_low = False
                break
        if is_swing_low:
            swing_lows.append(i)
    
    return swing_highs, swing_lows


def validate_directional_extension(df, idx, is_high, lookforward=5, atr_multiplier=1.5):
    """
    æ¡ä»¶ä¸€ï¼šéªŒè¯æ–¹å‘æ€§å»¶ä¼¸
    - è‡³å°‘3-5æ ¹åŒæ–¹å‘Kçº¿
    - æ€»ç§»åŠ¨å¹…åº¦ >= 1.5 Ã— ATR
    - æœªè¢«å¿«é€Ÿå®Œå…¨åå‘åæ²¡
    """
    if idx + lookforward >= len(df):
        return False, 0
    
    atr = df.iloc[idx]['atr']
    if pd.isna(atr):
        return False, 0
    
    required_move = atr * atr_multiplier
    
    if is_high:
        # Swing Highååº”è¯¥å‘ä¸‹å»¶ä¼¸
        start_price = df.iloc[idx]['high']
        min_price = df.iloc[idx + 1: idx + lookforward + 1]['low'].min()
        move = start_price - min_price
        
        # æ£€æŸ¥æ˜¯å¦è¢«å¿«é€Ÿåæ²¡ï¼ˆåç»­Kçº¿æ²¡æœ‰ç«‹å³åˆ›æ–°é«˜ï¼‰
        max_high_after = df.iloc[idx + 1: idx + lookforward + 1]['high'].max()
        if max_high_after > start_price:
            return False, 0
    else:
        # Swing Lowååº”è¯¥å‘ä¸Šå»¶ä¼¸
        start_price = df.iloc[idx]['low']
        max_price = df.iloc[idx + 1: idx + lookforward + 1]['high'].max()
        move = max_price - start_price
        
        # æ£€æŸ¥æ˜¯å¦è¢«å¿«é€Ÿåæ²¡
        min_low_after = df.iloc[idx + 1: idx + lookforward + 1]['low'].min()
        if min_low_after < start_price:
            return False, 0
    
    return move >= required_move, move


def validate_structure_break(df, swing_highs, swing_lows, idx, is_high):
    """
    æ¡ä»¶äºŒï¼šæ‰“ç ´å‰ä¸€è½®ç»“æ„
    Swing Highæœ‰æ•ˆï¼šåç»­ä»·æ ¼çªç ´äº†å‰ä¸€ä¸ªLower High
    Swing Lowæœ‰æ•ˆï¼šåç»­ä»·æ ¼çªç ´äº†å‰ä¸€ä¸ªHigher Low
    """
    if is_high:
        prev_highs = [h for h in swing_highs if h < idx]
        if len(prev_highs) < 2:
            return True
        
        prev_high_idx = prev_highs[-1]
        prev_prev_high_idx = prev_highs[-2]
        
        current_high = df.iloc[idx]['high']
        prev_high = df.iloc[prev_high_idx]['high']
        prev_prev_high = df.iloc[prev_prev_high_idx]['high']
        
        if current_high > prev_high or (prev_high < prev_prev_high and current_high > prev_high):
            return True
    else:
        prev_lows = [l for l in swing_lows if l < idx]
        if len(prev_lows) < 2:
            return True
        
        prev_low_idx = prev_lows[-1]
        prev_prev_low_idx = prev_lows[-2]
        
        current_low = df.iloc[idx]['low']
        prev_low = df.iloc[prev_low_idx]['low']
        prev_prev_low = df.iloc[prev_prev_low_idx]['low']
        
        if current_low < prev_low or (prev_low > prev_prev_low and current_low < prev_low):
            return True
    
    return False


def check_volatility_expansion(df, idx):
    """
    æ¡ä»¶ä¸‰ï¼ˆåŠ åˆ†é¡¹ï¼‰ï¼šæ³¢åŠ¨ç‡æ‰©å¼ 
    å½“æ—¥ATR > 1.3 Ã— ATRå‡å€¼
    """
    atr = df.iloc[idx]['atr']
    atr_ma = df.iloc[idx]['atr_ma']
    
    if pd.isna(atr) or pd.isna(atr_ma):
        return False
    
    return atr > atr_ma * 1.3


def classify_structure_level(df, idx, is_high, move_size, has_volatility_expansion):
    """
    ç»“æ„åˆ†çº§
    ä¸€çº§ï¼šè¶‹åŠ¿èµ·ç‚¹/ç»ˆç‚¹/åè½¬ç‚¹ + æ³¢åŠ¨ç‡æ‰©å¼ 
    äºŒçº§ï¼šè¶‹åŠ¿ä¸­æ®µå›æ’¤ç‚¹
    """
    atr = df.iloc[idx]['atr']
    if pd.isna(atr):
        return 2
    
    if move_size > atr * 2 and has_volatility_expansion:
        return 1
    
    if move_size > atr * 2.5:
        return 1
    
    return 2


def calculate_zone(df, idx, is_high, zone_width_multiplier=0.3, default_atr=20):
    """
    è®¡ç®—ZoneåŒºé—´
    åŒºé—´å®½åº¦ = 0.2-0.4 Ã— ATR
    """
    atr = df.iloc[idx]['atr']
    if pd.isna(atr):
        atr = default_atr
    
    zone_width = atr * zone_width_multiplier
    
    if is_high:
        price = df.iloc[idx]['high']
        zone_top = price + zone_width / 2
        zone_bottom = price - zone_width / 2
    else:
        price = df.iloc[idx]['low']
        zone_top = price + zone_width / 2
        zone_bottom = price - zone_width / 2
    
    return zone_top, zone_bottom, price


def analyze_structures(df, default_atr=20, zone_width_multiplier=0.3):
    """
    ä¸»åˆ†æå‡½æ•°ï¼šè¯†åˆ«æ‰€æœ‰åˆæ ¼ç»“æ„ä½
    """
    swing_highs, swing_lows = find_swing_candidates(df, left_bars=3)
    
    structures = []
    
    # åˆ†æSwing Highs
    for idx in swing_highs:
        valid_extension, move_size = validate_directional_extension(df, idx, is_high=True)
        if not valid_extension:
            continue
        
        valid_break = validate_structure_break(df, swing_highs, swing_lows, idx, is_high=True)
        if not valid_break:
            continue
        
        has_vol_expansion = check_volatility_expansion(df, idx)
        level = classify_structure_level(df, idx, is_high=True, move_size=move_size, has_volatility_expansion=has_vol_expansion)
        zone_top, zone_bottom, price = calculate_zone(df, idx, is_high=True, zone_width_multiplier=zone_width_multiplier, default_atr=default_atr)
        
        structures.append({
            'date': df.iloc[idx]['time'],
            'type': 'resistance',
            'level': level,
            'price': price,
            'zone_top': zone_top,
            'zone_bottom': zone_bottom,
            'move_size': move_size,
            'vol_expansion': has_vol_expansion,
            'idx': idx
        })
    
    # åˆ†æSwing Lows
    for idx in swing_lows:
        valid_extension, move_size = validate_directional_extension(df, idx, is_high=False)
        if not valid_extension:
            continue
        
        valid_break = validate_structure_break(df, swing_highs, swing_lows, idx, is_high=False)
        if not valid_break:
            continue
        
        has_vol_expansion = check_volatility_expansion(df, idx)
        level = classify_structure_level(df, idx, is_high=False, move_size=move_size, has_volatility_expansion=has_vol_expansion)
        zone_top, zone_bottom, price = calculate_zone(df, idx, is_high=False, zone_width_multiplier=zone_width_multiplier, default_atr=default_atr)
        
        structures.append({
            'date': df.iloc[idx]['time'],
            'type': 'support',
            'level': level,
            'price': price,
            'zone_top': zone_top,
            'zone_bottom': zone_bottom,
            'move_size': move_size,
            'vol_expansion': has_vol_expansion,
            'idx': idx
        })
    
    return pd.DataFrame(structures)


def get_active_structures(structures_df, current_price):
    """
    è·å–å½“å‰ä»ç„¶æœ‰æ•ˆçš„ç»“æ„ä½
    """
    if structures_df.empty:
        return pd.DataFrame()
    
    active = []
    
    for _, row in structures_df.iterrows():
        if row['type'] == 'resistance':
            if current_price < row['zone_top']:
                active.append(row)
        else:
            if current_price > row['zone_bottom']:
                active.append(row)
    
    return pd.DataFrame(active)


def format_output(structures_df, current_price, product):
    """
    æ ¼å¼åŒ–è¾“å‡ºç»“æœ
    """
    if structures_df.empty:
        return "æœªæ‰¾åˆ°æœ‰æ•ˆç»“æ„ä½"
    
    resistances = structures_df[structures_df['type'] == 'resistance'].sort_values('price', ascending=True)
    supports = structures_df[structures_df['type'] == 'support'].sort_values('price', ascending=False)
    
    output_lines = []
    output_lines.append(f"{product} ç»“æ„ä½åˆ†æ")
    output_lines.append(f"å½“å‰ä»·æ ¼: {current_price:.2f}")
    output_lines.append("=" * 40)
    
    output_lines.append("\nğŸ“ˆ é˜»åŠ›ä½ (Resistance)")
    output_lines.append("-" * 40)
    
    r1_count = 0
    r2_count = 0
    for _, row in resistances.iterrows():
        level_str = "â˜…ä¸€çº§" if row['level'] == 1 else "äºŒçº§"
        vol_str = " [æ”¾é‡]" if row['vol_expansion'] else ""
        distance = row['price'] - current_price
        output_lines.append(
            f"{level_str}: {row['zone_bottom']:.2f} - {row['zone_top']:.2f} "
            f"(+{distance:.2f}ç‚¹){vol_str}"
        )
        if row['level'] == 1:
            r1_count += 1
        else:
            r2_count += 1
    
    output_lines.append("\nğŸ“‰ æ”¯æ’‘ä½ (Support)")
    output_lines.append("-" * 40)
    
    s1_count = 0
    s2_count = 0
    for _, row in supports.iterrows():
        level_str = "â˜…ä¸€çº§" if row['level'] == 1 else "äºŒçº§"
        vol_str = " [æ”¾é‡]" if row['vol_expansion'] else ""
        distance = current_price - row['price']
        output_lines.append(
            f"{level_str}: {row['zone_bottom']:.2f} - {row['zone_top']:.2f} "
            f"(-{distance:.2f}ç‚¹){vol_str}"
        )
        if row['level'] == 1:
            s1_count += 1
        else:
            s2_count += 1
    
    output_lines.append("\n" + "=" * 40)
    output_lines.append(f"ç»Ÿè®¡: ä¸€çº§é˜»åŠ›{r1_count}ä¸ª, äºŒçº§é˜»åŠ›{r2_count}ä¸ª, ä¸€çº§æ”¯æ’‘{s1_count}ä¸ª, äºŒçº§æ”¯æ’‘{s2_count}ä¸ª")
    
    return "\n".join(output_lines)


def create_chart(df, structures_df, current_price, product):
    """
    åˆ›å»ºKçº¿å›¾å¹¶æ ‡æ³¨ç»“æ„ä½
    """
    fig = make_subplots(rows=2, cols=1, shared_xaxes=True,
                        vertical_spacing=0.03,
                        row_heights=[0.7, 0.3])
    
    fig.add_trace(
        go.Candlestick(
            x=df['time'],
            open=df['open'],
            high=df['high'],
            low=df['low'],
            close=df['close'],
            name=product
        ),
        row=1, col=1
    )
    
    for _, row in structures_df.iterrows():
        color = 'rgba(255, 0, 0, 0.2)' if row['type'] == 'resistance' else 'rgba(0, 255, 0, 0.2)'
        border_color = 'red' if row['type'] == 'resistance' else 'green'
        line_width = 2 if row['level'] == 1 else 1
        
        fig.add_hrect(
            y0=row['zone_bottom'],
            y1=row['zone_top'],
            fillcolor=color,
            line=dict(color=border_color, width=line_width),
            row=1, col=1
        )
        
        level_str = "L1" if row['level'] == 1 else "L2"
        type_str = "R" if row['type'] == 'resistance' else "S"
        fig.add_annotation(
            x=df['time'].iloc[-1],
            y=row['price'],
            text=f"{type_str}{level_str}: {row['price']:.0f}",
            showarrow=False,
            xanchor='left',
            font=dict(size=10, color=border_color),
            row=1, col=1
        )
    
    fig.add_hline(y=current_price, line_dash="dash", line_color="blue",
                  annotation_text=f"å½“å‰: {current_price:.2f}", row=1, col=1)
    
    fig.add_trace(
        go.Scatter(x=df['time'], y=df['atr'], name='ATR(14)', line=dict(color='orange')),
        row=2, col=1
    )
    fig.add_trace(
        go.Scatter(x=df['time'], y=df['atr_ma'], name='ATR MA(20)', line=dict(color='gray', dash='dash')),
        row=2, col=1
    )
    
    fig.update_layout(
        title=f'{product} æ—¥çº¿ç»“æ„ä½åˆ†æ',
        xaxis_rangeslider_visible=False,
        height=800
    )
    
    return fig


# ============================================================================
# Streamlit ç•Œé¢
# ============================================================================


st.title("ğŸ“Š ES/NQ æ—¥çº¿ç»“æ„ä½åˆ†æå™¨")
st.markdown("""
åŸºäºSwing High/Lowè¯†åˆ«æœ‰æ•ˆç»“æ„ä½ï¼Œè¾“å‡ºZoneåŒºé—´ä¾›æ—¥å†…äº¤æ˜“å‚è€ƒã€‚

**ç­›é€‰æ¡ä»¶ï¼š**
1. æ–¹å‘æ€§å»¶ä¼¸ â‰¥ 1.5Ã— ATR
2. æ‰“ç ´å‰ä¸€è½®ç»“æ„å½¢æ€
3. æ³¢åŠ¨ç‡æ‰©å¼ ï¼ˆåŠ åˆ†é¡¹ï¼‰
""")

# ä¾§è¾¹æ 
st.sidebar.header("ğŸ“Œ é€‰æ‹©äº§å“")
product = st.sidebar.selectbox(
    "é€‰æ‹©åˆ†æçš„äº§å“",
    options=['ES', 'NQ'],
    format_func=lambda x: PRODUCT_CONFIG[x]['name']
)

st.sidebar.markdown(f"**{PRODUCT_CONFIG[product]['description']}**")

st.sidebar.header("âš™ï¸ å‚æ•°è®¾ç½®")
left_bars = st.sidebar.slider("Swingæ£€æµ‹å·¦ä¾§Kçº¿æ•°", 2, 5, 3)
lookforward = st.sidebar.slider("å»¶ä¼¸ç¡®è®¤Kçº¿æ•°", 3, 7, 5)
atr_multiplier = st.sidebar.slider("ATRå€æ•°é˜ˆå€¼", 1.0, 2.5, 1.5)
zone_width = st.sidebar.slider("Zoneå®½åº¦(ATRå€æ•°)", 0.2, 0.5, 0.3)

# è·å–äº§å“é…ç½®
config = PRODUCT_CONFIG[product]

# æ–‡ä»¶ä¸Šä¼ 
st.subheader(f"ğŸ“ ä¸Šä¼  {product} æ—¥çº¿æ•°æ®")
uploaded_file = st.file_uploader(f"ä¸Šä¼ {product}æ—¥çº¿CSVæ–‡ä»¶", type=['csv'])

if uploaded_file is not None:
    # åŠ è½½æ•°æ®
    df = load_and_prepare_data(uploaded_file)
    
    st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)}ä¸ªäº¤æ˜“æ—¥ ({df['time'].min().strftime('%Y-%m-%d')} è‡³ {df['time'].max().strftime('%Y-%m-%d')})")
    
    # å½“å‰ä»·æ ¼å’ŒATR
    current_price = df.iloc[-1]['close']
    current_atr = df.iloc[-1]['atr']
    
    st.info(f"ğŸ“Š **{product}** | å½“å‰ä»·æ ¼: {current_price:.2f} | ATR(14): {current_atr:.2f} ç‚¹ | Zoneå®½åº¦çº¦: {current_atr * zone_width:.2f} ç‚¹")
    
    # åˆ†æç»“æ„
    with st.spinner("æ­£åœ¨åˆ†æç»“æ„ä½..."):
        all_structures = analyze_structures(df, default_atr=config['default_atr'], zone_width_multiplier=zone_width)
        active_structures = get_active_structures(all_structures, current_price)
    
    # æ˜¾ç¤ºç»“æœ
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("ğŸ“‹ å½“å‰æœ‰æ•ˆç»“æ„ä½")
        output_text = format_output(active_structures, current_price, product)
        st.code(output_text, language=None)
        
        # TradingViewè¾“å…¥æ ¼å¼
        st.subheader("ğŸ“ TradingViewå¿«é€Ÿè¾“å…¥")
        if not active_structures.empty:
            tv_lines = []
            resistances = active_structures[active_structures['type'] == 'resistance'].sort_values('price')
            supports = active_structures[active_structures['type'] == 'support'].sort_values('price', ascending=False)
            
            for i, (_, row) in enumerate(resistances.head(2).iterrows()):
                tv_lines.append(f"R{i+1}_top = {row['zone_top']:.2f}")
                tv_lines.append(f"R{i+1}_bottom = {row['zone_bottom']:.2f}")
            
            for i, (_, row) in enumerate(supports.head(2).iterrows()):
                tv_lines.append(f"S{i+1}_top = {row['zone_top']:.2f}")
                tv_lines.append(f"S{i+1}_bottom = {row['zone_bottom']:.2f}")
            
            st.code("\n".join(tv_lines), language=None)
    
    with col2:
        st.subheader("ğŸ“ˆ Kçº¿å›¾")
        fig = create_chart(df, active_structures, current_price, product)
        st.plotly_chart(fig, use_container_width=True)
    
    # è¯¦ç»†æ•°æ®è¡¨
    with st.expander("æŸ¥çœ‹æ‰€æœ‰æ£€æµ‹åˆ°çš„ç»“æ„ä½"):
        if not all_structures.empty:
            display_df = all_structures.copy()
            display_df['date'] = display_df['date'].dt.strftime('%Y-%m-%d')
            display_df['level'] = display_df['level'].map({1: 'ä¸€çº§', 2: 'äºŒçº§'})
            display_df['type'] = display_df['type'].map({'resistance': 'é˜»åŠ›', 'support': 'æ”¯æ’‘'})
            display_df = display_df[['date', 'type', 'level', 'price', 'zone_top', 'zone_bottom', 'move_size', 'vol_expansion']]
            display_df.columns = ['æ—¥æœŸ', 'ç±»å‹', 'çº§åˆ«', 'ä»·æ ¼', 'Zoneä¸Šæ²¿', 'Zoneä¸‹æ²¿', 'å»¶ä¼¸å¹…åº¦', 'æ”¾é‡']
            st.dataframe(display_df, use_container_width=True)
        else:
            st.info("æœªæ£€æµ‹åˆ°ç¬¦åˆæ¡ä»¶çš„ç»“æ„ä½")

else:
    st.info(f"ğŸ‘† è¯·å…ˆåœ¨å·¦ä¾§é€‰æ‹©äº§å“ï¼ˆES/NQï¼‰ï¼Œç„¶åä¸Šä¼ å¯¹åº”çš„æ—¥çº¿CSVæ–‡ä»¶")
    
    st.markdown("""
    ### å¦‚ä½•å¯¼å‡ºæ•°æ®
    1. åœ¨TradingViewæ‰“å¼€å¯¹åº”äº§å“çš„æ—¥çº¿å›¾
       - ES: `ES1!` æˆ– `ESH2025`
       - NQ: `NQ1!` æˆ– `NQH2025`
    2. ç¡®ä¿æ—¶é—´æ¡†æ¶é€‰æ‹© **1D (æ—¥çº¿)**
    3. å›¾è¡¨å³ä¸Šè§’èœå• â†’ **Export chart data**
    4. ä¸‹è½½CSVæ–‡ä»¶å¹¶ä¸Šä¼ åˆ°è¿™é‡Œ
    
    ### CSVæ ¼å¼è¦æ±‚
    ```
    time,open,high,low,close,Volume
    2025/6/2,5898.75,5955.5,5867.5,5947.25,1194125
    ...
    ```
    
    ### ES vs NQ å‚è€ƒ
    | äº§å“ | ä»·æ ¼èŒƒå›´ | ATRèŒƒå›´ | Zoneå®½åº¦ |
    |------|----------|---------|----------|
    | ES | 6000-7000 | 15-25ç‚¹ | ~6ç‚¹ |
    | NQ | 20000-22000 | 60-100ç‚¹ | ~24ç‚¹ |
    """)


    
