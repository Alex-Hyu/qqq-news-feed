import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import requests
import datetime
from datetime import timedelta
import pytz
import feedparser
from io import StringIO
from transformers import pipeline
from streamlit_autorefresh import st_autorefresh

# --- 0. å…¨å±€é…ç½® ---
st.set_page_config(page_title="QQQ å®è§‚æˆ˜æƒ…å®¤ Pro", layout="wide", page_icon="ğŸ¦…")

st.markdown("""
    <style>
    .metric-card {background-color: #f9f9f9; border-radius: 5px; padding: 10px; border: 1px solid #e0e0e0;}
    .news-card {padding: 10px; margin-bottom: 5px; border-radius: 5px; border-left: 5px solid #ccc;}
    .news-bull {background-color: #e6fffa; border-left-color: #00c04b;}
    .news-bear {background-color: #fff5f5; border-left-color: #ff4b4b;}
    </style>
    """, unsafe_allow_html=True)

# --- [ä¾§è¾¹æ ] é…ç½® ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    av_api_key = st.text_input("AlphaVantage API Key", value="UMWB63OXOOCIZHXR", type="password")
    st.divider()
    st.subheader("ç³»ç»ŸçŠ¶æ€")
    count = st_autorefresh(interval=30 * 60 * 1000, key="data_refresher")
    st.caption(f"ğŸŸ¢ è‡ªåŠ¨åˆ·æ–°: å¼€å¯ (30åˆ†é’Ÿ)")
    if st.button("ğŸ”„ ç«‹å³åˆ·æ–°"):
        st.rerun()

# --- 1. æ ¸å¿ƒæ¨¡å‹ä¸æ•°æ®è·å– ---

@st.cache_resource
def load_ai_model():
    return pipeline("sentiment-analysis", model="ProsusAI/finbert")

# å®è§‚æ•°æ®
@st.cache_data(ttl=3600)
def get_ny_fed_data():
    try:
        url = "https://markets.newyorkfed.org/api/rates/all/latest.json"
        r = requests.get(url, timeout=5).json()
        rates = {'SOFR': 5.3, 'TGCR': 5.3} 
        for item in r.get('refRates', []):
            if item['type'] == 'SOFR': rates['SOFR'] = float(item['percentRate'])
            if item['type'] == 'TGCR': rates['TGCR'] = float(item['percentRate'])
        return rates
    except: return {'SOFR': 5.33, 'TGCR': 5.32}

# RRP/TGA
@st.cache_data(ttl=3600)
def get_fed_liquidity():
    res = {"RRP": 0, "RRP_Chg": 0, "TGA": 0, "TGA_Chg": 0}
    try:
        rrp_df = pd.read_csv("https://fred.stlouisfed.org/graph/fredgraph.csv?id=RRPONTSYD")
        res['RRP'] = rrp_df.iloc[-1]['RRPONTSYD']
        res['RRP_Chg'] = res['RRP'] - rrp_df.iloc[-2]['RRPONTSYD']
        tga_df = pd.read_csv("https://fred.stlouisfed.org/graph/fredgraph.csv?id=WTREGEN")
        res['TGA'] = tga_df.iloc[-1]['WTREGEN']
        res['TGA_Chg'] = res['TGA'] - tga_df.iloc[-2]['WTREGEN']
    except: pass
    return res

# å¸‚åœºæ•°æ®
@st.cache_data(ttl=1800)
def get_credit_spreads():
    try:
        data = yf.download(["HYG", "LQD"], period="5d", progress=False)['Close']
        if isinstance(data.columns, pd.MultiIndex): data.columns = data.columns.droplevel(0)
        ratio = data['HYG'] / data['LQD']
        curr = ratio.iloc[-1]
        pct = ((curr - ratio.iloc[-2]) / ratio.iloc[-2]) * 100
        return curr, pct
    except: return 0, 0

@st.cache_data(ttl=1800)
def get_rates_and_fx():
    tickers = ["^IRX", "^TNX", "^TYX", "DX-Y.NYB", "JPY=X", "^MOVE"] 
    res = {}
    try:
        df = yf.download(tickers, period="5d", progress=False)['Close']
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.droplevel(0)
        res['Yield_2Y'] = df.get('^IRX', pd.Series([5.2])).iloc[-1]
        res['Yield_10Y'] = df.get('^TNX', pd.Series([4.2])).iloc[-1]
        res['Yield_30Y'] = df.get('^TYX', pd.Series([4.4])).iloc[-1]
        res['DXY'] = df.get('DX-Y.NYB', pd.Series([104])).iloc[-1]
        res['USDJPY'] = df.get('JPY=X', pd.Series([150])).iloc[-1]
        res['MOVE'] = df.get('^MOVE', pd.Series([100.0])).iloc[-1]
        res['Inversion'] = res['Yield_10Y'] - res['Yield_2Y']
    except:
        res = {'Yield_2Y':5.0, 'Yield_10Y':4.2, 'Yield_30Y':4.3, 'DXY':104, 'USDJPY':150, 'MOVE':100, 'Inversion':-0.8}
    return res

@st.cache_data(ttl=1800)
def get_volatility_indices():
    data = {}
    try:
        vix = yf.Ticker("^VIX").history(period="2d")['Close'].iloc[-1]
        data['VIX'] = vix
    except: data['VIX'] = 15.0
    try:
        r = requests.get("https://api.alternative.me/fng/").json()
        data['Crypto_Val'] = int(r['data'][0]['value'])
        data['Crypto_Text'] = r['data'][0]['value_classification']
    except: 
        data['Crypto_Val'] = 50; data['Crypto_Text'] = "Unknown"
    return data

# --- [ä¿®å¤] Gamma Flip / Wall èšåˆç®—æ³• ---
@st.cache_data(ttl=1800)
def get_derivatives_structure():
    res = {
        "Futures_Basis": 0, "Basis_Status": "Normal", 
        "GEX_Net": "Neutral", "Call_Wall": 0, "Put_Wall": 0, 
        "Flip_Line": 0, "Current_Price": 0,
        "Vanna_Charm_Proxy": "Neutral",
        "Data_Note": ""
    }
    try:
        # 1. åŸºç¡€ä»·æ ¼
        market_data = yf.download(["NQ=F", "^NDX", "QQQ"], period="2d", progress=False)['Close']
        if isinstance(market_data.columns, pd.MultiIndex): market_data.columns = market_data.columns.droplevel(0)
        
        fut = market_data['NQ=F'].iloc[-1]
        spot = market_data['^NDX'].iloc[-1]
        qqq_price = market_data['QQQ'].iloc[-1]
        res['Current_Price'] = qqq_price
        
        basis = fut - spot
        res['Futures_Basis'] = basis
        if basis < -10: res['Basis_Status'] = "ğŸ”´ Backwardation"
        elif basis > 50: res['Basis_Status'] = "ğŸŸ¢ Contango"
        else: res['Basis_Status'] = "âšª Flat"
        
        # 2. [æ ¸å¿ƒä¿®å¤] èšåˆå¤šæœŸæƒé“¾è®¡ç®— Wall
        qqq = yf.Ticker("QQQ")
        # è·å–æœ€è¿‘çš„ 4 ä¸ªåˆ°æœŸæ—¥ (è¦†ç›–å‘¨æƒå’Œæœˆæƒ)
        expirations = qqq.options[:4] 
        
        all_calls = []
        all_puts = []
        
        for date in expirations:
            try:
                chain = qqq.option_chain(date)
                # å¿…é¡»æ¸…æ´—æ•°æ®: å¡«å…… NaN ä¸º 0
                c = chain.calls.fillna(0)
                p = chain.puts.fillna(0)
                all_calls.append(c[['strike', 'openInterest', 'volume']])
                all_puts.append(p[['strike', 'openInterest', 'volume']])
            except:
                continue
        
        if all_calls and all_puts:
            # åˆå¹¶æ•°æ®
            df_calls = pd.concat(all_calls)
            df_puts = pd.concat(all_puts)
            
            # æŒ‰ Strike èšåˆæ±‚å’Œ OI
            total_calls = df_calls.groupby('strike')['openInterest'].sum()
            total_puts = df_puts.groupby('strike')['openInterest'].sum()
            
            # æ‰¾åˆ°èšåˆåçš„æœ€å¤§æŒä»“ä½
            res['Call_Wall'] = total_calls.idxmax()
            res['Put_Wall'] = total_puts.idxmax()
            
            # 3. è®¡ç®— Flip Line
            # ç®—æ³•: Call OI - Put OI çš„å·®å€¼ (Net Gamma Proxy)
            # å¯¹é½ç´¢å¼•
            combined = pd.DataFrame({'Call_OI': total_calls, 'Put_OI': total_puts}).fillna(0)
            combined['Net_OI'] = combined['Call_OI'] - combined['Put_OI']
            
            # å¯»æ‰¾ç¬¦å·ç¿»è½¬ç‚¹ (ä»æ­£å˜è´Ÿçš„åœ°æ–¹)
            # æˆ–è€…å¯»æ‰¾ Net OI æœ€æ¥è¿‘ 0 çš„ç‚¹ (åœ¨ Put Wall å’Œ Call Wall ä¹‹é—´)
            # ç®€å•ç®—æ³•: å¯»æ‰¾ Put OI å¼€å§‹è¶…è¿‡ Call OI çš„å…³é”®ç‚¹
            flip_candidates = combined[combined['Net_OI'] < 0]
            if not flip_candidates.empty:
                # æ‰¾æœ€æ¥è¿‘ç°ä»·çš„ç¿»è½¬ç‚¹
                flip_strike = flip_candidates.index[0] # ç®€æ˜“å–ç¬¬ä¸€ä¸ª
                # ä¼˜åŒ–: åœ¨ç°ä»·é™„è¿‘æ‰¾
                near_price = flip_candidates.index[abs(flip_candidates.index - qqq_price).argmin()]
                res['Flip_Line'] = near_price
            else:
                res['Flip_Line'] = res['Put_Wall'] # å…œåº•
                
            # GEX çŠ¶æ€åˆ¤å®š
            if qqq_price < res['Flip_Line']: res['GEX_Net'] = "ğŸ”´ Negative (é«˜æ³¢)"
            else: res['GEX_Net'] = "ğŸŸ¢ Positive (ä½æ³¢)"
            
            res['Data_Note'] = f"èšåˆäº† {len(expirations)} ä¸ªåˆ°æœŸæ—¥"
            
        # Vanna
        if market_data['^NDX'].iloc[-1] > market_data['^NDX'].iloc[-2]:
            res['Vanna_Charm_Proxy'] = "Tailwind (åŠ©æ¶¨)"
        else: res['Vanna_Charm_Proxy'] = "Headwind (é˜»åŠ›)"

    except Exception as e: 
        res['Data_Note'] = "æ•°æ®è·å–å¤±è´¥"
        print(e)
    return res

# --- [ä¿®å¤] PCR è®¡ç®—ä¹Ÿæ”¹ä¸ºèšåˆæ¨¡å¼ ---
@st.cache_data(ttl=1800)
def get_qqq_options_data():
    qqq = yf.Ticker("QQQ")
    res = {"PCR": 0.0, "Unusual": []}
    try:
        # åŒæ ·èšåˆå‰ 4 ä¸ªåˆ°æœŸæ—¥ï¼Œæ ·æœ¬é‡æ›´å¤§æ›´å‡†
        expirations = qqq.options[:4]
        
        total_c_vol = 0
        total_p_vol = 0
        unusual = []
        
        for date in expirations:
            try:
                chain = qqq.option_chain(date)
                calls = chain.calls.fillna(0)
                puts = chain.puts.fillna(0)
                
                total_c_vol += calls['volume'].sum()
                total_p_vol += puts['volume'].sum()
                
                # å¼‚åŠ¨æ‰«æ (åªä¿ç•™çœŸæ­£çš„å¤§å•)
                for opt_type, df, icon in [("CALL", calls, "ğŸŸ¢"), ("PUT", puts, "ğŸ”´")]:
                    # æé«˜é˜ˆå€¼: æˆäº¤é‡ > 1000
                    hot = df[(df['volume'] > 1000) & (df['volume'] > df['openInterest'] * 1.5)]
                    for _, row in hot.iterrows():
                        unusual.append({
                            "Type": f"{icon} {opt_type}", 
                            "Strike": row['strike'],
                            "Exp": date, # åŠ ä¸Šæ—¥æœŸ
                            "Vol": int(row['volume']), 
                            "OI": int(row['openInterest']),
                            "Ratio": round(row['volume'] / (row['openInterest']+1), 1)
                        })
            except: continue
            
        if total_c_vol > 0: 
            res['PCR'] = round(total_p_vol / total_c_vol, 2)
            
        # æŒ‰æˆäº¤é‡æ’åºå–å‰ 15
        res['Unusual'] = sorted(unusual, key=lambda x: x['Vol'], reverse=True)[:15]
    except: pass
    return res

# æ—¥å† (Alpha Vantage)
@st.cache_data(ttl=3600)
def get_macro_calendar(api_key=""):
    if api_key:
        try:
            url = f"https://www.alphavantage.co/query?function=ECONOMIC_CALENDAR&apikey={api_key}"
            r = requests.get(url, timeout=5)
            df = pd.read_csv(StringIO(r.text))
            df = df[df['currency'] == 'USD']
            keywords = ["GDP", "Unemployment", "CPI", "Interest Rate", "Payroll", "FOMC", "PCE"]
            df['is_important'] = df['event'].apply(lambda x: any(k in x for k in keywords))
            df = df[df['is_important']]
            today = datetime.date.today().strftime("%Y-%m-%d")
            df = df[df['date'] >= today].sort_values('date').head(10)
            display_df = df[['date', 'time', 'event', 'estimate', 'previous']].copy()
            display_df.columns = ['Date', 'Time', 'Event', 'Est', 'Prev']
            if not display_df.empty: return display_df, "API Data"
        except: pass

    # å¤‡ç”¨
    today = datetime.date.today()
    events = []
    next_month = today.replace(day=28) + datetime.timedelta(days=4)
    next_cpi = today.replace(day=12) 
    if today.day > 12: next_cpi = (next_month - datetime.timedelta(days=1)).replace(day=12)
    events.append({"Date": next_cpi, "Event": "CPI (Est)", "Type": "Inflation"})
    
    events = sorted(events, key=lambda x: x['Date'])
    df = pd.DataFrame(events)
    df = df[df['Date'] >= today].head(5)
    d_df = df.copy()
    d_df['Time']="--"; d_df['Est']="--"; d_df['Prev']="--"
    return d_df[['Date','Time','Event','Est','Prev']], "Estimated"

@st.cache_data(ttl=1800)
def get_macro_news():
    feeds = [
        ("CNBC Economy", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=20910258"),
        ("MarketWatch", "http://feeds.marketwatch.com/marketwatch/topstories/")
    ]
    articles = []
    for src, url in feeds:
        try:
            f = feedparser.parse(url)
            for e in f.entries[:4]:
                articles.append({"Title": e.title, "Link": e.link, "Source": src})
        except: pass
    return pd.DataFrame(articles)

# --- 2. æ ¸å¿ƒç®—æ³• ---

def calculate_macro_score(ny_fed, fed_liq, credit, rates, vol, opt, deriv, news_score_val):
    score = 0
    details = []
    
    # æµåŠ¨æ€§ (25%)
    liq_score = 0
    spread = ny_fed['SOFR'] - ny_fed['TGCR']
    if spread > 0.05: liq_score -= 1.0; details.append("ğŸ”´ SOFR å¼‚å¸¸")
    elif spread < 0.02: liq_score += 0.5
    if fed_liq['RRP_Chg'] > 20: liq_score -= 0.5; details.append("ğŸ”´ RRP æŠ½æ°´")
    if fed_liq['TGA_Chg'] > 20: liq_score -= 0.5; details.append("ğŸ”´ TGA æŠ½æ°´")
    if credit[1] < -0.5: liq_score -= 0.5
    score += max(-2.5, min(2.5, liq_score))
    
    # ç¾å€º (25%)
    bond_score = 0
    if rates['Yield_10Y'] > 4.5: bond_score -= 1.0
    elif rates['Yield_10Y'] < 4.0: bond_score += 1.0
    if rates['MOVE'] > 110: bond_score -= 1.5
    score += max(-2.5, min(2.5, bond_score))
    
    # ææ…Œ (15%)
    fear_score = 0
    if vol['VIX'] > 25: fear_score -= 1.0
    elif vol['VIX'] < 13: fear_score -= 0.5
    if vol['Crypto_Val'] < 20: fear_score += 0.5
    score += fear_score
    
    # äº¤æ˜“ (20%)
    trade_score = 0
    if opt['PCR'] > 1.1: trade_score -= 0.5; details.append("ğŸ“‰ PCR åç©º")
    elif opt['PCR'] < 0.7: trade_score += 0.5
    if deriv['Basis_Status'].startswith("ğŸ”´"): trade_score -= 1.0; details.append("ğŸ”´ æœŸè´§è´´æ°´")
    if deriv['GEX_Net'].startswith("ğŸ”´"): trade_score -= 0.5; details.append("ğŸ”´ è·Œç ´ Gamma Flip")
    elif deriv['GEX_Net'].startswith("ğŸŸ¢"): trade_score += 0.5
    score += max(-2.0, min(2.0, trade_score))
    
    # æ–°é—» (15%)
    score += news_score_val * 1.5
    
    return round(score * (10 / 7.5), 1), details

# --- 3. UI ---

with st.spinner("æ­£åœ¨èšåˆå¤šæœŸæƒé“¾æ•°æ® (30åˆ†é’Ÿåˆ·æ–°)..."):
    ai_model = load_ai_model()
    ny_fed = get_ny_fed_data()
    fed_liq = get_fed_liquidity()
    credit = get_credit_spreads()
    rates = get_rates_and_fx()
    vol = get_volatility_indices()
    # æ ¸å¿ƒæ•°æ®æº
    opt = get_qqq_options_data()
    deriv = get_derivatives_structure()
    
    cal_df, cal_source = get_macro_calendar(av_api_key)
    raw_news = get_macro_news()

    processed_news = []
    sentiment_total = 0
    if not raw_news.empty:
        for i, row in raw_news.head(8).iterrows():
            try:
                res = ai_model(row['Title'][:512])[0]
                label = res['label']
                score = res['score']
                sent = "Neutral"; val = 0
                if label == 'positive' and score > 0.5: sent="Bullish"; val=1
                elif label == 'negative' and score > 0.5: sent="Bearish"; val=-1
                sentiment_total += val
                processed_news.append({**row, "Sentiment": sent})
            except: pass
        avg_news_score = sentiment_total / max(1, len(processed_news))
    else: avg_news_score = 0

    final_score, reasons = calculate_macro_score(ny_fed, fed_liq, credit, rates, vol, opt, deriv, avg_news_score)

# --- HEADER ---
st.title("ğŸ¦… QQQ å®è§‚æˆ˜æƒ…å®¤ Pro (Live)")
current_time = datetime.datetime.now(pytz.timezone('US/Eastern')).strftime('%Y-%m-%d %H:%M EST')
st.caption(f"ä¸Šæ¬¡æ›´æ–°: {current_time} | è‡ªåŠ¨åˆ·æ–°: å¼€å¯ (30åˆ†é’Ÿ)")

col_score, col_text = st.columns([1, 3])
with col_score:
    color = "red" if final_score < -3 else "green" if final_score > 3 else "gray"
    st.metric("å¤§ç›˜å¤šç©ºç»¼è¯„ (-10 ~ +10)", f"{final_score}", delta_color="off")
    if final_score > 3: st.success("### åå¤š (Bullish)")
    elif final_score < -3: st.error("### åç©º (Bearish)")
    else: st.info("### ä¸­æ€§éœ‡è¡ (Neutral)")

with col_text:
    st.markdown("#### ğŸ›¡ï¸ æˆ˜æƒ…ç»¼è¿°")
    st.write("é©±åŠ¨å› å­: " + " | ".join(reasons))
    if fed_liq['RRP_Chg'] > 100:
        st.warning("âš ï¸ ä¸¥é‡è­¦å‘Š: RRP æ¿€å¢ï¼Œå¸‚åœºæµåŠ¨æ€§æ­£åœ¨å¿«é€Ÿæ¯ç«­ï¼")

st.divider()

# 1. æµåŠ¨æ€§
st.subheader("1. æµåŠ¨æ€§ç›‘æ§ (Liquidity)")
l1, l2, l3, l4, l5 = st.columns(5)
l1.metric("SOFR", f"{ny_fed['SOFR']:.2f}%", f"Spread: {ny_fed['SOFR'] - ny_fed['TGCR']:.3f}")
l2.metric("Repo (TGCR)", f"{ny_fed['TGCR']:.2f}%")
l3.metric("RRP (é€†å›è´­)", f"${fed_liq['RRP']:.0f}B", f"{fed_liq['RRP_Chg']:.0f}B", delta_color="inverse")
l4.metric("TGA (è´¢æ”¿éƒ¨)", f"${fed_liq['TGA']:.0f}B", f"{fed_liq['TGA_Chg']:.0f}B", delta_color="inverse")
l5.metric("HYG/LQD", f"{credit[0]:.3f}", f"{credit[1]:.2f}%")

st.divider()

# 2. ç¾å€º
st.subheader("2. ç¾å€ºä¸æ±‡ç‡ (Rates & FX)")
r1, r2, r3, r4, r5 = st.columns(5)
r1.metric("10Y ç¾å€ºæ”¶ç›Šç‡", f"{rates['Yield_10Y']:.2f}%")
r2.metric("MOVE (å€ºå¸‚ææ…Œ)", f"{rates['MOVE']:.2f}")
r3.metric("2Y/10Y å€’æŒ‚", f"{rates['Inversion']:.2f}%")
r4.metric("ç¾å…ƒæŒ‡æ•° (DXY)", f"{rates['DXY']:.2f}")
r5.metric("ç¾å…ƒ/æ—¥å…ƒ", f"{rates['USDJPY']:.2f}")

st.divider()

# 3. äº¤æ˜“ä¸å¾®è§‚ç»“æ„ (èšåˆç‰ˆ)
st.subheader("3. äº¤æ˜“ä¸å¾®è§‚ç»“æ„ (Aggregated Options & GEX)")
st.caption(f"æ•°æ®è¯´æ˜: å·²èšåˆæœªæ¥ 4 ä¸ªåˆ°æœŸæ—¥ (åŒ…å«æœˆæƒ) çš„ OI æ•°æ®ï¼Œè§£å†³ 0DTE æ•°æ®ç¼ºå¤±é—®é¢˜ã€‚")

t1, t2, t3, t4 = st.columns(4)
t1.metric("QQQ æœŸæƒ PCR", f"{opt['PCR']}", "Put/Call Ratio")
t2.metric("VIX è‚¡å¸‚ææ…Œ", f"{vol['VIX']:.2f}")
t3.metric("å¸åœˆææ…ŒæŒ‡æ•°", f"{vol['Crypto_Val']}", f"{vol['Crypto_Text']}")
t4.metric("æœŸè´§åŸºå·® (Basis)", f"{deriv['Futures_Basis']:.2f}", deriv['Basis_Status'])

g1, g2, g3 = st.columns(3)
g1.metric("Gamma Flip Line (èšåˆè‡ªç®—)", f"${deriv['Flip_Line']:.2f}", deriv['GEX_Net'], delta_color="off")
g2.metric("Put Wall (å¼ºæ”¯æ’‘)", f"${deriv['Put_Wall']}", "Total OI Max")
g3.metric("Call Wall (å¼ºé˜»åŠ›)", f"${deriv['Call_Wall']}", "Total OI Max")

with st.expander("ğŸ“š äº¤æ˜“å‘˜å‚è€ƒæ‰‹å†Œï¼šå¦‚ä½•è§£è¯» PCR (OI)ï¼Ÿ", expanded=False):
    st.markdown("""
    #### 1. æ•°å€¼ > 1.2 (é«˜ä½ - æåº¦æ‚²è§‚)
    *   **ç›´è§‚æ„Ÿè§‰**: å¤§å®¶éƒ½çœ‹ç©ºã€‚åšå¸‚å•†æ‰‹é‡Œå…¨æ˜¯ Short Put (Long Delta)ã€‚
    *   **ğŸ›¡ï¸ æ“ä½œ**: åªè¦ QQQ æ²¡å´©ï¼Œæ„å‘³ç€åº•éƒ¨æ”¯æ’‘å¼ºã€‚åå¼¹æ—¶åšå¸‚å•†å¿…é¡»ä¹°å›å¯¹å†²ã€‚**åå‘åšå¤šä¿¡å·ã€‚**
    #### 2. æ•°å€¼ < 0.7 (ä½ä½ - æåº¦è´ªå©ª)
    *   **ç›´è§‚æ„Ÿè§‰**: å¤§å®¶éƒ½çœ‹å¤šã€‚åšå¸‚å•†æ‰‹é‡Œå…¨æ˜¯ Short Call (Short Delta)ã€‚
    *   **âš ï¸ æ“ä½œ**: ä¸Šæ¶¨åƒåŠ› (Call Wall é˜»åŠ›)ã€‚**åå‘åšç©º/æ­¢ç›ˆä¿¡å·ã€‚**
    """)

with st.expander("æŸ¥çœ‹ QQQ å¼‚åŠ¨é›·è¾¾ä¸ Vanna/Charm çŠ¶æ€", expanded=True):
    c_ex1, c_ex2 = st.columns([2, 1])
    with c_ex1:
        st.write("**âš¡ å¼‚åŠ¨é›·è¾¾ (Aggregated Volume > 1000)**")
        if opt['Unusual']: 
            st.dataframe(
                pd.DataFrame(opt['Unusual']), 
                column_config={"Exp": "åˆ°æœŸæ—¥"},
                use_container_width=True
            )
        else: st.info("ä»Šæ—¥æ— æ˜¾è‘—å¼‚åŠ¨ã€‚")
    with c_ex2:
        st.write("**Greek Flows (Proxy)**")
        st.info(f"ğŸ”® Vanna/Charm çŠ¶æ€: **{deriv['Vanna_Charm_Proxy']}**")
        st.caption("æ³¨: è‹¥VIXä¸‹è·Œï¼ŒDealerè§£å¥—Callï¼Œå½¢æˆVannaåŠ©æ¶¨ï¼›è‹¥VIXæš´æ¶¨åˆ™åä¹‹ã€‚")

st.divider()

# 4. æ–°é—»
st.subheader("4. å®è§‚æ–°é—»æƒ…æŠ¥ (AI Sentiment)")
col_news_list, col_news_stat = st.columns([3, 1])
with col_news_list:
    if processed_news:
        for item in processed_news:
            css_class = "news-card"
            icon = "âšª"
            if item['Sentiment'] == "Bullish": css_class += " news-bull"; icon = "ğŸŸ¢"
            elif item['Sentiment'] == "Bearish": css_class += " news-bear"; icon = "ğŸ”´"
            st.markdown(f"""<div class="{css_class}"><strong>{icon} {item['Sentiment']}</strong> | <a href="{item['Link']}" target="_blank">{item['Title']}</a><br><span style="font-size:0.8em;color:gray;">{item['Source']}</span></div>""", unsafe_allow_html=True)
    else: st.write("æš‚æ— æœ€æ–°æ–°é—»æ•°æ®ã€‚")
with col_news_stat:
    st.metric("æ–°é—»æƒ…ç»ªåˆ†", f"{avg_news_score:.2f}", "(-1 ç©º ~ 1 å¤š)")

st.divider()

# 5. æ—¥å†
st.subheader(f"5. å®è§‚æ—¥å† ({cal_source})")
c1, c2 = st.columns([3, 1])
with c1:
    if not cal_df.empty:
        st.dataframe(cal_df, hide_index=True, use_container_width=True)
    else: st.write("è¿‘æœŸæ— é‡è¦æ•°æ®ã€‚")

with c2:
    st.markdown("""
    **Fed è§‚å¯Ÿ**:
    - ğŸ¦… **é¹°æ´¾**: Waller
    - ğŸ•Šï¸ **é¸½æ´¾**: Goolsbee
    - âš–ï¸ **ä¸­æ€§**: Powell
    """)
