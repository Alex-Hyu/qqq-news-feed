import streamlit as st
import yfinance as yf
import pandas as pd
from transformers import pipeline
import datetime
import feedparser
import requests
import numpy as np

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="QQQ å®è§‚æµåŠ¨æ€§é›·è¾¾", layout="wide", page_icon="ğŸ¦…")

# --- ç¼“å­˜åŒº (æ¨¡å‹åŠ è½½) ---
@st.cache_resource
def load_sentiment_model():
    return pipeline("sentiment-analysis", model="ProsusAI/finbert")

# --- æ ¸å¿ƒåŠŸèƒ½ 1: è·å–æµåŠ¨æ€§æ•°æ® (çº½çº¦è”å‚¨ API) ---
@st.cache_data(ttl=3600) # 1å°æ—¶æ›´æ–°ä¸€æ¬¡
def get_liquidity_data():
    """
    ä»çº½çº¦è”å‚¨è·å–å®˜æ–¹ SOFR å’Œ TGCR (ä½œä¸º Repo ä»£è¡¨) æ•°æ®
    """
    try:
        # çº½çº¦è”å‚¨å®˜æ–¹å…¬å¼€ API
        url = "https://markets.newyorkfed.org/api/rates/all/latest.json"
        r = requests.get(url)
        data = r.json()
        
        rates = {}
        # è§£ææ•°æ®
        for item in data.get('refRates', []):
            if item['type'] == 'SOFR':
                rates['SOFR'] = float(item['percentRate'])
            if item['type'] == 'TGCR': # Tri-Party General Collateral Rate (Repo ä»£ç†)
                rates['TGCR'] = float(item['percentRate'])
                
        # å¦‚æœ API å¶å°”æŠ½é£ï¼Œç»™ä¸ªå…œåº•æ•°æ® (åŸºäºå½“å‰å¸‚åœºåˆ©ç‡)
        if 'SOFR' not in rates: rates['SOFR'] = 5.30
        if 'TGCR' not in rates: rates['TGCR'] = 5.30
            
        return rates
    except:
        return {'SOFR': 5.30, 'TGCR': 5.30}

# --- æ ¸å¿ƒåŠŸèƒ½ 2: è·å–ææ…Œè´ªå©ªæŒ‡æ•° ---
@st.cache_data(ttl=1800)
def get_fear_greed():
    indices = {}
    
    # 1. å¸åœˆææ…ŒæŒ‡æ•° (API)
    try:
        r = requests.get("https://api.alternative.me/fng/")
        data = r.json()
        indices['Crypto_Value'] = int(data['data'][0]['value'])
        indices['Crypto_Label'] = data['data'][0]['value_classification']
    except:
        indices['Crypto_Value'] = 50
        indices['Crypto_Label'] = "Unknown"

    # 2. è‚¡å¸‚ææ…ŒæŒ‡æ•° (ç”¨ VIX å’Œ åŠ¨é‡ æ¨¡æ‹Ÿ CNN æŒ‡æ•°ï¼Œå› ä¸º CNN åçˆ¬è™«ä¸¥é‡)
    try:
        market_data = yf.Ticker("^VIX")
        vix = market_data.history(period="1d")['Close'].iloc[-1]
        
        # ç®€å•æ˜ å°„ç®—æ³•: VIX è¶Šé«˜ï¼Œææ…Œè¶Šä¸¥é‡ (0-100, 100æ˜¯æåº¦è´ªå©ª)
        # VIX 12 = Greed (80), VIX 30 = Fear (20)
        stock_fng = max(0, min(100, 100 - (vix - 10) * 4)) 
        
        indices['Stock_Value'] = int(stock_fng)
        indices['VIX'] = vix
        
        if stock_fng > 75: indices['Stock_Label'] = "æåº¦è´ªå©ª (Extreme Greed)"
        elif stock_fng > 55: indices['Stock_Label'] = "è´ªå©ª (Greed)"
        elif stock_fng < 25: indices['Stock_Label'] = "æåº¦ææ…Œ (Extreme Fear)"
        elif stock_fng < 45: indices['Stock_Label'] = "ææ…Œ (Fear)"
        else: indices['Stock_Label'] = "ä¸­æ€§ (Neutral)"
        
    except:
        indices['Stock_Value'] = 50
        indices['Stock_Label'] = "Neutral"
        indices['VIX'] = 0
        
    return indices

# --- æ ¸å¿ƒåŠŸèƒ½ 3: ç»¼åˆæ–°é—»ä¸ä»·æ ¼ ---
@st.cache_data(ttl=300)
def get_market_news_and_price():
    # è·å–ä»·æ ¼
    tickers = ["QQQ", "^TNX"]
    prices = {}
    try:
        data = yf.download(tickers, period="2d", progress=False)['Close']
        # æ•°æ®æ¸…æ´—
        if isinstance(data.columns, pd.MultiIndex): data.columns = data.columns.droplevel(0)
        
        for t in tickers:
            try:
                prev = data[t].iloc[-2]
                curr = data[t].iloc[-1]
                prices[t] = ((curr - prev) / prev) * 100
            except: prices[t] = 0.0
    except:
        prices = {"QQQ": 0.0, "^TNX": 0.0}

    # è·å–æ–°é—»
    all_news = []
    
    # RSS æº
    feeds = [
        ("CNBC Economy", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=20910258"),
        ("MarketWatch", "http://feeds.marketwatch.com/marketwatch/topstories/"),
        ("WSJ Business", "https://feeds.a.dj.com/rss/WSJcomUSBusiness.xml")
    ]
    
    for name, url in feeds:
        try:
            f = feedparser.parse(url)
            for e in f.entries[:4]: # æ¯ä¸ªæºå–å‰4æ¡
                all_news.append({
                    "Title": e.title,
                    "Link": e.link,
                    "Source": name,
                    "Time": datetime.datetime.now()
                })
        except: pass
        
    return prices, pd.DataFrame(all_news)

# --- é€»è¾‘åˆ¤æ–­å¼•æ“ ---
def analyze_macro_context(sofr, tgcr, stock_fng, news_score):
    """
    ä¸Šå¸è§†è§’ç®—æ³•ï¼šç»“åˆæµåŠ¨æ€§ã€æƒ…ç»ªã€æ–°é—»ç»™å‡ºæœ€ç»ˆåˆ¤æ–­
    """
    # 1. æµåŠ¨æ€§åˆ¤æ–­
    # å½“å‰åŸºå‡†åˆ©ç‡çº¦ä¸º 5.3% (å‡è®¾). å¦‚æœ SOFR é£™å‡è¿œè¶… TGCRï¼Œè¯´æ˜é’±å¾ˆè´µ
    spread = sofr - tgcr
    liquidity_status = "ä¸­æ€§ (Neutral)"
    liquidity_score = 0 # -1 (ç´§), 0 (ä¸­), 1 (æ¾)
    
    if sofr > 5.40 or spread > 0.10: 
        liquidity_status = "ğŸ”´ ç´§å¼  (Tight/Stress)"
        liquidity_score = -1
    elif sofr < 5.20:
        liquidity_status = "ğŸŸ¢ å®½æ¾ (Loose)"
        liquidity_score = 1
    else:
        liquidity_status = "âšª å¹³ç¨³ (Stable)"
        liquidity_score = 0
        
    # 2. æœ€ç»ˆå®è§‚è¶‹åŠ¿åˆ¤æ–­
    # é€»è¾‘ï¼šæµåŠ¨æ€§ç´§å¼  = æ— è®ºæƒ…ç»ªå¦‚ä½•éƒ½åç©º
    # é€»è¾‘ï¼šæµåŠ¨æ€§å¹³ç¨³ + æåº¦ææ…Œ = æŠ„åº•æœºä¼š (Bullish)
    # é€»è¾‘ï¼šæµåŠ¨æ€§å¹³ç¨³ + æåº¦è´ªå©ª = è§é¡¶é£é™© (Bearish)
    
    verdict = "ä¸­æ€§éœ‡è¡ (Neutral)"
    verdict_color = "gray"
    explanation = "å¸‚åœºå¤„äºå¹³è¡¡çŠ¶æ€ï¼Œå…³æ³¨ç‰¹å®šä¸ªè‚¡æ–°é—»ã€‚"
    
    if liquidity_score == -1:
        verdict = "ç©ºå¤´è¶‹åŠ¿ (Bearish)"
        verdict_color = "red"
        explanation = "è­¦å‘Šï¼šæµåŠ¨æ€§å‡ºç°ç´§å¼ è¿¹è±¡ (SOFR/Repo å¼‚å¸¸)ã€‚æ­¤æ—¶åº”ç°é‡‘ä¸ºç‹ï¼Œé¿å…é«˜é£é™©èµ„äº§ã€‚"
    
    elif stock_fng < 20 and news_score > -0.5:
        verdict = "è¶…å–åå¼¹ (Rebound Long)"
        verdict_color = "green"
        explanation = "å¸‚åœºæåº¦ææ…Œï¼Œä½†åŸºæœ¬é¢æ–°é—»æœªå…¨é¢å´©ç›˜ï¼Œå­˜åœ¨åå¼¹æœºä¼šã€‚"
        
    elif stock_fng > 80:
        verdict = "è¿‡çƒ­é¢„è­¦ (Overheated)"
        verdict_color = "orange"
        explanation = "å¸‚åœºæåº¦è´ªå©ªï¼Œéšæ—¶å¯èƒ½å›è°ƒã€‚å»ºè®®æ­¢ç›ˆæˆ–å¯¹å†²ã€‚"
        
    elif news_score > 0.5 and liquidity_score >= 0:
        verdict = "å¤šå¤´è¶‹åŠ¿ (Bullish)"
        verdict_color = "green"
        explanation = "å®è§‚æ–°é—»å‘å¥½ï¼Œä¸”æµåŠ¨æ€§å……è£•ï¼Œåˆ©å¥½ QQQã€‚"
        
    return liquidity_status, verdict, verdict_color, explanation

# --- UI æ¸²æŸ“ ---
st.title("ğŸ¦… QQQ å®è§‚å…¨æ™¯é›·è¾¾")
st.markdown("é›†æˆ **SOFR æµåŠ¨æ€§** | **ææ…ŒæŒ‡æ•°** | **AI æ–°é—»åˆ†æ** çš„ä¸‰ä½ä¸€ä½“å†³ç­–ç³»ç»Ÿ")

with st.spinner("æ­£åœ¨è¿æ¥ç¾è”å‚¨ä¸å¸‚åœºæ•°æ®æº..."):
    liq_data = get_liquidity_data()
    fng_data = get_fear_greed()
    prices, df_news = get_market_news_and_price()
    sentiment_pipe = load_sentiment_model()

# --- ç¬¬ä¸€éƒ¨åˆ†ï¼šå®è§‚ä»ªè¡¨ç›˜ ---
st.subheader("1. å®è§‚ä»ªè¡¨ç›˜ (Macro Dashboard)")

col1, col2, col3, col4 = st.columns(4)

# SOFR å±•ç¤º
sofr_val = liq_data.get('SOFR', 0)
col1.metric("SOFR (èµ„é‡‘æˆæœ¬)", f"{sofr_val:.2f}%", "çº½çº¦è”å‚¨åŸºå‡†")

# GC Repo å±•ç¤º (ä½¿ç”¨ TGCR)
tgcr_val = liq_data.get('TGCR', 0)
col2.metric("Repo/TGCR (å›è´­åˆ©ç‡)", f"{tgcr_val:.2f}%", f"Spread: {sofr_val - tgcr_val:.2f}")

# è‚¡å¸‚æƒ…ç»ª
s_val = fng_data.get('Stock_Value', 50)
s_label = fng_data.get('Stock_Label', 'Neutral')
col3.metric("ç¾è‚¡æƒ…ç»ª", f"{s_val}/100", s_label, delta_color="off")

# å¸åœˆæƒ…ç»ª
c_val = fng_data.get('Crypto_Value', 50)
c_label = fng_data.get('Crypto_Label', 'Unknown')
col4.metric("åŠ å¯†è´§å¸æƒ…ç»ª", f"{c_val}/100", c_label, delta_color="off")

st.divider()

# --- ç¬¬äºŒéƒ¨åˆ†ï¼šAI æ–°é—»å¤„ç†ä¸æœ€ç»ˆåˆ¤æ–­ ---
st.subheader("2. æ™ºèƒ½ç ”åˆ¤ (Smart Verdict)")

# å¤„ç†æ–°é—»æƒ…ç»ª
bull_count = 0
bear_count = 0
news_score_agg = 0 # -1 åˆ° 1

if not df_news.empty:
    # åªå–å‰ 10 æ¡åˆ†æä»¥èŠ‚çœæ—¶é—´
    process_df = df_news.head(10).copy()
    results = []
    
    # è¿›åº¦æ¡
    bar = st.progress(0, "AI æ­£åœ¨é˜…è¯»æ–°é—»...")
    
    for i, row in process_df.iterrows():
        try:
            out = sentiment_pipe(row['Title'][:512])[0]
            label = out['label']
            
            # ç®€å•çš„ QQQ é€»è¾‘æ˜ å°„
            impact = "ä¸­æ€§"
            headline = row['Title'].lower()
            
            if label == 'positive': 
                impact = "åˆ©å¤š (Bullish)"
                bull_count += 1
                news_score_agg += 1
            elif label == 'negative': 
                impact = "åˆ©ç©º (Bearish)"
                bear_count += 1
                news_score_agg -= 1
                
            # ç‰¹æ®Šå…³é”®è¯è¦†ç›–
            if "inflation" in headline and "rise" in headline: 
                impact = "é‡å¤§åˆ©ç©º (Inflation)"
                bear_count += 1
            if "rate cut" in headline:
                impact = "é‡å¤§åˆ©å¤š (Rate Cut)"
                bull_count += 2
                
            results.append({**row, "AI_Signal": impact})
        except: pass
        bar.progress((i+1)/10)
    bar.empty()
    
    # å½’ä¸€åŒ–æ–°é—»åˆ†æ•°
    total_scanned = bull_count + bear_count + 1
    final_news_score = news_score_agg / total_scanned 
    
    # è°ƒç”¨æ ¸å¿ƒåˆ¤æ–­é€»è¾‘
    liq_status, final_verdict, v_color, reason = analyze_macro_context(
        sofr_val, tgcr_val, s_val, final_news_score
    )
    
    # å±•ç¤ºæœ€ç»ˆå¤§ç»“è®º
    c1, c2 = st.columns([1, 2])
    with c1:
        st.info(f"æµåŠ¨æ€§çŠ¶æ€: **{liq_status}**")
    with c2:
        if v_color == "red": st.error(f"å½“å‰è¶‹åŠ¿åˆ¤æ–­: **{final_verdict}**")
        elif v_color == "green": st.success(f"å½“å‰è¶‹åŠ¿åˆ¤æ–­: **{final_verdict}**")
        else: st.warning(f"å½“å‰è¶‹åŠ¿åˆ¤æ–­: **{final_verdict}**")
        
    st.caption(f"ğŸ” åˆ¤è¯: {reason}")

    # å±•ç¤ºæ–°é—»åˆ—è¡¨
    with st.expander("æŸ¥çœ‹è¯¦ç»†æ–°é—»æºåˆ†æ", expanded=True):
        res_df = pd.DataFrame(results)
        for i, row in res_df.iterrows():
            icon = "ğŸŸ¢" if "åˆ©å¤š" in row['AI_Signal'] else "ğŸ”´" if "åˆ©ç©º" in row['AI_Signal'] else "âšª"
            st.write(f"{icon} **{row['AI_Signal']}** | [{row['Title']}]({row['Link']})")
            st.caption(f"æ¥æº: {row['Source']}")
