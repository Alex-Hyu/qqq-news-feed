import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import requests
import datetime
from datetime import timedelta
import pytz
import feedparser
from io import StringIO
from transformers import pipeline
from streamlit_autorefresh import st_autorefresh
from scipy.stats import norm
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# --- 0. å…¨å±€é…ç½® ---
st.set_page_config(page_title="å®è§‚æˆ˜æƒ…è§‚å¯Ÿå®¤", layout="wide", page_icon="ğŸ¦…")

st.markdown("""
    <style>
    .metric-card {background-color: #f9f9f9; border-radius: 5px; padding: 10px; border: 1px solid #e0e0e0;}
    .news-card {padding: 10px; margin-bottom: 5px; border-radius: 5px; border-left: 5px solid #ccc;}
    .news-bull {background-color: #e6fffa; border-left-color: #00c04b;}
    .news-bear {background-color: #fff5f5; border-left-color: #ff4b4b;}
    .news-neutral {background-color: #f8f9fa; border-left-color: #6c757d;}
    .summary-box {padding: 15px; border-radius: 10px; margin-bottom: 20px;}
    .summary-bull {background-color: #d4edda; color: #155724; border: 1px solid #c3e6cb;}
    .summary-bear {background-color: #f8d7da; color: #721c24; border: 1px solid #f5c6cb;}
    .summary-neutral {background-color: #e2e3e5; color: #383d41; border: 1px solid #d6d8db;}
    .calendar-urgent {background-color: #fff3cd; border-left: 4px solid #ffc107; padding: 8px; margin: 4px 0; border-radius: 4px;}
    .calendar-soon {background-color: #e7f3ff; border-left: 4px solid #0d6efd; padding: 8px; margin: 4px 0; border-radius: 4px;}
    .calendar-normal {background-color: #f8f9fa; border-left: 4px solid #6c757d; padding: 8px; margin: 4px 0; border-radius: 4px;}
    .importance-5 {color: #dc3545; font-weight: bold;}
    .importance-4 {color: #fd7e14; font-weight: bold;}
    .importance-3 {color: #0d6efd;}
    .importance-2 {color: #6c757d;}
    .category-tag {display: inline-block; padding: 2px 8px; border-radius: 12px; font-size: 0.75em; margin-right: 5px;}
    .tag-fed {background-color: #dc3545; color: white;}
    .tag-boj {background-color: #fd7e14; color: white;}
    .tag-ai {background-color: #6f42c1; color: white;}
    .tag-mag7 {background-color: #0d6efd; color: white;}
    .tag-crypto {background-color: #ffc107; color: black;}
    .tag-macro {background-color: #198754; color: white;}
    .regime-box {padding: 15px; border-radius: 10px; margin: 10px 0;}
    .regime-risk-on {background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); border: 2px solid #28a745;}
    .regime-risk-off {background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%); border: 2px solid #dc3545;}
    .regime-neutral {background: linear-gradient(135deg, #e2e3e5 0%, #d6d8db 100%); border: 2px solid #6c757d;}
    .export-box {background-color: #f0f7ff; border: 1px dashed #0d6efd; padding: 15px; border-radius: 8px; margin: 10px 0;}
    </style>
    """, unsafe_allow_html=True)

# --- [ä¾§è¾¹æ ] ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    av_api_key = st.text_input("AlphaVantage API Key", value="UMWB63OXOOCIZHXR", type="password")
    
    st.divider()
    st.subheader("ğŸ”„ åˆ·æ–°æ§åˆ¶")
    
    # å…¨å±€åˆ·æ–° (æ‰€æœ‰æ•°æ®)
    if st.button("ğŸ”„ å…¨å±€åˆ·æ–° (æ‰€æœ‰æ•°æ®)", use_container_width=True):
        st.cache_data.clear()
        st.rerun()
    
    st.caption("âš ï¸ å…¨å±€åˆ·æ–°è¾ƒæ…¢ï¼Œå»ºè®®ä»…åœ¨å¼€ç›˜å‰ä½¿ç”¨")
    
    st.divider()
    
    # åˆ†ç±»åˆ·æ–°
    st.markdown("**æŒ‰éœ€åˆ·æ–°ï¼š**")
    
    col_ref1, col_ref2 = st.columns(2)
    with col_ref1:
        if st.button("ğŸ“Š GEX/æœŸæƒ", use_container_width=True, help="åˆ·æ–°æœŸæƒé“¾å’ŒGEXè®¡ç®—"):
            # æ¸…é™¤æœŸæƒç›¸å…³ç¼“å­˜
            calculate_gex_profile.clear()
            get_qqq_options_data.clear()
            get_derivatives_structure.clear()
            st.rerun()
    
    with col_ref2:
        if st.button("ğŸ“ˆ æ—¥å†…æ•°æ®", use_container_width=True, help="åˆ·æ–°VWAPå’Œç›˜ä¸­æ•°æ®"):
            get_intraday_tactics.clear()
            st.rerun()
    
    col_ref3, col_ref4 = st.columns(2)
    with col_ref3:
        if st.button("ğŸ“° æ–°é—»", use_container_width=True, help="åˆ·æ–°æ–°é—»å’Œæƒ…ç»ªåˆ†æ"):
            get_multi_source_news.clear()
            st.rerun()
    
    with col_ref4:
        if st.button("ğŸ’§ æµåŠ¨æ€§", use_container_width=True, help="åˆ·æ–°SOFR/RRP/TGA"):
            get_sofr_repo_history.clear()
            get_rrp_tga_history.clear()
            get_ny_fed_data.clear()
            get_fed_liquidity.clear()
            st.rerun()
    
    st.divider()
    st.subheader("ğŸ“‹ ç¼“å­˜ç­–ç•¥")
    st.caption("""
    â€¢ æµåŠ¨æ€§/å®è§‚: 4å°æ—¶  
    â€¢ ç¾å€º/æ±‡ç‡: 2å°æ—¶  
    â€¢ æ–°é—»: 2å°æ—¶  
    â€¢ æœŸæƒ/GEX: 1å°æ—¶  
    â€¢ æ—¥å†…VWAP: 5åˆ†é’Ÿ
    """)

# ============================================================
# 1. æ ¸å¿ƒæ•°æ®è·å–å‡½æ•°
# ============================================================

@st.cache_resource
def load_ai_model():
    return pipeline("sentiment-analysis", model="ProsusAI/finbert")

# --- SOFR/Repo å†å²æ•°æ® (30å¤©) ---
@st.cache_data(ttl=14400)  # 4å°æ—¶ç¼“å­˜ (å®è§‚æ•°æ®å˜åŒ–æ…¢)
def get_sofr_repo_history():
    """è·å– SOFR å’Œ Repo åˆ©ç‡çš„30å¤©å†å²æ•°æ®"""
    result = {
        'dates': [],
        'sofr': [],
        'tgcr': [],
        'spread': [],
        'current_sofr': 5.33,
        'current_tgcr': 5.32
    }
    try:
        # NY Fed API for historical rates
        end_date = datetime.date.today()
        start_date = end_date - timedelta(days=45)  # å¤šå–ä¸€äº›ç¡®ä¿æœ‰30ä¸ªäº¤æ˜“æ—¥
        
        url = f"https://markets.newyorkfed.org/api/rates/secured/sofr/search.json?startDate={start_date}&endDate={end_date}"
        r = requests.get(url, timeout=10)
        if r.status_code == 200:
            data = r.json()
            sofr_data = {}
            for item in data.get('refRates', []):
                date = item.get('effectiveDate', '')
                rate = item.get('percentRate', 0)
                sofr_data[date] = float(rate)
        
        # TGCR (Tri-Party General Collateral Rate)
        url_tgcr = f"https://markets.newyorkfed.org/api/rates/secured/tgcr/search.json?startDate={start_date}&endDate={end_date}"
        r2 = requests.get(url_tgcr, timeout=10)
        tgcr_data = {}
        if r2.status_code == 200:
            data2 = r2.json()
            for item in data2.get('refRates', []):
                date = item.get('effectiveDate', '')
                rate = item.get('percentRate', 0)
                tgcr_data[date] = float(rate)
        
        # åˆå¹¶æ•°æ®
        all_dates = sorted(set(sofr_data.keys()) & set(tgcr_data.keys()))[-30:]
        for date in all_dates:
            result['dates'].append(date)
            result['sofr'].append(sofr_data.get(date, 0))
            result['tgcr'].append(tgcr_data.get(date, 0))
            result['spread'].append(sofr_data.get(date, 0) - tgcr_data.get(date, 0))
        
        if result['sofr']:
            result['current_sofr'] = result['sofr'][-1]
            result['current_tgcr'] = result['tgcr'][-1]
            
    except Exception as e:
        st.warning(f"SOFR/Repo å†å²æ•°æ®è·å–å¤±è´¥: {e}")
    
    return result

# --- RRP/TGA å†å²æ•°æ® (30å¤©) ---
@st.cache_data(ttl=14400)  # 4å°æ—¶ç¼“å­˜ (æ¯å¤©æ›´æ–°ä¸€æ¬¡çš„æ•°æ®)
def get_rrp_tga_history():
    """è·å– RRP å’Œ TGA çš„30å¤©å†å²æ•°æ®"""
    result = {
        'dates': [],
        'rrp': [],
        'tga': [],
        'current_rrp': 0,
        'current_tga': 0,
        'rrp_chg': 0,
        'tga_chg': 0
    }
    try:
        # RRP (Overnight Reverse Repo)
        rrp_url = "https://fred.stlouisfed.org/graph/fredgraph.csv?id=RRPONTSYD"
        rrp_df = pd.read_csv(rrp_url)
        
        # è‡ªåŠ¨æ£€æµ‹æ—¥æœŸåˆ—å (å¯èƒ½æ˜¯ 'DATE' æˆ– 'date' æˆ–ç¬¬ä¸€åˆ—)
        date_col = None
        for col in rrp_df.columns:
            if col.upper() == 'DATE' or 'date' in col.lower():
                date_col = col
                break
        if date_col is None:
            date_col = rrp_df.columns[0]  # ä½¿ç”¨ç¬¬ä¸€åˆ—ä½œä¸ºæ—¥æœŸ
        
        # æ•°æ®åˆ—
        rrp_col = 'RRPONTSYD' if 'RRPONTSYD' in rrp_df.columns else rrp_df.columns[1]
        
        rrp_df = rrp_df.dropna().tail(35)
        rrp_df[date_col] = pd.to_datetime(rrp_df[date_col])
        
        # TGA (Treasury General Account)
        tga_url = "https://fred.stlouisfed.org/graph/fredgraph.csv?id=WTREGEN"
        tga_df = pd.read_csv(tga_url)
        
        # è‡ªåŠ¨æ£€æµ‹ TGA åˆ—å
        tga_date_col = None
        for col in tga_df.columns:
            if col.upper() == 'DATE' or 'date' in col.lower():
                tga_date_col = col
                break
        if tga_date_col is None:
            tga_date_col = tga_df.columns[0]
        
        tga_col = 'WTREGEN' if 'WTREGEN' in tga_df.columns else tga_df.columns[1]
        
        tga_df = tga_df.dropna().tail(35)
        tga_df[tga_date_col] = pd.to_datetime(tga_df[tga_date_col])
        
        # å–æœ€è¿‘30å¤©
        result['dates'] = rrp_df[date_col].dt.strftime('%Y-%m-%d').tolist()[-30:]
        result['rrp'] = rrp_df[rrp_col].tolist()[-30:]
        
        # TGA æ˜¯å‘¨åº¦æ•°æ®ï¼Œéœ€è¦å¯¹é½ (ä½¿ç”¨å‰å‘å¡«å……)
        tga_dict = dict(zip(tga_df[tga_date_col].dt.strftime('%Y-%m-%d'), tga_df[tga_col]))
        result['tga'] = []
        last_tga = list(tga_dict.values())[-1] if tga_dict else 0
        for d in result['dates']:
            if d in tga_dict:
                last_tga = tga_dict[d]
            result['tga'].append(last_tga)
        
        if result['rrp']:
            result['current_rrp'] = result['rrp'][-1]
            result['rrp_chg'] = result['rrp'][-1] - result['rrp'][-2] if len(result['rrp']) > 1 else 0
        if result['tga']:
            result['current_tga'] = result['tga'][-1]
            result['tga_chg'] = result['tga'][-1] - result['tga'][-2] if len(result['tga']) > 1 else 0
            
    except Exception as e:
        # é™é»˜å¤±è´¥ï¼Œä¸æ˜¾ç¤ºè­¦å‘Šï¼Œè¿”å›ç©ºç»“æœ
        pass
    
    return result

@st.cache_data(ttl=14400)  # 4å°æ—¶ç¼“å­˜
def get_ny_fed_data():
    try:
        url = "https://markets.newyorkfed.org/api/rates/all/latest.json"
        r = requests.get(url, timeout=5).json()
        rates = {'SOFR': 5.3, 'TGCR': 5.3} 
        for item in r.get('refRates', []):
            if item['type'] == 'SOFR': rates['SOFR'] = float(item['percentRate'])
            if item['type'] == 'TGCR': rates['TGCR'] = float(item['percentRate'])
        return rates
    except: return {'SOFR': 5.33, 'TGCR': 5.32}

@st.cache_data(ttl=14400)  # 4å°æ—¶ç¼“å­˜
def get_fed_liquidity():
    res = {"RRP": 0, "RRP_Chg": 0, "TGA": 0, "TGA_Chg": 0}
    try:
        rrp_df = pd.read_csv("https://fred.stlouisfed.org/graph/fredgraph.csv?id=RRPONTSYD")
        res['RRP'] = rrp_df.iloc[-1]['RRPONTSYD']
        res['RRP_Chg'] = res['RRP'] - rrp_df.iloc[-2]['RRPONTSYD']
        tga_df = pd.read_csv("https://fred.stlouisfed.org/graph/fredgraph.csv?id=WTREGEN")
        res['TGA'] = tga_df.iloc[-1]['WTREGEN']
        res['TGA_Chg'] = res['TGA'] - tga_df.iloc[-2]['WTREGEN']
    except: pass
    return res

@st.cache_data(ttl=7200)  # 2å°æ—¶ç¼“å­˜
def get_credit_spreads():
    try:
        data = yf.download(["HYG", "LQD"], period="5d", progress=False)['Close']
        if isinstance(data.columns, pd.MultiIndex): data.columns = data.columns.get_level_values(0)
        ratio = data['HYG'] / data['LQD']
        curr = ratio.iloc[-1]
        pct = ((curr - ratio.iloc[-2]) / ratio.iloc[-2]) * 100
        return curr, pct
    except: return 0, 0

@st.cache_data(ttl=7200)  # 2å°æ—¶ç¼“å­˜
def get_rates_and_fx():
    tickers = ["^IRX", "^TNX", "DX-Y.NYB", "JPY=X", "^MOVE"] 
    res = {'Yield_Short': 0, 'Yield_10Y': 0, 'Inversion': 0, 'DXY': 0, 'USDJPY': 0, 'MOVE': 0, 'USDJPY_Chg': 0}
    
    try:
        df = yf.download(tickers, period="1mo", group_by='ticker', progress=False)
        
        try:
            tnx_series = df['^TNX']['Close'].dropna()
            if not tnx_series.empty:
                res['Yield_10Y'] = tnx_series.iloc[-1]
        except: pass

        try:
            irx_series = df['^IRX']['Close'].dropna()
            if not irx_series.empty:
                res['Yield_Short'] = irx_series.iloc[-1]
        except: pass
        
        try:
            move_series = df['^MOVE']['Close']
            move_series = move_series.ffill().dropna()
            if not move_series.empty:
                res['MOVE'] = move_series.iloc[-1]
            else:
                res['MOVE'] = 0
        except: pass

        try:
            if not df['DX-Y.NYB']['Close'].dropna().empty: 
                res['DXY'] = df['DX-Y.NYB']['Close'].dropna().iloc[-1]
            jpy_series = df['JPY=X']['Close'].dropna()
            if not jpy_series.empty: 
                res['USDJPY'] = jpy_series.iloc[-1]
                if len(jpy_series) > 1:
                    res['USDJPY_Chg'] = jpy_series.iloc[-1] - jpy_series.iloc[-2]
        except: pass

        if res['Yield_10Y'] and res['Yield_Short']:
            res['Inversion'] = res['Yield_10Y'] - res['Yield_Short']

    except Exception as e:
        print(f"Rates Error: {e}")
        
    return res

@st.cache_data(ttl=3600)  # 1å°æ—¶ç¼“å­˜
def get_volatility_indices():
    data = {}
    try:
        vix = yf.Ticker("^VIX").history(period="2d")['Close'].iloc[-1]
        data['VIX'] = vix
    except: data['VIX'] = 15.0
    try:
        r = requests.get("https://api.alternative.me/fng/").json()
        data['Crypto_Val'] = int(r['data'][0]['value'])
        data['Crypto_Text'] = r['data'][0]['value_classification']
    except: data['Crypto_Val'] = 50; data['Crypto_Text'] = "Unknown"
    return data

@st.cache_data(ttl=3600)  # 1å°æ—¶ç¼“å­˜
def get_derivatives_structure():
    res = {
        "Futures_Basis": 0, "Basis_Status": "Normal", 
        "GEX_Net": "Neutral", "Call_Wall": 0, "Put_Wall": 0, 
        "Vanna_Status": "Neutral", "Current_Price": 0
    }
    try:
        market_data = yf.download(["NQ=F", "^NDX", "QQQ", "^VIX"], period="2d", progress=False)['Close']
        if isinstance(market_data.columns, pd.MultiIndex): market_data.columns = market_data.columns.get_level_values(0)
        
        fut = market_data['NQ=F'].iloc[-1]
        spot = market_data['^NDX'].iloc[-1]
        qqq_price = market_data['QQQ'].iloc[-1]
        res['Current_Price'] = qqq_price
        
        basis = fut - spot
        res['Futures_Basis'] = basis
        if basis < -15: res['Basis_Status'] = "ğŸ”´ Backwardation (æåº¦çœ‹ç©º)"
        elif basis > 60: res['Basis_Status'] = "ğŸŸ¢ Contango (æ­£å¸¸)"
        else: res['Basis_Status'] = "âšª Neutral"
        
        qqq = yf.Ticker("QQQ")
        expirations = qqq.options[:3] 
        all_calls = []; all_puts = []
        for date in expirations:
            try:
                chain = qqq.option_chain(date)
                c = chain.calls.fillna(0); p = chain.puts.fillna(0)
                c = c[c['openInterest'] > 100]; p = p[p['openInterest'] > 100]
                all_calls.append(c[['strike', 'openInterest']])
                all_puts.append(p[['strike', 'openInterest']])
            except: continue
        
        if all_calls:
            df_calls = pd.concat(all_calls).groupby('strike')['openInterest'].sum()
            df_puts = pd.concat(all_puts).groupby('strike')['openInterest'].sum()
            res['Call_Wall'] = df_calls.idxmax()
            res['Put_Wall'] = df_puts.idxmax()
            
            range_min = qqq_price * 0.98; range_max = qqq_price * 1.02
            calls_atm = df_calls[(df_calls.index >= range_min) & (df_calls.index <= range_max)].sum()
            puts_atm = df_puts[(df_puts.index >= range_min) & (df_puts.index <= range_max)].sum()
            gamma_ratio = puts_atm / max(1, calls_atm)
            
            if qqq_price < res['Put_Wall']: res['GEX_Net'] = "ğŸ”´ Negative Gamma (Crash Risk)"
            elif qqq_price > res['Call_Wall']: res['GEX_Net'] = "ğŸŸ¢ Positive Gamma (Breakout)"
            else:
                if gamma_ratio > 1.2: res['GEX_Net'] = "ğŸŸ  Weak Negative (éœ‡è¡åå¼±)"
                else: res['GEX_Net'] = "ğŸŸ¢ Positive Gamma (éœ‡è¡åå¼º)"

        ndx_chg = spot - market_data['^NDX'].iloc[-2]
        vix_chg = market_data['^VIX'].iloc[-1] - market_data['^VIX'].iloc[-2]
        if ndx_chg > 0 and vix_chg < 0: res['Vanna_Status'] = "ğŸŸ¢ Tailwind (åŠ©æ¶¨)"
        elif ndx_chg < 0 and vix_chg > 0: res['Vanna_Status'] = "ğŸ”´ Headwind (åŠ©è·Œ)"
    except: pass
    return res

@st.cache_data(ttl=3600)  # 1å°æ—¶ç¼“å­˜
def get_qqq_options_data():
    qqq = yf.Ticker("QQQ")
    res = {"PCR": 0.0, "Unusual": []}
    try:
        expirations = qqq.options[:3]
        total_c_vol = 0; total_p_vol = 0; unusual = []
        for date in expirations:
            try:
                chain = qqq.option_chain(date)
                calls = chain.calls.fillna(0); puts = chain.puts.fillna(0)
                total_c_vol += calls['volume'].sum(); total_p_vol += puts['volume'].sum()
                for opt_type, df, icon in [("CALL", calls, "ğŸŸ¢"), ("PUT", puts, "ğŸ”´")]:
                    hot = df[(df['volume'] > 2000) & (df['volume'] > df['openInterest'] * 1.2)]
                    for _, row in hot.iterrows():
                        unusual.append({
                            "Type": f"{icon} {opt_type}", "Strike": row['strike'], "Exp": date,
                            "Vol": int(row['volume']), "OI": int(row['openInterest']),
                            "Ratio": round(row['volume'] / (row['openInterest']+1), 1)
                        })
            except: continue
        if total_c_vol > 0: res['PCR'] = round(total_p_vol / total_c_vol, 2)
        res['Unusual'] = sorted(unusual, key=lambda x: x['Vol'], reverse=True)[:10]
    except: pass
    return res

@st.cache_data(ttl=300)  # 5åˆ†é’Ÿç¼“å­˜ (æ—¥å†…æ•°æ®éœ€è¦è¾ƒæ–°)
def get_intraday_tactics():
    res = {
        "VWAP": 0, "Price": 0, "Trend": "Neutral",
        "Exp_Move": 0, "Upper_Band": 0, "Lower_Band": 0,
        "0DTE_Call_Vol": 0, "0DTE_Put_Vol": 0, "0DTE_Sentiment": "Neutral",
        "Last_Update": datetime.datetime.now().strftime("%H:%M:%S")
    }
    try:
        df = yf.download("QQQ", period="1d", interval="1m", progress=False)
        if not df.empty:
            if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
            df['TP'] = (df['High'] + df['Low'] + df['Close']) / 3
            df['PV'] = df['TP'] * df['Volume']
            vwap = df['PV'].sum() / df['Volume'].sum() if df['Volume'].sum() > 0 else 0
            
            current_price = df['Close'].iloc[-1]
            res['VWAP'] = vwap
            res['Price'] = current_price
            
            if vwap > 0:
                if current_price > vwap * 1.001: res['Trend'] = "ğŸŸ¢ å¤šå¤´å¼ºåŠ¿"
                elif current_price < vwap * 0.999: res['Trend'] = "ğŸ”´ ç©ºå¤´å‹åˆ¶"
                else: res['Trend'] = "âšª éœ‡è¡"
            
        vix = yf.Ticker("^VIX").history(period="1d")['Close'].iloc[-1]
        exp_move = res['Price'] * ((vix/16)/100)
        res['Exp_Move'] = exp_move
        res['Upper_Band'] = res['Price'] + exp_move
        res['Lower_Band'] = res['Price'] - exp_move
        
        qqq = yf.Ticker("QQQ")
        target_date = qqq.options[0]
        chain = qqq.option_chain(target_date)
        c_vol = chain.calls['volume'].sum()
        p_vol = chain.puts['volume'].sum()
        res['0DTE_Call_Vol'] = c_vol
        res['0DTE_Put_Vol'] = p_vol
        
        ratio = p_vol / c_vol if c_vol > 0 else 1
        if ratio < 0.8: res['0DTE_Sentiment'] = "ğŸŸ¢ Call ä¸»å¯¼"
        elif ratio > 1.2: res['0DTE_Sentiment'] = "ğŸ”´ Put ä¸»å¯¼"
        else: res['0DTE_Sentiment'] = "âšª å¹³è¡¡"
        
        res['Expiry_Date'] = target_date
    except Exception as e: pass
    return res

# ============================================================
# 2. æ–°é—»ç³»ç»Ÿ (å¤šæº + é‡è¦æ€§è¯„åˆ†)
# ============================================================

# å…³é”®è¯é‡è¦æ€§æƒé‡
IMPORTANCE_WEIGHTS = {
    # æœ€é«˜ä¼˜å…ˆçº§ - å¤®è¡Œæ”¿ç­– (æƒé‡ 5)
    "FOMC": 5, "rate decision": 5, "Powell": 5, "Ueda": 5, "Kuroda": 5,
    "rate cut": 5, "rate hike": 5, "QT": 5, "QE": 5, "tapering": 5,
    "Fed": 4, "BOJ": 4, "ECB": 4, "Bank of Japan": 4,
    
    # é«˜ä¼˜å…ˆçº§ - å®è§‚æ•°æ® (æƒé‡ 4)
    "CPI": 4, "inflation": 4, "employment": 4, "GDP": 4, "PCE": 4,
    "payroll": 4, "unemployment": 4, "Treasury": 4, "yield": 3,
    
    # ä¸­é«˜ä¼˜å…ˆçº§ - ä¸ƒå·¨å¤´ (æƒé‡ 3)
    "NVIDIA": 3, "NVDA": 3, "Apple": 3, "AAPL": 3, 
    "Microsoft": 3, "MSFT": 3, "Google": 3, "Alphabet": 3, "GOOGL": 3,
    "Amazon": 3, "AMZN": 3, "Meta": 3, "META": 3, 
    "Tesla": 3, "TSLA": 3,
    
    # ä¸­ä¼˜å…ˆçº§ - AI (æƒé‡ 3)
    "OpenAI": 3, "ChatGPT": 3, "GPT-5": 4, "AI chip": 3, "GPU": 3,
    "artificial intelligence": 3, "machine learning": 2, "LLM": 3,
    "Anthropic": 3, "Claude": 2,
    
    # åŠ å¯†è´§å¸ (æƒé‡ 2)
    "Bitcoin": 2, "BTC": 2, "Ethereum": 2, "ETH": 2, "crypto": 2,
    
    # ä¸€èˆ¬è´¢ç» (æƒé‡ 1-2)
    "earnings": 2, "revenue": 2, "guidance": 2,
    "stock": 1, "market": 1, "trading": 1
}

# æ–°é—»åˆ†ç±»
NEWS_CATEGORIES = {
    "fed": ["Fed", "FOMC", "Powell", "rate cut", "rate hike", "QT", "QE", "Treasury", "Federal Reserve"],
    "boj": ["BOJ", "Bank of Japan", "Ueda", "Kuroda", "yen", "JPY"],
    "ai": ["OpenAI", "ChatGPT", "GPT", "AI chip", "artificial intelligence", "LLM", "Anthropic", "Claude", "machine learning"],
    "mag7": ["NVIDIA", "NVDA", "Apple", "AAPL", "Microsoft", "MSFT", "Google", "Alphabet", "GOOGL", "Amazon", "AMZN", "Meta", "META", "Tesla", "TSLA"],
    "crypto": ["Bitcoin", "BTC", "Ethereum", "ETH", "crypto", "cryptocurrency"],
    "macro": ["CPI", "inflation", "GDP", "employment", "payroll", "unemployment", "PCE"]
}

def categorize_news(title: str) -> list:
    """å¯¹æ–°é—»è¿›è¡Œåˆ†ç±»"""
    categories = []
    title_lower = title.lower()
    for cat, keywords in NEWS_CATEGORIES.items():
        for kw in keywords:
            if kw.lower() in title_lower:
                categories.append(cat)
                break
    return list(set(categories)) if categories else ["general"]

def score_news_importance(title: str) -> int:
    """è®¡ç®—æ–°é—»é‡è¦æ€§è¯„åˆ†"""
    score = 0
    title_lower = title.lower()
    for keyword, weight in IMPORTANCE_WEIGHTS.items():
        if keyword.lower() in title_lower:
            score = max(score, weight)  # å–æœ€é«˜æƒé‡è€Œéç´¯åŠ 
    return score

@st.cache_data(ttl=7200)  # 2å°æ—¶ç¼“å­˜ (æ–°é—» + FinBERT åˆ†æè¾ƒæ…¢)
def get_multi_source_news():
    """ä»å¤šä¸ªæ¥æºè·å–æ–°é—»"""
    feeds = [
        # å®è§‚ & ç¾è”å‚¨
        ("Fed", "https://www.federalreserve.gov/feeds/press_all.xml"),
        ("Reuters", "https://feeds.reuters.com/reuters/businessNews"),
        ("CNBC", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=20910258"),
        
        # ç§‘æŠ€ & AI
        ("TechCrunch", "https://techcrunch.com/feed/"),
        
        # åŠ å¯†è´§å¸
        ("CoinDesk", "https://www.coindesk.com/arc/outboundfeeds/rss/"),
    ]
    
    articles = []
    for src, url in feeds:
        try:
            f = feedparser.parse(url)
            for e in f.entries[:8]:  # æ¯ä¸ªæºå–8æ¡
                title = e.get('title', '')
                link = e.get('link', '')
                published = e.get('published', e.get('updated', ''))
                
                importance = score_news_importance(title)
                categories = categorize_news(title)
                
                articles.append({
                    "Title": title,
                    "Link": link,
                    "Source": src,
                    "Published": published,
                    "Importance": importance,
                    "Categories": categories
                })
        except Exception as e:
            continue
    
    # æŒ‰é‡è¦æ€§æ’åº
    articles = sorted(articles, key=lambda x: x['Importance'], reverse=True)
    
    return pd.DataFrame(articles)

# ============================================================
# 3. å®è§‚æ—¥å† (2025 å…³é”®æ—¥æœŸ + å€’è®¡æ—¶)
# ============================================================

MACRO_CALENDAR_2025 = [
    # FOMC ä¼šè®®
    {"date": "2025-01-29", "event": "FOMC åˆ©ç‡å†³è®®", "type": "fed", "importance": 5},
    {"date": "2025-03-19", "event": "FOMC åˆ©ç‡å†³è®® + ç‚¹é˜µå›¾", "type": "fed", "importance": 5},
    {"date": "2025-05-07", "event": "FOMC åˆ©ç‡å†³è®®", "type": "fed", "importance": 5},
    {"date": "2025-06-18", "event": "FOMC åˆ©ç‡å†³è®® + ç‚¹é˜µå›¾", "type": "fed", "importance": 5},
    {"date": "2025-07-30", "event": "FOMC åˆ©ç‡å†³è®®", "type": "fed", "importance": 5},
    {"date": "2025-09-17", "event": "FOMC åˆ©ç‡å†³è®® + ç‚¹é˜µå›¾", "type": "fed", "importance": 5},
    {"date": "2025-11-05", "event": "FOMC åˆ©ç‡å†³è®®", "type": "fed", "importance": 5},
    {"date": "2025-12-17", "event": "FOMC åˆ©ç‡å†³è®® + ç‚¹é˜µå›¾", "type": "fed", "importance": 5},
    
    # CPI æ•°æ® (é€šå¸¸åœ¨æ¯æœˆ10-15æ—¥)
    {"date": "2025-01-15", "event": "CPI (12æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-02-12", "event": "CPI (1æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-03-12", "event": "CPI (2æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-04-10", "event": "CPI (3æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-05-13", "event": "CPI (4æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-06-11", "event": "CPI (5æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-07-11", "event": "CPI (6æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-08-13", "event": "CPI (7æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-09-10", "event": "CPI (8æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-10-10", "event": "CPI (9æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-11-13", "event": "CPI (10æœˆ)", "type": "inflation", "importance": 4},
    {"date": "2025-12-10", "event": "CPI (11æœˆ)", "type": "inflation", "importance": 4},
    
    # éå†œå°±ä¸š (é€šå¸¸åœ¨æ¯æœˆç¬¬ä¸€ä¸ªå‘¨äº”)
    {"date": "2025-01-10", "event": "éå†œå°±ä¸š (12æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-02-07", "event": "éå†œå°±ä¸š (1æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-03-07", "event": "éå†œå°±ä¸š (2æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-04-04", "event": "éå†œå°±ä¸š (3æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-05-02", "event": "éå†œå°±ä¸š (4æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-06-06", "event": "éå†œå°±ä¸š (5æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-07-03", "event": "éå†œå°±ä¸š (6æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-08-01", "event": "éå†œå°±ä¸š (7æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-09-05", "event": "éå†œå°±ä¸š (8æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-10-03", "event": "éå†œå°±ä¸š (9æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-11-07", "event": "éå†œå°±ä¸š (10æœˆ)", "type": "employment", "importance": 4},
    {"date": "2025-12-05", "event": "éå†œå°±ä¸š (11æœˆ)", "type": "employment", "importance": 4},
    
    # BOJ ä¼šè®®
    {"date": "2025-01-24", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-03-14", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-05-01", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-06-13", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-07-31", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-09-19", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-10-31", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    {"date": "2025-12-19", "event": "BOJ åˆ©ç‡å†³è®®", "type": "boj", "importance": 4},
    
    # æœŸæƒåˆ°æœŸ
    {"date": "2025-01-17", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-02-21", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-03-21", "event": "ä¸‰å·«æ—¥ (Quad Witching)", "type": "opex", "importance": 4},
    {"date": "2025-04-17", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-05-16", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-06-20", "event": "ä¸‰å·«æ—¥ (Quad Witching)", "type": "opex", "importance": 4},
    {"date": "2025-07-18", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-08-15", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-09-19", "event": "ä¸‰å·«æ—¥ (Quad Witching)", "type": "opex", "importance": 4},
    {"date": "2025-10-17", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-11-21", "event": "æœˆåº¦æœŸæƒåˆ°æœŸ (OPEX)", "type": "opex", "importance": 3},
    {"date": "2025-12-19", "event": "ä¸‰å·«æ—¥ (Quad Witching)", "type": "opex", "importance": 4},
]

def get_macro_calendar_with_countdown():
    """è·å–å¸¦å€’è®¡æ—¶çš„å®è§‚æ—¥å†"""
    today = datetime.date.today()
    upcoming = []
    
    for evt in MACRO_CALENDAR_2025:
        evt_date = datetime.datetime.strptime(evt["date"], "%Y-%m-%d").date()
        days_until = (evt_date - today).days
        
        if -1 <= days_until <= 60:  # åŒ…æ‹¬æ˜¨å¤©åˆ°æœªæ¥60å¤©
            countdown = ""
            urgency = "normal"
            
            if days_until < 0:
                countdown = "æ˜¨å¤©"
                urgency = "past"
            elif days_until == 0:
                countdown = "ğŸ”´ ä»Šå¤©!"
                urgency = "urgent"
            elif days_until == 1:
                countdown = "ğŸŸ  æ˜å¤©"
                urgency = "urgent"
            elif days_until <= 3:
                countdown = f"âš ï¸ {days_until}å¤©å"
                urgency = "soon"
            elif days_until <= 7:
                countdown = f"ğŸ“… {days_until}å¤©å"
                urgency = "soon"
            else:
                countdown = f"{days_until}å¤©å"
                urgency = "normal"
            
            upcoming.append({
                **evt,
                "countdown": countdown,
                "urgency": urgency,
                "days_until": days_until
            })
    
    return sorted(upcoming, key=lambda x: x["days_until"])

# ============================================================
# 4. Gamma è®¡ç®—ç³»ç»Ÿ (Black-Scholes)
# ============================================================

def black_scholes_gamma(S, K, T, r, sigma):
    """
    è®¡ç®— Black-Scholes Gamma
    S: ç°è´§ä»·æ ¼
    K: è¡Œæƒä»·
    T: åˆ°æœŸæ—¶é—´ (å¹´)
    r: æ— é£é™©åˆ©ç‡
    sigma: éšå«æ³¢åŠ¨ç‡
    """
    if T <= 0 or sigma <= 0 or S <= 0 or K <= 0:
        return 0
    
    try:
        d1 = (np.log(S/K) + (r + 0.5*sigma**2)*T) / (sigma*np.sqrt(T))
        gamma = norm.pdf(d1) / (S * sigma * np.sqrt(T))
        return gamma
    except:
        return 0

@st.cache_data(ttl=3600)  # 1å°æ—¶ç¼“å­˜ (å¯æ‰‹åŠ¨åˆ·æ–°è·å–æœ€æ–°)
def calculate_gex_profile():
    """
    è®¡ç®—å®Œæ•´çš„ GEX Profile
    è¿”å›æŒ‰ Strike åˆ†å¸ƒçš„ Gamma Exposure
    """
    # è®°å½•è®¡ç®—æ—¶é—´
    calc_time = datetime.datetime.now(pytz.timezone('US/Eastern'))
    
    # è®¡ç®— OI æ•°æ®æ—¥æœŸ (å‰ä¸€ä¸ªäº¤æ˜“æ—¥)
    # ç®€åŒ–å¤„ç†ï¼šå¦‚æœæ˜¯å‘¨ä¸€ï¼ŒOI æ˜¯å‘¨äº”çš„ï¼›å¦åˆ™æ˜¯æ˜¨å¤©çš„
    today = datetime.date.today()
    if today.weekday() == 0:  # å‘¨ä¸€
        oi_date = today - timedelta(days=3)  # å‘¨äº”
    elif today.weekday() == 6:  # å‘¨æ—¥
        oi_date = today - timedelta(days=2)  # å‘¨äº”
    elif today.weekday() == 5:  # å‘¨å…­
        oi_date = today - timedelta(days=1)  # å‘¨äº”
    else:
        oi_date = today - timedelta(days=1)  # æ˜¨å¤©
    
    result = {
        'strikes': [],
        'gex_call': [],
        'gex_put': [],
        'gex_net': [],
        'total_gex': 0,
        'gamma_flip': 0,
        'max_pain': 0,
        'spot_price': 0,
        'put_wall': 0,
        'call_wall': 0,
        'calc_time': calc_time.strftime('%Y-%m-%d %H:%M:%S EST'),
        'oi_date': oi_date.strftime('%Y-%m-%d'),
        'oi_weekday': ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥'][oi_date.weekday()]
    }
    
    try:
        # è·å– QQQ æ•°æ®
        qqq = yf.Ticker("QQQ")
        hist = qqq.history(period="1d")
        if hist.empty:
            return result
        spot = float(hist['Close'].iloc[-1])
        result['spot_price'] = spot
        
        # è·å–æ— é£é™©åˆ©ç‡ (3ä¸ªæœˆå›½å€º)
        try:
            irx_hist = yf.Ticker("^IRX").history(period="1d")
            if not irx_hist.empty:
                irx = float(irx_hist['Close'].iloc[-1]) / 100
            else:
                irx = 0.05
        except:
            irx = 0.05
        
        # æ”¶é›†æ‰€æœ‰æœŸæƒé“¾æ•°æ®
        try:
            expirations = qqq.options[:4]  # å–å‰4ä¸ªåˆ°æœŸæ—¥
        except:
            return result
            
        all_options = []
        
        for exp_date in expirations:
            try:
                chain = qqq.option_chain(exp_date)
                
                # è®¡ç®—åˆ°æœŸæ—¶é—´
                exp_dt = datetime.datetime.strptime(exp_date, "%Y-%m-%d")
                today = datetime.datetime.now()
                days_to_exp = (exp_dt - today).days
                T = max(days_to_exp / 365, 0.001)
                
                # å¤„ç† Calls
                for _, row in chain.calls.iterrows():
                    try:
                        oi = row.get('openInterest', 0)
                        if pd.isna(oi):
                            oi = 0
                        oi = float(oi)
                        
                        if oi > 50:
                            iv = row.get('impliedVolatility', 0.3)
                            if pd.isna(iv) or iv <= 0 or iv > 5:  # IV è¶…è¿‡ 500% è§†ä¸ºå¼‚å¸¸
                                iv = 0.3
                            iv = float(iv)
                            
                            strike = float(row['strike'])
                            all_options.append({
                                'strike': strike,
                                'oi': oi,
                                'iv': iv,
                                'T': T,
                                'type': 'call'
                            })
                    except:
                        continue
                
                # å¤„ç† Puts
                for _, row in chain.puts.iterrows():
                    try:
                        oi = row.get('openInterest', 0)
                        if pd.isna(oi):
                            oi = 0
                        oi = float(oi)
                        
                        if oi > 50:
                            iv = row.get('impliedVolatility', 0.3)
                            if pd.isna(iv) or iv <= 0 or iv > 5:
                                iv = 0.3
                            iv = float(iv)
                            
                            strike = float(row['strike'])
                            all_options.append({
                                'strike': strike,
                                'oi': oi,
                                'iv': iv,
                                'T': T,
                                'type': 'put'
                            })
                    except:
                        continue
            except:
                continue
        
        if not all_options:
            return result
        
        # è®¡ç®—æ¯ä¸ª Strike çš„ GEX
        gex_by_strike = {}
        
        for opt in all_options:
            try:
                strike = opt['strike']
                gamma = black_scholes_gamma(spot, strike, opt['T'], irx, opt['iv'])
                
                # GEX = Gamma Ã— OI Ã— 100 Ã— SpotÂ² / 1e9 (è½¬æ¢ä¸ºåäº¿ç¾å…ƒ)
                gex = gamma * opt['oi'] * 100 * (spot ** 2) / 1e9
                
                if strike not in gex_by_strike:
                    gex_by_strike[strike] = {'call': 0, 'put': 0}
                
                if opt['type'] == 'call':
                    gex_by_strike[strike]['call'] += gex
                else:
                    gex_by_strike[strike]['put'] += gex
            except:
                continue
        
        if not gex_by_strike:
            return result
        
        # è¿‡æ»¤å¹¶æ’åº - åªä¿ç•™ç°ä»·é™„è¿‘ Â±10% çš„ strikes
        valid_strikes = [s for s in gex_by_strike.keys() if spot * 0.9 <= s <= spot * 1.1]
        valid_strikes = sorted(valid_strikes)
        
        if not valid_strikes:
            return result
        
        for strike in valid_strikes:
            result['strikes'].append(strike)
            result['gex_call'].append(gex_by_strike[strike]['call'])
            result['gex_put'].append(-gex_by_strike[strike]['put'])  # Put GEX ä¸ºè´Ÿ
            result['gex_net'].append(gex_by_strike[strike]['call'] - gex_by_strike[strike]['put'])
        
        # è®¡ç®—æ€» GEX
        result['total_gex'] = sum(result['gex_net'])
        
        # æ‰¾ Gamma Flip Point (å‡€ GEX ä»æ­£å˜è´Ÿæˆ–ä»è´Ÿå˜æ­£çš„ç‚¹)
        for i in range(len(result['strikes']) - 1):
            current_gex = result['gex_net'][i]
            next_gex = result['gex_net'][i+1]
            if (current_gex > 0 and next_gex < 0) or (current_gex < 0 and next_gex > 0):
                result['gamma_flip'] = (result['strikes'][i] + result['strikes'][i+1]) / 2
                break
        
        # æ‰¾ Put Wall å’Œ Call Wall (æœ€å¤§ GEX é›†ä¸­ä½ç½®)
        if result['gex_call']:
            max_call_gex = max(result['gex_call'])
            if max_call_gex > 0:
                max_call_idx = result['gex_call'].index(max_call_gex)
                result['call_wall'] = result['strikes'][max_call_idx]
        
        if result['gex_put']:
            min_put_gex = min(result['gex_put'])  # æœ€è´Ÿçš„
            if min_put_gex < 0:
                max_put_idx = result['gex_put'].index(min_put_gex)
                result['put_wall'] = result['strikes'][max_put_idx]
        
        # è®¡ç®— Max Pain (ç®€åŒ–ç‰ˆ - æ‰¾ OI æœ€é›†ä¸­çš„ strike)
        try:
            total_oi_by_strike = {}
            for opt in all_options:
                strike = opt['strike']
                if strike in valid_strikes:
                    if strike not in total_oi_by_strike:
                        total_oi_by_strike[strike] = 0
                    total_oi_by_strike[strike] += opt['oi']
            
            if total_oi_by_strike:
                result['max_pain'] = max(total_oi_by_strike, key=total_oi_by_strike.get)
        except:
            pass
        
    except Exception as e:
        # é™é»˜å¤±è´¥ï¼Œè¿”å›ç©ºç»“æœ
        pass
    
    return result

# ============================================================
# 5. æ™ºèƒ½è§„åˆ™å¼•æ“
# ============================================================

def analyze_market_regime(ny_fed, fed_liq, credit, rates, vol, opt, deriv, rrp_tga_hist):
    """
    æ™ºèƒ½è§„åˆ™å¼•æ“ï¼šåˆ†æå¸‚åœºçŠ¶æ€å¹¶ç”Ÿæˆä¿¡å·
    """
    signals = []
    regime = "neutral"
    score = 0
    
    # ========== æµåŠ¨æ€§åˆ†æ ==========
    # è§„åˆ™1: SOFR-Repo åˆ©å·®
    spread = ny_fed['SOFR'] - ny_fed['TGCR']
    if spread > 0.10:
        signals.append({
            "level": "CRITICAL",
            "category": "æµåŠ¨æ€§",
            "msg": f"ğŸš¨ é“¶è¡Œé—´æµåŠ¨æ€§ç´§ç¼º: SOFR-Repo åˆ©å·® {spread:.3f}% è¶…è¿‡è­¦æˆ’çº¿",
            "action": "å‡ä»“è§‚æœ›ï¼Œå…³æ³¨ Fed ç´§æ€¥æ“ä½œ",
            "score": -2
        })
        score -= 2
    elif spread > 0.05:
        signals.append({
            "level": "WARNING",
            "category": "æµåŠ¨æ€§",
            "msg": f"âš ï¸ æµåŠ¨æ€§åç´§: SOFR-Repo åˆ©å·® {spread:.3f}%",
            "action": "è°¨æ…æŒä»“",
            "score": -1
        })
        score -= 1
    elif spread < 0.02:
        signals.append({
            "level": "POSITIVE",
            "category": "æµåŠ¨æ€§",
            "msg": f"âœ… æµåŠ¨æ€§å……è£•: SOFR-Repo åˆ©å·® {spread:.3f}%",
            "action": "ç¯å¢ƒæœ‰åˆ©äºé£é™©èµ„äº§",
            "score": 1
        })
        score += 1
    
    # è§„åˆ™2: RRP + TGA è”åŠ¨
    rrp_chg = fed_liq['RRP_Chg']
    tga_chg = fed_liq['TGA_Chg']
    
    if rrp_chg < -50 and tga_chg > 30:
        signals.append({
            "level": "CRITICAL",
            "category": "æµåŠ¨æ€§",
            "msg": f"ğŸš¨ åŒé‡æŠ½æ°´: RRP {rrp_chg:.0f}B æµå‡º + TGA å¢åŠ  {tga_chg:.0f}B",
            "action": "ç³»ç»ŸæµåŠ¨æ€§æ€¥å‰§æ”¶ç¼©ï¼Œé«˜åº¦è­¦æƒ•",
            "score": -2
        })
        score -= 2
    elif rrp_chg > 50:
        signals.append({
            "level": "POSITIVE",
            "category": "æµåŠ¨æ€§",
            "msg": f"âœ… RRP æ³¨æ°´: {rrp_chg:.0f}B æµå…¥éš”å¤œé€†å›è´­",
            "action": "æµåŠ¨æ€§æ”¹å–„",
            "score": 1
        })
        score += 1
    
    # è§„åˆ™3: ä¿¡ç”¨åˆ©å·®
    if credit[1] < -1.0:
        signals.append({
            "level": "CRITICAL",
            "category": "é£é™©åå¥½",
            "msg": f"ğŸš¨ ä¿¡ç”¨é£é™©é£™å‡: HYG/LQD å•æ—¥ä¸‹è·Œ {credit[1]:.2f}%",
            "action": "èµ„é‡‘æ’¤ç¦»åƒåœ¾å€ºï¼ŒRisk-Off æ¨¡å¼",
            "score": -2
        })
        score -= 2
    elif credit[1] < -0.3:
        signals.append({
            "level": "WARNING",
            "category": "é£é™©åå¥½",
            "msg": f"âš ï¸ ä¿¡ç”¨åç´§: HYG/LQD ä¸‹è·Œ {credit[1]:.2f}%",
            "action": "å…³æ³¨ä¿¡ç”¨å¸‚åœºåŠ¨æ€",
            "score": -1
        })
        score -= 1
    elif credit[1] > 0.5:
        signals.append({
            "level": "POSITIVE",
            "category": "é£é™©åå¥½",
            "msg": f"âœ… é£é™©åå¥½å›å‡: HYG/LQD ä¸Šæ¶¨ {credit[1]:.2f}%",
            "action": "Risk-On ç¯å¢ƒ",
            "score": 1
        })
        score += 1
    
    # ========== ç¾å€ºåˆ†æ ==========
    # è§„åˆ™4: 10Y æ”¶ç›Šç‡
    if rates['Yield_10Y'] > 5.0:
        signals.append({
            "level": "CRITICAL",
            "category": "ç¾å€º",
            "msg": f"ğŸš¨ åˆ©ç‡é£æš´: 10Y æ”¶ç›Šç‡ {rates['Yield_10Y']:.2f}% çªç ´ 5%",
            "action": "ç§‘æŠ€è‚¡ä¼°å€¼æ‰¿å‹ï¼Œå‡æŒé«˜ä¹…æœŸèµ„äº§",
            "score": -2
        })
        score -= 2
    elif rates['Yield_10Y'] > 4.5:
        signals.append({
            "level": "WARNING",
            "category": "ç¾å€º",
            "msg": f"âš ï¸ åˆ©ç‡å‹åŠ›: 10Y æ”¶ç›Šç‡ {rates['Yield_10Y']:.2f}%",
            "action": "å…³æ³¨æˆé•¿è‚¡è¡¨ç°",
            "score": -1
        })
        score -= 1
    
    # è§„åˆ™5: MOVE æŒ‡æ•°
    if rates['MOVE'] > 130:
        signals.append({
            "level": "CRITICAL",
            "category": "ç¾å€º",
            "msg": f"ğŸš¨ å€ºå¸‚ææ…Œ: MOVE {rates['MOVE']:.0f} æç«¯æ³¢åŠ¨",
            "action": "æµåŠ¨æ€§å±æœºé£é™©ï¼Œç°é‡‘ä¸ºç‹",
            "score": -2
        })
        score -= 2
    elif rates['MOVE'] > 110:
        signals.append({
            "level": "WARNING",
            "category": "ç¾å€º",
            "msg": f"âš ï¸ å€ºå¸‚æ³¢åŠ¨: MOVE {rates['MOVE']:.0f}",
            "action": "æ³¨æ„æŠµæŠ¼å“ä»·å€¼æ³¢åŠ¨",
            "score": -1
        })
        score -= 1
    
    # è§„åˆ™6: æ”¶ç›Šç‡æ›²çº¿
    if rates['Inversion'] < -1.0:
        signals.append({
            "level": "WARNING",
            "category": "ç¾å€º",
            "msg": f"âš ï¸ æ·±åº¦å€’æŒ‚: 10Y-3M = {rates['Inversion']:.2f}%",
            "action": "ç»æµè¡°é€€å‰ç»æŒ‡æ ‡äº®ç¯",
            "score": -0.5
        })
        score -= 0.5
    
    # ========== æ—¥å…ƒå¥—åˆ©åˆ†æ ==========
    # è§„åˆ™7: USDJPY + VIX è”åŠ¨
    if rates.get('USDJPY_Chg', 0) < -2 and vol['VIX'] > 20:
        signals.append({
            "level": "CRITICAL",
            "category": "æ±‡ç‡",
            "msg": f"ğŸš¨ æ—¥å…ƒå¥—åˆ©å¹³ä»“: USDJPY æ€¥è·Œ + VIX {vol['VIX']:.1f}",
            "action": "å…¨çƒ Risk-Offï¼Œå‡æŒé£é™©èµ„äº§",
            "score": -2
        })
        score -= 2
    
    # ========== ææ…ŒæŒ‡æ ‡ ==========
    # è§„åˆ™8: VIX
    if vol['VIX'] > 30:
        signals.append({
            "level": "CRITICAL",
            "category": "ææ…Œ",
            "msg": f"ğŸš¨ VIX ææ…Œ: {vol['VIX']:.1f}",
            "action": "å¸‚åœºæåº¦ææ…Œï¼Œå¯èƒ½æ˜¯åå¼¹æœºä¼š",
            "score": -1  # ææ…Œæ—¶åè€Œå¯èƒ½è§åº•
        })
        score -= 1
    elif vol['VIX'] > 25:
        signals.append({
            "level": "WARNING",
            "category": "ææ…Œ",
            "msg": f"âš ï¸ VIX å‡é«˜: {vol['VIX']:.1f}",
            "action": "æ³¢åŠ¨åŠ å‰§ï¼Œæ§åˆ¶ä»“ä½",
            "score": -1
        })
        score -= 1
    elif vol['VIX'] < 12:
        signals.append({
            "level": "WARNING",
            "category": "ææ…Œ",
            "msg": f"âš ï¸ VIX è¿‡ä½: {vol['VIX']:.1f} (è‡ªæ»¡ä¿¡å·)",
            "action": "å¸‚åœºè¿‡äºä¹è§‚ï¼Œæ³¨æ„çªå‘é£é™©",
            "score": -0.5
        })
        score -= 0.5
    
    # è§„åˆ™9: å¸åœˆææ…Œè´ªå©ª
    if vol['Crypto_Val'] < 20:
        signals.append({
            "level": "POSITIVE",
            "category": "æƒ…ç»ª",
            "msg": f"âœ… å¸åœˆæåº¦ææ…Œ: {vol['Crypto_Val']} ({vol['Crypto_Text']})",
            "action": "åå‘æŒ‡æ ‡ï¼Œå¯èƒ½æ˜¯ä¹°å…¥æ—¶æœº",
            "score": 0.5
        })
        score += 0.5
    elif vol['Crypto_Val'] > 80:
        signals.append({
            "level": "WARNING",
            "category": "æƒ…ç»ª",
            "msg": f"âš ï¸ å¸åœˆæåº¦è´ªå©ª: {vol['Crypto_Val']} ({vol['Crypto_Text']})",
            "action": "è¿‡çƒ­ä¿¡å·ï¼Œè°¨æ…è¿½é«˜",
            "score": -0.5
        })
        score -= 0.5
    
    # ========== äº¤æ˜“ç»“æ„ ==========
    # è§„åˆ™10: Gamma ç¯å¢ƒ
    if "Negative" in deriv['GEX_Net'] or "Crash" in deriv['GEX_Net']:
        signals.append({
            "level": "WARNING",
            "category": "ç»“æ„",
            "msg": f"âš ï¸ è´Ÿ Gamma ç¯å¢ƒ: {deriv['GEX_Net']}",
            "action": "åšå¸‚å•†è¿½æ¶¨æ€è·Œï¼Œæ³¢åŠ¨æ”¾å¤§",
            "score": -1
        })
        score -= 1
    elif "Positive" in deriv['GEX_Net']:
        signals.append({
            "level": "POSITIVE",
            "category": "ç»“æ„",
            "msg": f"âœ… æ­£ Gamma ç¯å¢ƒ: {deriv['GEX_Net']}",
            "action": "åšå¸‚å•†é«˜æŠ›ä½å¸ï¼Œæ³¢åŠ¨æ”¶æ•›",
            "score": 1
        })
        score += 1
    
    # è§„åˆ™11: æœŸè´§åŸºå·®
    if "Backwardation" in deriv['Basis_Status']:
        signals.append({
            "level": "CRITICAL",
            "category": "ç»“æ„",
            "msg": f"ğŸš¨ æœŸè´§è´´æ°´: åŸºå·® {deriv['Futures_Basis']:.1f}",
            "action": "æåº¦ææ…Œæˆ–å¼ºçƒˆå¯¹å†²éœ€æ±‚",
            "score": -2
        })
        score -= 2
    
    # ========== ç¡®å®šå¸‚åœºçŠ¶æ€ ==========
    if score >= 3:
        regime = "risk_on"
    elif score <= -3:
        regime = "risk_off"
    else:
        regime = "neutral"
    
    return {
        "signals": signals,
        "regime": regime,
        "score": score
    }

# ============================================================
# 6. å®è§‚è¯„åˆ†è®¡ç®— (ä¿ç•™åŸæœ‰é€»è¾‘)
# ============================================================

def calculate_macro_score(ny_fed, fed_liq, credit, rates, vol, opt, deriv, news_score_val):
    score = 0; flags = []
    
    # æµåŠ¨æ€§
    liq_score = 0
    spread = ny_fed['SOFR'] - ny_fed['TGCR']
    if spread > 0.05: liq_score -= 1.0; flags.append("ğŸ”´ æµåŠ¨æ€§ç´§ç¼º (SOFR > Repo)")
    elif spread < 0.02: liq_score += 0.5
    if fed_liq['RRP_Chg'] > 20: liq_score -= 0.5; flags.append("ğŸ”´ RRP æŠ½æ°´")
    if fed_liq['TGA_Chg'] > 20: liq_score -= 0.5; flags.append("ğŸ”´ TGA æŠ½æ°´")
    if credit[1] < -0.5: liq_score -= 0.5; flags.append("ğŸ”´ HYG/LQD é¿é™©æ¨¡å¼ (Credit Stress)")
    elif credit[1] > 0.2: liq_score += 0.5
    score += max(-2.5, min(2.5, liq_score))
    
    # ç¾å€º
    bond_score = 0
    if rates['Yield_10Y'] > 4.5: bond_score -= 1.0; flags.append("ğŸ”´ 10Y æ”¶ç›Šç‡è¿‡é«˜ (>4.5%)")
    elif rates['Yield_10Y'] < 4.0: bond_score += 1.0
    if rates['MOVE'] > 110: bond_score -= 1.5; flags.append("ğŸ”´ MOVE å€ºå¸‚ææ…Œ")
    if rates['Inversion'] < -0.5: flags.append("âš ï¸ æ”¶ç›Šç‡æ·±åº¦å€’æŒ‚ (Recession Risk)")
    score += max(-2.5, min(2.5, bond_score))
    
    # ææ…Œ
    fear_score = 0
    if vol['VIX'] > 25: fear_score -= 1.0; flags.append("ğŸ”´ VIX ææ…Œæ¨¡å¼")
    elif vol['VIX'] < 13: fear_score -= 0.5; flags.append("âš ï¸ VIX è¿‡ä½ (è‡ªæ»¡)")
    if vol['Crypto_Val'] < 20: fear_score += 0.5; flags.append("ğŸŸ¢ å¸åœˆæåº¦ææ…Œ (åå‘åšå¤š)")
    score += fear_score
    
    # äº¤æ˜“
    trade_score = 0
    if opt['PCR'] > 1.2: trade_score -= 0.5; flags.append("ğŸ“‰ PCR æé«˜ (ç©ºå¤´æ‹¥æŒ¤)")
    elif opt['PCR'] < 0.6: trade_score += 0.5; flags.append("ğŸ“ˆ PCR æä½ (å¤šå¤´æ‹¥æŒ¤)")
    if deriv['Basis_Status'].startswith("ğŸ”´"): trade_score -= 1.0; flags.append("ğŸ”´ æœŸè´§è´´æ°´ (Hedging Demand)")
    if "Negative" in deriv['GEX_Net']: trade_score -= 0.5; flags.append("ğŸ”´ è´Ÿ Gamma (é«˜æ³¢åŠ¨é£é™©)")
    if "Headwind" in deriv['Vanna_Status']: flags.append("ğŸ”´ Vanna é˜»åŠ› (VIX Spike)")
    score += max(-2.0, min(2.0, trade_score))
    
    # æ–°é—»
    score += news_score_val * 1.5
    
    final_score = round(score * (10 / 7.5), 1)
    summary = ""
    action = ""
    if final_score > 3:
        summary = "å®è§‚ç¯å¢ƒ **åå¤š (Bullish)**ã€‚æµåŠ¨æ€§ç¯å¢ƒé…åˆï¼Œå¸‚åœºæƒ…ç»ªç¨³å®šã€‚"
        action = "âœ… **æ“ä½œå»ºè®®**: é€¢ä½åšå¤š (Buy Dips)ï¼Œä»¥ Call Wall ä¸ºç›®æ ‡ä½ã€‚"
    elif final_score < -3:
        summary = "å®è§‚ç¯å¢ƒ **åç©º (Bearish)**ã€‚æ£€æµ‹åˆ°æµåŠ¨æ€§å‹åŠ›æˆ–å¸‚åœºææ…ŒæŒ‡æ ‡å¼‚å¸¸ã€‚"
        action = "ğŸ›¡ï¸ **æ“ä½œå»ºè®®**: ç°é‡‘ä¸ºç‹ï¼Œåå¼¹åšç©º (Fade Rallies)ï¼Œå…³æ³¨ Put Wall æ”¯æ’‘ã€‚"
    else:
        summary = "å®è§‚ç¯å¢ƒ **ä¸­æ€§éœ‡è¡ (Neutral)**ã€‚å¤šç©ºä¿¡å·äº¤ç»‡ï¼Œç¼ºä¹æ˜ç¡®å®è§‚é©±åŠ¨ã€‚"
        action = "âš–ï¸ **æ“ä½œå»ºè®®**: åŒºé—´æ“ä½œ (Range Trade)ï¼Œé¿å…è¿½æ¶¨æ€è·Œï¼Œä»¥æ—¥å†…å¾®è§‚ç»“æ„ä¸ºä¸»ã€‚"
    if not flags: flags.append("æš‚æ— æ˜¾è‘—å¼‚å¸¸æŒ‡æ ‡")
    return final_score, flags, summary, action

# ============================================================
# 7. ç”Ÿæˆå¯¼å‡ºåˆ° Claude çš„æ–‡æœ¬
# ============================================================

def generate_claude_export(ny_fed, fed_liq, credit, rates, vol, opt, deriv, gex_data, regime_analysis, processed_news):
    """ç”Ÿæˆå¯å¤åˆ¶åˆ° Claude è¿›è¡Œæ·±åº¦åˆ†æçš„æ–‡æœ¬"""
    
    export_text = f"""# å®è§‚æˆ˜æƒ…å®¤æ•°æ®å¿«ç…§
ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} EST

## ä¸€ã€æµåŠ¨æ€§æŒ‡æ ‡
- SOFR: {ny_fed['SOFR']:.2f}%
- Repo (TGCR): {ny_fed['TGCR']:.2f}%
- SOFR-Repo åˆ©å·®: {(ny_fed['SOFR'] - ny_fed['TGCR']):.3f}%
- RRP: ${fed_liq['RRP']:.0f}B (æ—¥å˜åŒ–: {fed_liq['RRP_Chg']:.0f}B)
- TGA: ${fed_liq['TGA']:.0f}B (æ—¥å˜åŒ–: {fed_liq['TGA_Chg']:.0f}B)
- HYG/LQD: {credit[0]:.3f} (æ—¥å˜åŒ–: {credit[1]:.2f}%)

## äºŒã€ç¾å€ºä¸æ±‡ç‡
- 10Y æ”¶ç›Šç‡: {rates['Yield_10Y']:.2f}%
- 3M æ”¶ç›Šç‡: {rates['Yield_Short']:.2f}%
- 10Y-3M åˆ©å·®: {rates['Inversion']:.2f}%
- MOVE æŒ‡æ•°: {rates['MOVE']:.1f}
- DXY: {rates['DXY']:.2f}
- USDJPY: {rates['USDJPY']:.2f}

## ä¸‰ã€ææ…Œä¸æƒ…ç»ª
- VIX: {vol['VIX']:.2f}
- å¸åœˆææ…Œè´ªå©ª: {vol['Crypto_Val']} ({vol['Crypto_Text']})
- PCR: {opt['PCR']:.2f}

## å››ã€äº¤æ˜“å¾®è§‚ç»“æ„
- æœŸè´§åŸºå·®: {deriv['Futures_Basis']:.1f} ({deriv['Basis_Status']})
- Gamma ç¯å¢ƒ: {deriv['GEX_Net']}
- Vanna çŠ¶æ€: {deriv['Vanna_Status']}
- Put Wall: ${deriv['Put_Wall']:.0f}
- Call Wall: ${deriv['Call_Wall']:.0f}

## äº”ã€GEX åˆ†æ
- å½“å‰ä»·æ ¼: ${gex_data['spot_price']:.2f}
- å‡€ GEX: {gex_data['total_gex']:.2f}B
- Gamma Flip Point: ${gex_data['gamma_flip']:.2f}
- Max Pain: ${gex_data['max_pain']:.2f}
- GEX Put Wall: ${gex_data['put_wall']:.2f}
- GEX Call Wall: ${gex_data['call_wall']:.2f}

## å…­ã€è§„åˆ™å¼•æ“ä¿¡å·
å¸‚åœºçŠ¶æ€: {regime_analysis['regime'].upper()}
ç»¼åˆè¯„åˆ†: {regime_analysis['score']:.1f}

å…³é”®ä¿¡å·:
"""
    
    for sig in regime_analysis['signals']:
        export_text += f"- [{sig['level']}] {sig['msg']}\n"
    
    export_text += "\n## ä¸ƒã€é‡ç‚¹æ–°é—»\n"
    for item in processed_news[:10]:
        cats = ", ".join(item.get('Categories', ['general']))
        export_text += f"- [{cats}] {item['Title']} (é‡è¦æ€§: {item.get('Importance', 0)})\n"
    
    export_text += """
---
è¯·åŸºäºä»¥ä¸Šæ•°æ®è¿›è¡Œæ·±åº¦åˆ†æ:
1. å½“å‰å¸‚åœºå¤„äºä»€ä¹ˆå®è§‚å‘¨æœŸï¼Ÿ
2. æµåŠ¨æ€§ç¯å¢ƒå¯¹é£é™©èµ„äº§çš„å½±å“ï¼Ÿ
3. æœ‰å“ªäº›æ½œåœ¨çš„é£é™©ç‚¹ï¼Ÿ
4. ä»Šæ—¥äº¤æ˜“çš„æœ€ä½³ç­–ç•¥æ˜¯ä»€ä¹ˆï¼Ÿ
"""
    
    return export_text

# ============================================================
# 8. å†å²ç»Ÿè®¡ (ä¿ç•™åŸæœ‰)
# ============================================================

@st.cache_data(ttl=86400)
def get_qqq_historical_stats():
    res = {}
    try:
        df = yf.download("QQQ", period="3y", interval="1d", progress=False)
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(0)
        
        df['Range'] = df['High'] - df['Low']
        df['Body'] = df['Close'] - df['Open']
        df['Abs_Body'] = df['Body'].abs()
        df['Efficiency'] = df['Abs_Body'] / df['Range']
        
        conditions = [
            (df['Efficiency'] > 0.5) & (df['Body'] > 0),
            (df['Efficiency'] > 0.5) & (df['Body'] < 0),
            (df['Efficiency'] <= 0.5)
        ]
        choices = ['Trend_Up', 'Trend_Down', 'Choppy']
        df['Type'] = np.select(conditions, choices, default='Choppy')
        
        counts = df['Type'].value_counts()
        total_days = len(df)
        
        res['Up_Days'] = counts.get('Trend_Up', 0)
        res['Down_Days'] = counts.get('Trend_Down', 0)
        res['Chop_Days'] = counts.get('Choppy', 0)
        
        res['Up_Pct'] = round((res['Up_Days'] / total_days) * 100, 1)
        res['Down_Pct'] = round((res['Down_Days'] / total_days) * 100, 1)
        res['Chop_Pct'] = round((res['Chop_Days'] / total_days) * 100, 1)
        
        res['Avg_Range'] = df['Range'].mean()
        res['Avg_Range_Pct'] = (df['Range'] / df['Open']).mean() * 100
        
    except Exception as e: 
        pass
    return res

# ============================================================
# UI æ¸²æŸ“
# ============================================================

# æ•°æ®åŠ è½½
with st.spinner("æ­£åœ¨èšåˆå…¨å¸‚åœºæ•°æ®..."):
    ai_model = load_ai_model()
    ny_fed = get_ny_fed_data()
    fed_liq = get_fed_liquidity()
    credit = get_credit_spreads()
    rates = get_rates_and_fx()
    vol = get_volatility_indices()
    opt = get_qqq_options_data()
    deriv = get_derivatives_structure()
    tactics = get_intraday_tactics()
    
    # æ–°å¢æ•°æ®
    sofr_repo_hist = get_sofr_repo_history()
    rrp_tga_hist = get_rrp_tga_history()
    raw_news = get_multi_source_news()
    calendar_events = get_macro_calendar_with_countdown()
    gex_data = calculate_gex_profile()
    
    # æ–°é—»æƒ…ç»ªåˆ†æ
    processed_news = []
    sentiment_total = 0
    weighted_sentiment = 0
    total_weight = 0
    
    if not raw_news.empty:
        for i, row in raw_news.head(15).iterrows():
            try:
                res = ai_model(row['Title'][:512])[0]
                label = res['label']
                score = res['score']
                sent = "Neutral"; val = 0
                if label == 'positive' and score > 0.5: sent="Bullish"; val=1
                elif label == 'negative' and score > 0.5: sent="Bearish"; val=-1
                
                importance = row.get('Importance', 1)
                weighted_sentiment += val * importance
                total_weight += importance
                sentiment_total += val
                
                processed_news.append({
                    **row.to_dict(), 
                    "Sentiment": sent,
                    "SentimentScore": val
                })
            except: pass
        
        avg_news_score = sentiment_total / max(1, len(processed_news))
        weighted_news_score = weighted_sentiment / max(1, total_weight)
    else: 
        avg_news_score = 0
        weighted_news_score = 0
    
    # è§„åˆ™å¼•æ“åˆ†æ
    regime_analysis = analyze_market_regime(ny_fed, fed_liq, credit, rates, vol, opt, deriv, rrp_tga_hist)
    
    # åŸæœ‰è¯„åˆ†ç³»ç»Ÿ
    final_score, flags, summary, action = calculate_macro_score(ny_fed, fed_liq, credit, rates, vol, opt, deriv, avg_news_score)

# ============================================================
# HEADER
# ============================================================
st.title("ğŸ¦… å®è§‚æˆ˜æƒ…è§‚å¯Ÿå®¤")
current_time = datetime.datetime.now(pytz.timezone('US/Eastern')).strftime('%Y-%m-%d %H:%M EST')
st.caption(f"Update: {current_time}")

# æˆ˜æƒ…ç»¼è¿°
summary_class = "summary-bull" if final_score > 3 else "summary-bear" if final_score < -3 else "summary-neutral"
regime_text = "ğŸŸ¢ Risk-On" if regime_analysis['regime'] == 'risk_on' else "ğŸ”´ Risk-Off" if regime_analysis['regime'] == 'risk_off' else "âšª Neutral"

st.markdown(f"""
<div class="summary-box {summary_class}">
    <h3>ğŸ›¡ï¸ æˆ˜æƒ…ç»¼è¿° (Score: {final_score}) | å¸‚åœºçŠ¶æ€: {regime_text}</h3>
    <p style="font-size:1.1em;">{summary}</p>
    <p><strong>ğŸš¨ å¼‚å¸¸æŒ‡æ ‡ç›‘æ§ (Flags):</strong> { '  |  '.join(flags) }</p>
    <hr style="border-top: 1px dashed #ccc;">
    <p style="font-weight:bold;">{action}</p>
</div>
""", unsafe_allow_html=True)

st.divider()

# ============================================================
# 1. æµåŠ¨æ€§ç›‘æ§ (å¸¦å›¾è¡¨)
# ============================================================
st.subheader("1. ğŸ’§ æµåŠ¨æ€§ç›‘æ§")

l1, l2, l3, l4, l5 = st.columns(5)
l1.metric("SOFR", f"{ny_fed['SOFR']:.2f}%", f"Spread: {ny_fed['SOFR'] - ny_fed['TGCR']:.3f}")
l2.metric("Repo (TGCR)", f"{ny_fed['TGCR']:.2f}%")
l3.metric("RRP", f"${fed_liq['RRP']:.0f}B", f"{fed_liq['RRP_Chg']:.0f}B", delta_color="inverse")
l4.metric("TGA", f"${fed_liq['TGA']:.0f}B", f"{fed_liq['TGA_Chg']:.0f}B", delta_color="inverse")
l5.metric("HYG/LQD", f"{credit[0]:.3f}", f"{credit[1]:.2f}%", help="é£é™©åå¥½æŒ‡æ ‡")

with st.expander("ğŸ“Š æµåŠ¨æ€§å†å²å›¾è¡¨ (30å¤©)", expanded=True):
    tab1, tab2 = st.tabs(["SOFR / Repo åˆ©å·®", "RRP / TGA"])
    
    with tab1:
        if sofr_repo_hist['dates']:
            fig = make_subplots(rows=2, cols=1, shared_xaxes=True, 
                               vertical_spacing=0.1,
                               subplot_titles=("SOFR vs Repo åˆ©ç‡", "SOFR-Repo åˆ©å·®"))
            
            fig.add_trace(go.Scatter(x=sofr_repo_hist['dates'], y=sofr_repo_hist['sofr'],
                                    name='SOFR', line=dict(color='#0d6efd', width=2)), row=1, col=1)
            fig.add_trace(go.Scatter(x=sofr_repo_hist['dates'], y=sofr_repo_hist['tgcr'],
                                    name='TGCR (Repo)', line=dict(color='#198754', width=2)), row=1, col=1)
            
            spread_colors = ['#dc3545' if s > 0.05 else '#ffc107' if s > 0.02 else '#198754' for s in sofr_repo_hist['spread']]
            fig.add_trace(go.Bar(x=sofr_repo_hist['dates'], y=sofr_repo_hist['spread'],
                                name='åˆ©å·®', marker_color=spread_colors), row=2, col=1)
            fig.add_hline(y=0.05, line_dash="dash", line_color="red", annotation_text="è­¦æˆ’çº¿", row=2, col=1)
            
            fig.update_layout(height=400, showlegend=True, legend=dict(orientation="h", yanchor="bottom", y=1.02))
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("SOFR/Repo å†å²æ•°æ®æš‚ä¸å¯ç”¨")
    
    with tab2:
        if rrp_tga_hist['dates']:
            fig2 = make_subplots(rows=2, cols=1, shared_xaxes=True,
                                vertical_spacing=0.1,
                                subplot_titles=("RRP (éš”å¤œé€†å›è´­)", "TGA (è´¢æ”¿éƒ¨è´¦æˆ·)"))
            
            fig2.add_trace(go.Scatter(x=rrp_tga_hist['dates'], y=rrp_tga_hist['rrp'],
                                     name='RRP', fill='tozeroy', line=dict(color='#6f42c1', width=2)), row=1, col=1)
            fig2.add_trace(go.Scatter(x=rrp_tga_hist['dates'], y=rrp_tga_hist['tga'],
                                     name='TGA', fill='tozeroy', line=dict(color='#fd7e14', width=2)), row=2, col=1)
            
            fig2.update_layout(height=400, showlegend=True, legend=dict(orientation="h", yanchor="bottom", y=1.02))
            st.plotly_chart(fig2, use_container_width=True)
        else:
            st.info("RRP/TGA å†å²æ•°æ®æš‚ä¸å¯ç”¨")

st.divider()

# ============================================================
# 2. ç¾å€ºä¸æ±‡ç‡
# ============================================================
st.subheader("2. ğŸ“ˆ ç¾å€ºä¸æ±‡ç‡")
r1, r2, r3, r4, r5 = st.columns(5)
r1.metric("10Y æ”¶ç›Šç‡", f"{rates['Yield_10Y']:.2f}%", help="å…¨çƒèµ„äº§å®šä»·ä¹‹é”š")
r2.metric("MOVE", f"{rates['MOVE']:.2f}", help="å€ºå¸‚ææ…ŒæŒ‡æ•°")
r3.metric("10Y/3M å€’æŒ‚", f"{rates['Inversion']:.2f}%", help="æ”¶ç›Šç‡æ›²çº¿")
r4.metric("DXY", f"{rates['DXY']:.2f}")
r5.metric("USDJPY", f"{rates['USDJPY']:.2f}")

st.divider()

# ============================================================
# 3. äº¤æ˜“ç»“æ„ + GEX Profile
# ============================================================
st.subheader("3. ğŸ¯ äº¤æ˜“ä¸å¾®è§‚ç»“æ„")

t1, t2, t3, t4 = st.columns(4)
t1.metric("PCR", f"{opt['PCR']}", help="Put/Call Ratio")
t2.metric("VIX", f"{vol['VIX']:.2f}")
t3.metric("å¸åœˆææ…Œ", f"{vol['Crypto_Val']}", f"{vol['Crypto_Text']}")
t4.metric("åŸºå·®", f"{deriv['Futures_Basis']:.2f}", deriv['Basis_Status'])

g1, g2, g3, g4 = st.columns(4)
g1.metric("Gamma", deriv['GEX_Net'])
g2.metric("Vanna", deriv['Vanna_Status'])
g3.metric("Put Wall", f"${deriv['Put_Wall']}")
g4.metric("Call Wall", f"${deriv['Call_Wall']}")

with st.expander("ğŸ“Š Gamma Exposure (GEX) Profile", expanded=True):
    # æ˜¾ç¤ºæ•°æ®æ—¶é—´æˆ³
    gex_time_col1, gex_time_col2, gex_time_col3 = st.columns(3)
    with gex_time_col1:
        st.caption(f"ğŸ“… OI æ•°æ®æ—¥æœŸ: **{gex_data.get('oi_date', 'N/A')}** ({gex_data.get('oi_weekday', '')})")
    with gex_time_col2:
        st.caption(f"â° è®¡ç®—æ—¶é—´: **{gex_data.get('calc_time', 'N/A')}**")
    with gex_time_col3:
        st.caption("ğŸ’¡ OI æ¯å¤©ç›˜å‰æ›´æ–°ï¼Œåæ˜ å‰ä¸€äº¤æ˜“æ—¥æ”¶ç›˜æŒä»“")
    
    if gex_data['strikes']:
        col_gex1, col_gex2 = st.columns([2, 1])
        
        with col_gex1:
            fig_gex = go.Figure()
            
            fig_gex.add_trace(go.Bar(
                x=gex_data['strikes'],
                y=gex_data['gex_call'],
                name='Call GEX',
                marker_color='#198754',
                opacity=0.7
            ))
            
            fig_gex.add_trace(go.Bar(
                x=gex_data['strikes'],
                y=gex_data['gex_put'],
                name='Put GEX',
                marker_color='#dc3545',
                opacity=0.7
            ))
            
            fig_gex.add_trace(go.Scatter(
                x=gex_data['strikes'],
                y=gex_data['gex_net'],
                name='Net GEX',
                line=dict(color='#0d6efd', width=3)
            ))
            
            fig_gex.add_vline(x=gex_data['spot_price'], line_dash="dash", line_color="yellow",
                             annotation_text=f"ç°ä»· ${gex_data['spot_price']:.2f}")
            
            if gex_data['gamma_flip'] > 0:
                fig_gex.add_vline(x=gex_data['gamma_flip'], line_dash="dot", line_color="orange",
                                 annotation_text=f"Gamma Flip ${gex_data['gamma_flip']:.0f}")
            
            fig_gex.update_layout(
                title="GEX Distribution by Strike",
                xaxis_title="Strike Price",
                yaxis_title="GEX (Billions $)",
                barmode='relative',
                height=400,
                legend=dict(orientation="h", yanchor="bottom", y=1.02)
            )
            
            st.plotly_chart(fig_gex, use_container_width=True)
        
        with col_gex2:
            st.markdown("#### ğŸ“ å…³é”®ä½ç½®")
            st.metric("å½“å‰ä»·æ ¼", f"${gex_data['spot_price']:.2f}")
            st.metric("å‡€ GEX", f"{gex_data['total_gex']:.2f}B", 
                     "æ­£ Gamma âœ…" if gex_data['total_gex'] > 0 else "è´Ÿ Gamma âš ï¸")
            st.metric("Gamma Flip", f"${gex_data['gamma_flip']:.2f}" if gex_data['gamma_flip'] > 0 else "N/A")
            st.metric("Max Pain", f"${gex_data['max_pain']:.2f}" if gex_data['max_pain'] > 0 else "N/A")
            st.metric("GEX Put Wall", f"${gex_data['put_wall']:.2f}" if gex_data['put_wall'] > 0 else "N/A")
            st.metric("GEX Call Wall", f"${gex_data['call_wall']:.2f}" if gex_data['call_wall'] > 0 else "N/A")
            
            st.markdown("---")
            st.markdown("**è§£è¯»:**")
            if gex_data['total_gex'] > 0:
                st.success("æ­£ Gamma: åšå¸‚å•†é«˜æŠ›ä½å¸ï¼Œæ³¢åŠ¨æ”¶æ•›")
            else:
                st.warning("è´Ÿ Gamma: åšå¸‚å•†è¿½æ¶¨æ€è·Œï¼Œæ³¢åŠ¨æ”¾å¤§")
    else:
        st.info("GEX æ•°æ®è®¡ç®—ä¸­...")

with st.expander("ğŸ“š æˆ˜æœ¯æ‰‹å†Œï¼šæŒ‡æ ‡æ·±åº¦è§£è¯»", expanded=False):
    st.markdown("""
    **1. HYG/LQD (ä¿¡è´·è„‰æ)**
    *   **å®šä¹‰**: é«˜æ”¶ç›Šå€º(Junk Bond)ä¸æŠ•èµ„çº§å€º(Corp Bond)çš„ä»·æ ¼æ¯”ç‡ã€‚
    *   **ç”¨æ³•**: å®ƒæ˜¯è‚¡å¸‚çš„å…ˆè¡ŒæŒ‡æ ‡ã€‚å¦‚æœ QQQ åœ¨æ¶¨ï¼Œä½† HYG/LQD åœ¨è·Œï¼ˆèƒŒç¦»ï¼‰ï¼Œè¯´æ˜èªæ˜çš„å€ºåˆ¸èµ„é‡‘æ­£åœ¨æ’¤é€€ã€‚

    **2. MOVE æŒ‡æ•° (å€ºå¸‚ VIX)**
    *   **å®šä¹‰**: è¡¡é‡ç¾å€ºæ”¶ç›Šç‡çš„æ³¢åŠ¨ç‡ã€‚
    *   **ç”¨æ³•**: MOVE æ˜¯é‡‘èç³»ç»Ÿçš„"åº•å±‚ä½“æ¸©"ã€‚å¦‚æœ MOVE é£™å‡ (>110)ï¼Œæ„å‘³ç€æŠµæŠ¼å“ä»·å€¼ä¸ç¨³å®šã€‚

    **3. GEX (Gamma Exposure)**
    *   **å®šä¹‰**: åšå¸‚å•†æŒæœ‰çš„ Gamma æ•å£æ€»é‡ã€‚
    *   **ç”¨æ³•**: æ­£ GEX = ä½æ³¢åŠ¨åŒºé—´éœ‡è¡; è´Ÿ GEX = é«˜æ³¢åŠ¨å•è¾¹è¡Œæƒ…ã€‚
    *   **Gamma Flip**: æ­£è´Ÿ Gamma ç¿»è½¬çš„ä»·æ ¼ç‚¹ï¼Œæ˜¯å…³é”®æ”¯æ’‘/é˜»åŠ›ã€‚

    **4. Vanna & Charm**
    *   **Vanna**: VIX ä¸‹è·Œæ—¶ï¼Œåšå¸‚å•†ä¹°å›å¯¹å†²ç›˜ï¼ŒåŠ©æ¶¨ (Vanna Rally)ã€‚
    *   **Charm**: æœŸæƒåˆ°æœŸæ—¥å‰ï¼Œä»·æ ¼è¢«å¸é™„åœ¨ä¸»åŠ›æŒä»“åŒºã€‚
    """)

with st.expander("æŸ¥çœ‹å¼‚åŠ¨é›·è¾¾", expanded=False):
    if opt['Unusual']: 
        st.dataframe(pd.DataFrame(opt['Unusual']), use_container_width=True)
    else: 
        st.info("æ— æ˜¾è‘—å¼‚åŠ¨")

st.divider()

# ============================================================
# 4. æ™ºèƒ½è§„åˆ™å¼•æ“åˆ†æ
# ============================================================
st.subheader("4. ğŸ§  æ™ºèƒ½è§„åˆ™å¼•æ“åˆ†æ")

signal_categories = {}
for sig in regime_analysis['signals']:
    cat = sig['category']
    if cat not in signal_categories:
        signal_categories[cat] = []
    signal_categories[cat].append(sig)

cols = st.columns(3)
col_idx = 0

for category, signals in signal_categories.items():
    with cols[col_idx % 3]:
        st.markdown(f"**{category}**")
        for sig in signals:
            if sig['level'] == 'CRITICAL':
                st.error(f"{sig['msg']}")
            elif sig['level'] == 'WARNING':
                st.warning(f"{sig['msg']}")
            elif sig['level'] == 'POSITIVE':
                st.success(f"{sig['msg']}")
            else:
                st.info(f"{sig['msg']}")
    col_idx += 1

st.markdown("---")
# [å¯¼å‡ºåŠŸèƒ½å·²ç§»è‡³é¡µé¢åº•éƒ¨]

st.divider()

# ============================================================
# 5. å®è§‚æ–°é—» (å¤šæº + é‡è¦æ€§æ’åº)
# ============================================================
st.subheader("5. ğŸ“° å®è§‚æ–°é—» (å¤šæºèšåˆ)")

col_stat1, col_stat2, col_stat3 = st.columns(3)
col_stat1.metric("æ–°é—»æƒ…ç»ª", f"{avg_news_score:.2f}", "Bullish" if avg_news_score > 0.2 else "Bearish" if avg_news_score < -0.2 else "Neutral")
col_stat2.metric("åŠ æƒæƒ…ç»ª", f"{weighted_news_score:.2f}", help="æŒ‰é‡è¦æ€§åŠ æƒçš„æƒ…ç»ªåˆ†æ•°")
col_stat3.metric("æ–°é—»æ•°é‡", len(processed_news))

def get_category_tag(cat):
    tag_map = {
        'fed': ('<span class="category-tag tag-fed">Fed</span>', 'ğŸ›ï¸'),
        'boj': ('<span class="category-tag tag-boj">BOJ</span>', 'ğŸ‡¯ğŸ‡µ'),
        'ai': ('<span class="category-tag tag-ai">AI</span>', 'ğŸ¤–'),
        'mag7': ('<span class="category-tag tag-mag7">ä¸ƒå·¨å¤´</span>', 'ğŸ’'),
        'crypto': ('<span class="category-tag tag-crypto">Crypto</span>', 'â‚¿'),
        'macro': ('<span class="category-tag tag-macro">Macro</span>', 'ğŸ“Š'),
        'general': ('<span class="category-tag" style="background:#6c757d;color:white;">General</span>', 'ğŸ“°')
    }
    return tag_map.get(cat, tag_map['general'])

if processed_news:
    all_cats = set()
    for item in processed_news:
        all_cats.update(item.get('Categories', ['general']))
    
    selected_cat = st.selectbox("ç­›é€‰åˆ†ç±»", ["å…¨éƒ¨"] + sorted(list(all_cats)))
    
    for item in processed_news[:20]:
        cats = item.get('Categories', ['general'])
        
        if selected_cat != "å…¨éƒ¨" and selected_cat not in cats:
            continue
        
        importance = item.get('Importance', 0)
        sentiment = item.get('Sentiment', 'Neutral')
        
        if sentiment == "Bullish":
            css_class = "news-card news-bull"
        elif sentiment == "Bearish":
            css_class = "news-card news-bear"
        else:
            css_class = "news-card news-neutral"
        
        stars = "â­" * min(importance, 5)
        
        cat_tags = ""
        for cat in cats:
            tag_html, _ = get_category_tag(cat)
            cat_tags += tag_html
        
        st.markdown(f"""
        <div class="{css_class}">
            <div>{cat_tags} {stars}</div>
            <strong>[{sentiment}]</strong> <a href="{item['Link']}" target="_blank">{item['Title']}</a>
            <br><small>æ¥æº: {item['Source']}</small>
        </div>
        """, unsafe_allow_html=True)
else:
    st.write("æš‚æ— æ–°é—»")

st.divider()

# ============================================================
# 6. å®è§‚æ—¥å† (å¸¦å€’è®¡æ—¶)
# ============================================================
st.subheader("6. ğŸ“… å®è§‚æ—¥å†")

if calendar_events:
    urgent_events = [e for e in calendar_events if e['urgency'] == 'urgent']
    soon_events = [e for e in calendar_events if e['urgency'] == 'soon']
    normal_events = [e for e in calendar_events if e['urgency'] == 'normal']
    
    if urgent_events:
        st.markdown("### ğŸ”´ ç´§æ€¥å…³æ³¨")
        for evt in urgent_events:
            st.markdown(f"""
            <div class="calendar-urgent">
                <strong>{evt['countdown']}</strong> | {evt['date']} | {evt['event']}
                <span style="float:right;">{'â­' * evt['importance']}</span>
            </div>
            """, unsafe_allow_html=True)
    
    if soon_events:
        st.markdown("### ğŸŸ  è¿‘æœŸäº‹ä»¶")
        for evt in soon_events:
            st.markdown(f"""
            <div class="calendar-soon">
                <strong>{evt['countdown']}</strong> | {evt['date']} | {evt['event']}
                <span style="float:right;">{'â­' * evt['importance']}</span>
            </div>
            """, unsafe_allow_html=True)
    
    with st.expander(f"ğŸ“‹ æ›´å¤šäº‹ä»¶ ({len(normal_events)} ä¸ª)", expanded=False):
        for evt in normal_events:
            st.markdown(f"""
            <div class="calendar-normal">
                <strong>{evt['countdown']}</strong> | {evt['date']} | {evt['event']}
                <span style="float:right;">{'â­' * evt['importance']}</span>
            </div>
            """, unsafe_allow_html=True)
else:
    st.info("æš‚æ— æ—¥å†æ•°æ®")

st.divider()

# ============================================================
# 7. æ—¥å†…æˆ˜æœ¯
# ============================================================
st.subheader("7. âš”ï¸ æ—¥å†…æˆ˜æœ¯é¢æ¿")
st.caption(f"Snapshot: {tactics['Last_Update']}")

c_day1, c_day2, c_day3, c_day4 = st.columns(4)
c_day1.metric("VWAP", f"${tactics['VWAP']:.2f}", tactics['Trend'], delta_color="off")
c_day2.metric("é¢„æœŸæ³¢åŠ¨", f"Â±${tactics['Exp_Move']:.2f}")
c_day3.metric("0DTE æƒ…ç»ª", tactics['0DTE_Sentiment'])

vwap_val = tactics['VWAP']
delta_str = "N/A"
if vwap_val > 0:
    pct = ((tactics['Price'] - vwap_val) / vwap_val) * 100
    delta_str = f"{pct:.2f}% vs VWAP"

c_day4.metric("QQQ ç°ä»·", f"${tactics['Price']:.2f}", delta_str)

with st.expander("ğŸ¹ æ—¥å†…æŒ‡å—", expanded=True):
    st.write(f"ä¸Šè½¨: ${tactics['Upper_Band']:.2f} | ä¸‹è½¨: ${tactics['Lower_Band']:.2f}")
    st.write("ç­–ç•¥: ä»·æ ¼ > VWAP é€¢ä½å¤š; ä»·æ ¼ < VWAP é€¢é«˜ç©ºã€‚")

st.divider()

# ============================================================
# 8. å†å²ç»Ÿè®¡ (ä¿ç•™åŸæœ‰)
# ============================================================
st.subheader("8. ğŸ“Š ç­–ç•¥å›æµ‹ï¼šè¿‡å»3å¹´ QQQ Kçº¿å½¢æ€ç»Ÿè®¡")

with st.spinner("æ­£åœ¨å›æµ‹è¿‡å» 3 å¹´ K çº¿æ•°æ®..."):
    stats = get_qqq_historical_stats()

if stats:
    c_stat1, c_stat2 = st.columns([1, 2])
    
    with c_stat1:
        st.markdown("#### ğŸ“Š å¸‚åœºæ€§æ ¼ç”»åƒ")
        st.metric("éœ‡è¡/å‡å€¼å›å½’æ¦‚ç‡", f"{stats['Chop_Pct']}%", f"{stats['Chop_Days']} å¤©", delta_color="off")
        st.metric("å•è¾¹ä¸Šæ¶¨æ¦‚ç‡", f"{stats['Up_Pct']}%", f"{stats['Up_Days']} å¤©", delta_color="normal")
        st.metric("å•è¾¹ä¸‹è·Œæ¦‚ç‡", f"{stats['Down_Pct']}%", f"{stats['Down_Days']} å¤©", delta_color="inverse")
        
        st.info(f"ğŸ’¡ **æ—¥å†…å¹³å‡æ³¢å¹… (ATR)**: ${stats['Avg_Range']:.2f} ({stats['Avg_Range_Pct']:.2f}%)")

    with c_stat2:
        st.markdown("#### ğŸ§  é‡åŒ–äº¤æ˜“å¯ç¤ºå½•")
        
        if stats['Chop_Pct'] > 50:
            strategy = "ğŸ›¡ï¸ **é¦–é€‰ç­–ç•¥: å‡å€¼å›å½’ (Mean Reversion)**"
            details = """
            *   **ä¸è¦è¿½æ¶¨æ€è·Œ**: çªç ´ä¹°å…¥çš„èƒœç‡å¾ˆä½ã€‚
            *   **VWAP æˆ˜æ³•**: ä»·æ ¼åç¦» VWAP è¿‡è¿œæ—¶ï¼Œå¤§æ¦‚ç‡ä¼šå›å½’ã€‚
            *   **æœŸæƒ**: é€‚åˆå–æ–¹ç­–ç•¥ (Iron Condor) æˆ–åœ¨å…³é”®æ”¯æ’‘é˜»åŠ›ä½åšåè½¬ã€‚
            """
        else:
            strategy = "ğŸš€ **é¦–é€‰ç­–ç•¥: è¶‹åŠ¿è·Ÿéš (Trend Following)**"
            details = """
            *   **é¡ºåŠ¿è€Œä¸º**: çªç ´å…³é”®ç‚¹ä½åæœæ–­è¿½å•ã€‚
            *   **VWAP æˆ˜æ³•**: å›è¸© VWAP ä¸ç ´æ˜¯æœ€ä½³ä¸Šè½¦ç‚¹ã€‚
            *   **æœŸæƒ**: ä¹°å…¥ Call/Put èµŒå•è¾¹ã€‚
            """
            
        st.success(f"{strategy}")
        st.markdown(details)
        
        st.markdown("""
        ---
        **æ•°æ®è§£è¯»**:
        *   **éœ‡è¡æ—¥ (Choppy)**: æ”¶ç›˜ä»·å›æ’¤ï¼Œç•™æœ‰é•¿å½±çº¿ã€‚é€‚åˆ **é«˜æŠ›ä½å¸**ã€‚
        *   **è¶‹åŠ¿æ—¥ (Trend)**: æ”¶ç›˜ä»·åœ¨å…¨å¤©æœ€é«˜/æœ€ä½é™„è¿‘ã€‚é€‚åˆ **æŒæœ‰åˆ°æ”¶ç›˜**ã€‚
        *   **ç»Ÿè®¡ç»“è®º**: ç¾è‚¡å¤§éƒ¨åˆ†æ—¶é—´ (çº¦ 60%+) å¤„äºéœ‡è¡ä¸­ï¼Œå•è¾¹æš´è·Œæˆ–æš´æ¶¨å…¶å®æ˜¯å°‘æ•°ã€‚**æ—¥å†…äº¤æ˜“åˆ‡å¿Œé¢‘ç¹æ­¢æŸå»èµŒçªç ´ã€‚**
        """)



# ============================================================================
# äº§å“é…ç½®
# ============================================================================
PRODUCT_CONFIG = {
    'ES': {
        'name': 'ES (E-mini S&P 500)',
        'default_atr': 20,
        'price_format': '#.00',
        'description': 'ESä»·æ ¼çº¦6000-7000ç‚¹ï¼ŒATRçº¦15-25ç‚¹'
    },
    'NQ': {
        'name': 'NQ (E-mini Nasdaq 100)',
        'default_atr': 80,
        'price_format': '#.00',
        'description': 'NQä»·æ ¼çº¦20000-22000ç‚¹ï¼ŒATRçº¦60-100ç‚¹'
    }
}

# ============================================================================
# æ ¸å¿ƒè®¡ç®—å‡½æ•°
# ============================================================================

def load_and_prepare_data(uploaded_file):
    """åŠ è½½å¹¶å‡†å¤‡æ•°æ®"""
    df = pd.read_csv(uploaded_file)
    
    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
    try:
        df['time'] = pd.to_datetime(df['time'], format='%Y/%m/%d')
    except:
        try:
            df['time'] = pd.to_datetime(df['time'], format='%Y-%m-%d')
        except:
            df['time'] = pd.to_datetime(df['time'])
    
    df = df.sort_values('time').reset_index(drop=True)
    
    # è®¡ç®—ATR(14)
    df['tr'] = np.maximum(
        df['high'] - df['low'],
        np.maximum(
            abs(df['high'] - df['close'].shift(1)),
            abs(df['low'] - df['close'].shift(1))
        )
    )
    df['atr'] = df['tr'].rolling(window=14).mean()
    
    # è®¡ç®—ATRå‡å€¼ï¼ˆç”¨äºåˆ¤æ–­ATRæ‰©å¼ ï¼‰
    df['atr_ma'] = df['atr'].rolling(window=20).mean()
    
    return df


def find_swing_candidates(df, left_bars=3):
    """
    æ‰¾å‡ºå€™é€‰Swingç‚¹
    Swing High: å½“æ—¥High > å‰left_barsæ—¥æ‰€æœ‰High
    Swing Low: å½“æ—¥Low < å‰left_barsæ—¥æ‰€æœ‰Low
    """
    swing_highs = []
    swing_lows = []
    
    for i in range(left_bars, len(df)):
        # æ£€æŸ¥Swing High
        current_high = df.iloc[i]['high']
        is_swing_high = True
        for j in range(1, left_bars + 1):
            if df.iloc[i - j]['high'] >= current_high:
                is_swing_high = False
                break
        if is_swing_high:
            swing_highs.append(i)
        
        # æ£€æŸ¥Swing Low
        current_low = df.iloc[i]['low']
        is_swing_low = True
        for j in range(1, left_bars + 1):
            if df.iloc[i - j]['low'] <= current_low:
                is_swing_low = False
                break
        if is_swing_low:
            swing_lows.append(i)
    
    return swing_highs, swing_lows


def validate_directional_extension(df, idx, is_high, lookforward=5, atr_multiplier=1.5):
    """
    æ¡ä»¶ä¸€ï¼šéªŒè¯æ–¹å‘æ€§å»¶ä¼¸
    - è‡³å°‘3-5æ ¹åŒæ–¹å‘Kçº¿
    - æ€»ç§»åŠ¨å¹…åº¦ >= 1.5 Ã— ATR
    - æœªè¢«å¿«é€Ÿå®Œå…¨åå‘åæ²¡
    """
    if idx + lookforward >= len(df):
        return False, 0
    
    atr = df.iloc[idx]['atr']
    if pd.isna(atr):
        return False, 0
    
    required_move = atr * atr_multiplier
    
    if is_high:
        # Swing Highååº”è¯¥å‘ä¸‹å»¶ä¼¸
        start_price = df.iloc[idx]['high']
        min_price = df.iloc[idx + 1: idx + lookforward + 1]['low'].min()
        move = start_price - min_price
        
        # æ£€æŸ¥æ˜¯å¦è¢«å¿«é€Ÿåæ²¡ï¼ˆåç»­Kçº¿æ²¡æœ‰ç«‹å³åˆ›æ–°é«˜ï¼‰
        max_high_after = df.iloc[idx + 1: idx + lookforward + 1]['high'].max()
        if max_high_after > start_price:
            return False, 0
    else:
        # Swing Lowååº”è¯¥å‘ä¸Šå»¶ä¼¸
        start_price = df.iloc[idx]['low']
        max_price = df.iloc[idx + 1: idx + lookforward + 1]['high'].max()
        move = max_price - start_price
        
        # æ£€æŸ¥æ˜¯å¦è¢«å¿«é€Ÿåæ²¡
        min_low_after = df.iloc[idx + 1: idx + lookforward + 1]['low'].min()
        if min_low_after < start_price:
            return False, 0
    
    return move >= required_move, move


def validate_structure_break(df, swing_highs, swing_lows, idx, is_high):
    """
    æ¡ä»¶äºŒï¼šæ‰“ç ´å‰ä¸€è½®ç»“æ„
    Swing Highæœ‰æ•ˆï¼šåç»­ä»·æ ¼çªç ´äº†å‰ä¸€ä¸ªLower High
    Swing Lowæœ‰æ•ˆï¼šåç»­ä»·æ ¼çªç ´äº†å‰ä¸€ä¸ªHigher Low
    """
    if is_high:
        prev_highs = [h for h in swing_highs if h < idx]
        if len(prev_highs) < 2:
            return True
        
        prev_high_idx = prev_highs[-1]
        prev_prev_high_idx = prev_highs[-2]
        
        current_high = df.iloc[idx]['high']
        prev_high = df.iloc[prev_high_idx]['high']
        prev_prev_high = df.iloc[prev_prev_high_idx]['high']
        
        if current_high > prev_high or (prev_high < prev_prev_high and current_high > prev_high):
            return True
    else:
        prev_lows = [l for l in swing_lows if l < idx]
        if len(prev_lows) < 2:
            return True
        
        prev_low_idx = prev_lows[-1]
        prev_prev_low_idx = prev_lows[-2]
        
        current_low = df.iloc[idx]['low']
        prev_low = df.iloc[prev_low_idx]['low']
        prev_prev_low = df.iloc[prev_prev_low_idx]['low']
        
        if current_low < prev_low or (prev_low > prev_prev_low and current_low < prev_low):
            return True
    
    return False


def check_volatility_expansion(df, idx):
    """
    æ¡ä»¶ä¸‰ï¼ˆåŠ åˆ†é¡¹ï¼‰ï¼šæ³¢åŠ¨ç‡æ‰©å¼ 
    å½“æ—¥ATR > 1.3 Ã— ATRå‡å€¼
    """
    atr = df.iloc[idx]['atr']
    atr_ma = df.iloc[idx]['atr_ma']
    
    if pd.isna(atr) or pd.isna(atr_ma):
        return False
    
    return atr > atr_ma * 1.3


def classify_structure_level(df, idx, is_high, move_size, has_volatility_expansion):
    """
    ç»“æ„åˆ†çº§
    ä¸€çº§ï¼šè¶‹åŠ¿èµ·ç‚¹/ç»ˆç‚¹/åè½¬ç‚¹ + æ³¢åŠ¨ç‡æ‰©å¼ 
    äºŒçº§ï¼šè¶‹åŠ¿ä¸­æ®µå›æ’¤ç‚¹
    """
    atr = df.iloc[idx]['atr']
    if pd.isna(atr):
        return 2
    
    if move_size > atr * 2 and has_volatility_expansion:
        return 1
    
    if move_size > atr * 2.5:
        return 1
    
    return 2


def calculate_zone(df, idx, is_high, zone_width_multiplier=0.3, default_atr=20):
    """
    è®¡ç®—ZoneåŒºé—´
    åŒºé—´å®½åº¦ = 0.2-0.4 Ã— ATR
    """
    atr = df.iloc[idx]['atr']
    if pd.isna(atr):
        atr = default_atr
    
    zone_width = atr * zone_width_multiplier
    
    if is_high:
        price = df.iloc[idx]['high']
        zone_top = price + zone_width / 2
        zone_bottom = price - zone_width / 2
    else:
        price = df.iloc[idx]['low']
        zone_top = price + zone_width / 2
        zone_bottom = price - zone_width / 2
    
    return zone_top, zone_bottom, price


def analyze_structures(df, default_atr=20, zone_width_multiplier=0.3):
    """
    ä¸»åˆ†æå‡½æ•°ï¼šè¯†åˆ«æ‰€æœ‰åˆæ ¼ç»“æ„ä½
    """
    swing_highs, swing_lows = find_swing_candidates(df, left_bars=3)
    
    structures = []
    
    # åˆ†æSwing Highs
    for idx in swing_highs:
        valid_extension, move_size = validate_directional_extension(df, idx, is_high=True)
        if not valid_extension:
            continue
        
        valid_break = validate_structure_break(df, swing_highs, swing_lows, idx, is_high=True)
        if not valid_break:
            continue
        
        has_vol_expansion = check_volatility_expansion(df, idx)
        level = classify_structure_level(df, idx, is_high=True, move_size=move_size, has_volatility_expansion=has_vol_expansion)
        zone_top, zone_bottom, price = calculate_zone(df, idx, is_high=True, zone_width_multiplier=zone_width_multiplier, default_atr=default_atr)
        
        structures.append({
            'date': df.iloc[idx]['time'],
            'type': 'resistance',
            'level': level,
            'price': price,
            'zone_top': zone_top,
            'zone_bottom': zone_bottom,
            'move_size': move_size,
            'vol_expansion': has_vol_expansion,
            'idx': idx
        })
    
    # åˆ†æSwing Lows
    for idx in swing_lows:
        valid_extension, move_size = validate_directional_extension(df, idx, is_high=False)
        if not valid_extension:
            continue
        
        valid_break = validate_structure_break(df, swing_highs, swing_lows, idx, is_high=False)
        if not valid_break:
            continue
        
        has_vol_expansion = check_volatility_expansion(df, idx)
        level = classify_structure_level(df, idx, is_high=False, move_size=move_size, has_volatility_expansion=has_vol_expansion)
        zone_top, zone_bottom, price = calculate_zone(df, idx, is_high=False, zone_width_multiplier=zone_width_multiplier, default_atr=default_atr)
        
        structures.append({
            'date': df.iloc[idx]['time'],
            'type': 'support',
            'level': level,
            'price': price,
            'zone_top': zone_top,
            'zone_bottom': zone_bottom,
            'move_size': move_size,
            'vol_expansion': has_vol_expansion,
            'idx': idx
        })
    
    return pd.DataFrame(structures)


def get_active_structures(structures_df, current_price):
    """
    è·å–å½“å‰ä»ç„¶æœ‰æ•ˆçš„ç»“æ„ä½
    """
    if structures_df.empty:
        return pd.DataFrame()
    
    active = []
    
    for _, row in structures_df.iterrows():
        if row['type'] == 'resistance':
            if current_price < row['zone_top']:
                active.append(row)
        else:
            if current_price > row['zone_bottom']:
                active.append(row)
    
    return pd.DataFrame(active)


def format_output(structures_df, current_price, product):
    """
    æ ¼å¼åŒ–è¾“å‡ºç»“æœ
    """
    if structures_df.empty:
        return "æœªæ‰¾åˆ°æœ‰æ•ˆç»“æ„ä½"
    
    resistances = structures_df[structures_df['type'] == 'resistance'].sort_values('price', ascending=True)
    supports = structures_df[structures_df['type'] == 'support'].sort_values('price', ascending=False)
    
    output_lines = []
    output_lines.append(f"{product} ç»“æ„ä½åˆ†æ")
    output_lines.append(f"å½“å‰ä»·æ ¼: {current_price:.2f}")
    output_lines.append("=" * 40)
    
    output_lines.append("\nğŸ“ˆ é˜»åŠ›ä½ (Resistance)")
    output_lines.append("-" * 40)
    
    r1_count = 0
    r2_count = 0
    for _, row in resistances.iterrows():
        level_str = "â˜…ä¸€çº§" if row['level'] == 1 else "äºŒçº§"
        vol_str = " [æ”¾é‡]" if row['vol_expansion'] else ""
        distance = row['price'] - current_price
        output_lines.append(
            f"{level_str}: {row['zone_bottom']:.2f} - {row['zone_top']:.2f} "
            f"(+{distance:.2f}ç‚¹){vol_str}"
        )
        if row['level'] == 1:
            r1_count += 1
        else:
            r2_count += 1
    
    output_lines.append("\nğŸ“‰ æ”¯æ’‘ä½ (Support)")
    output_lines.append("-" * 40)
    
    s1_count = 0
    s2_count = 0
    for _, row in supports.iterrows():
        level_str = "â˜…ä¸€çº§" if row['level'] == 1 else "äºŒçº§"
        vol_str = " [æ”¾é‡]" if row['vol_expansion'] else ""
        distance = current_price - row['price']
        output_lines.append(
            f"{level_str}: {row['zone_bottom']:.2f} - {row['zone_top']:.2f} "
            f"(-{distance:.2f}ç‚¹){vol_str}"
        )
        if row['level'] == 1:
            s1_count += 1
        else:
            s2_count += 1
    
    output_lines.append("\n" + "=" * 40)
    output_lines.append(f"ç»Ÿè®¡: ä¸€çº§é˜»åŠ›{r1_count}ä¸ª, äºŒçº§é˜»åŠ›{r2_count}ä¸ª, ä¸€çº§æ”¯æ’‘{s1_count}ä¸ª, äºŒçº§æ”¯æ’‘{s2_count}ä¸ª")
    
    return "\n".join(output_lines)


def create_chart(df, structures_df, current_price, product):
    """
    åˆ›å»ºKçº¿å›¾å¹¶æ ‡æ³¨ç»“æ„ä½
    """
    fig = make_subplots(rows=2, cols=1, shared_xaxes=True,
                        vertical_spacing=0.03,
                        row_heights=[0.7, 0.3])
    
    fig.add_trace(
        go.Candlestick(
            x=df['time'],
            open=df['open'],
            high=df['high'],
            low=df['low'],
            close=df['close'],
            name=product
        ),
        row=1, col=1
    )
    
    for _, row in structures_df.iterrows():
        color = 'rgba(255, 0, 0, 0.2)' if row['type'] == 'resistance' else 'rgba(0, 255, 0, 0.2)'
        border_color = 'red' if row['type'] == 'resistance' else 'green'
        line_width = 2 if row['level'] == 1 else 1
        
        fig.add_hrect(
            y0=row['zone_bottom'],
            y1=row['zone_top'],
            fillcolor=color,
            line=dict(color=border_color, width=line_width),
            row=1, col=1
        )
        
        level_str = "L1" if row['level'] == 1 else "L2"
        type_str = "R" if row['type'] == 'resistance' else "S"
        fig.add_annotation(
            x=df['time'].iloc[-1],
            y=row['price'],
            text=f"{type_str}{level_str}: {row['price']:.0f}",
            showarrow=False,
            xanchor='left',
            font=dict(size=10, color=border_color),
            row=1, col=1
        )
    
    fig.add_hline(y=current_price, line_dash="dash", line_color="blue",
                  annotation_text=f"å½“å‰: {current_price:.2f}", row=1, col=1)
    
    fig.add_trace(
        go.Scatter(x=df['time'], y=df['atr'], name='ATR(14)', line=dict(color='orange')),
        row=2, col=1
    )
    fig.add_trace(
        go.Scatter(x=df['time'], y=df['atr_ma'], name='ATR MA(20)', line=dict(color='gray', dash='dash')),
        row=2, col=1
    )
    
    fig.update_layout(
        title=f'{product} æ—¥çº¿ç»“æ„ä½åˆ†æ',
        xaxis_rangeslider_visible=False,
        height=800
    )
    
    return fig


# ============================================================================
# Streamlit ç•Œé¢ - ES/NQ ç»“æ„ä½åˆ†æ
# ============================================================================

st.divider()
st.header("9. ğŸ“Š ES/NQ æ—¥çº¿ç»“æ„ä½åˆ†æå™¨")
st.markdown("""
åŸºäºSwing High/Lowè¯†åˆ«æœ‰æ•ˆç»“æ„ä½ï¼Œè¾“å‡ºZoneåŒºé—´ä¾›æ—¥å†…äº¤æ˜“å‚è€ƒã€‚

**ç­›é€‰æ¡ä»¶ï¼š**
1. æ–¹å‘æ€§å»¶ä¼¸ â‰¥ 1.5Ã— ATR
2. æ‰“ç ´å‰ä¸€è½®ç»“æ„å½¢æ€
3. æ³¢åŠ¨ç‡æ‰©å¼ ï¼ˆåŠ åˆ†é¡¹ï¼‰
""")

# ES/NQ åˆ†æå™¨æ§åˆ¶ (å†…ç½®åœ¨ä¸»åŒºåŸŸ)
col_es1, col_es2, col_es3, col_es4, col_es5 = st.columns(5)
with col_es1:
    product = st.selectbox("é€‰æ‹©äº§å“", options=['ES', 'NQ'], format_func=lambda x: PRODUCT_CONFIG[x]['name'])
with col_es2:
    left_bars = st.slider("Swingå·¦ä¾§Kçº¿", 2, 5, 3)
with col_es3:
    lookforward = st.slider("å»¶ä¼¸ç¡®è®¤Kçº¿", 3, 7, 5)
with col_es4:
    atr_multiplier = st.slider("ATRå€æ•°", 1.0, 2.5, 1.5)
with col_es5:
    zone_width = st.slider("Zoneå®½åº¦", 0.2, 0.5, 0.3)

# è·å–äº§å“é…ç½®
config = PRODUCT_CONFIG[product]

# æ–‡ä»¶ä¸Šä¼ 
st.subheader(f"ğŸ“ ä¸Šä¼  {product} æ—¥çº¿æ•°æ®")
uploaded_file = st.file_uploader(f"ä¸Šä¼ {product}æ—¥çº¿CSVæ–‡ä»¶", type=['csv'])

if uploaded_file is not None:
    # åŠ è½½æ•°æ®
    df = load_and_prepare_data(uploaded_file)
    
    st.success(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)}ä¸ªäº¤æ˜“æ—¥ ({df['time'].min().strftime('%Y-%m-%d')} è‡³ {df['time'].max().strftime('%Y-%m-%d')})")
    
    # å½“å‰ä»·æ ¼å’ŒATR
    current_price = df.iloc[-1]['close']
    current_atr = df.iloc[-1]['atr']
    
    st.info(f"ğŸ“Š **{product}** | å½“å‰ä»·æ ¼: {current_price:.2f} | ATR(14): {current_atr:.2f} ç‚¹ | Zoneå®½åº¦çº¦: {current_atr * zone_width:.2f} ç‚¹")
    
    # åˆ†æç»“æ„
    with st.spinner("æ­£åœ¨åˆ†æç»“æ„ä½..."):
        all_structures = analyze_structures(df, default_atr=config['default_atr'], zone_width_multiplier=zone_width)
        active_structures = get_active_structures(all_structures, current_price)
    
    # æ˜¾ç¤ºç»“æœ
    col1, col2 = st.columns([1, 2])
    
    with col1:
        st.subheader("ğŸ“‹ å½“å‰æœ‰æ•ˆç»“æ„ä½")
        output_text = format_output(active_structures, current_price, product)
        st.code(output_text, language=None)
        
        # TradingViewè¾“å…¥æ ¼å¼
        st.subheader("ğŸ“ TradingViewå¿«é€Ÿè¾“å…¥")
        if not active_structures.empty:
            tv_lines = []
            resistances = active_structures[active_structures['type'] == 'resistance'].sort_values('price')
            supports = active_structures[active_structures['type'] == 'support'].sort_values('price', ascending=False)
            
            for i, (_, row) in enumerate(resistances.head(2).iterrows()):
                tv_lines.append(f"R{i+1}_top = {row['zone_top']:.2f}")
                tv_lines.append(f"R{i+1}_bottom = {row['zone_bottom']:.2f}")
            
            for i, (_, row) in enumerate(supports.head(2).iterrows()):
                tv_lines.append(f"S{i+1}_top = {row['zone_top']:.2f}")
                tv_lines.append(f"S{i+1}_bottom = {row['zone_bottom']:.2f}")
            
            st.code("\n".join(tv_lines), language=None)
    
    with col2:
        st.subheader("ğŸ“ˆ Kçº¿å›¾")
        fig = create_chart(df, active_structures, current_price, product)
        st.plotly_chart(fig, use_container_width=True)
    
    # è¯¦ç»†æ•°æ®è¡¨
    with st.expander("æŸ¥çœ‹æ‰€æœ‰æ£€æµ‹åˆ°çš„ç»“æ„ä½"):
        if not all_structures.empty:
            display_df = all_structures.copy()
            display_df['date'] = display_df['date'].dt.strftime('%Y-%m-%d')
            display_df['level'] = display_df['level'].map({1: 'ä¸€çº§', 2: 'äºŒçº§'})
            display_df['type'] = display_df['type'].map({'resistance': 'é˜»åŠ›', 'support': 'æ”¯æ’‘'})
            display_df = display_df[['date', 'type', 'level', 'price', 'zone_top', 'zone_bottom', 'move_size', 'vol_expansion']]
            display_df.columns = ['æ—¥æœŸ', 'ç±»å‹', 'çº§åˆ«', 'ä»·æ ¼', 'Zoneä¸Šæ²¿', 'Zoneä¸‹æ²¿', 'å»¶ä¼¸å¹…åº¦', 'æ”¾é‡']
            st.dataframe(display_df, use_container_width=True)
        else:
            st.info("æœªæ£€æµ‹åˆ°ç¬¦åˆæ¡ä»¶çš„ç»“æ„ä½")

else:
    st.info(f"ğŸ‘† è¯·å…ˆåœ¨å·¦ä¾§é€‰æ‹©äº§å“ï¼ˆES/NQï¼‰ï¼Œç„¶åä¸Šä¼ å¯¹åº”çš„æ—¥çº¿CSVæ–‡ä»¶")
    
    st.markdown("""
    ### å¦‚ä½•å¯¼å‡ºæ•°æ®
    1. åœ¨TradingViewæ‰“å¼€å¯¹åº”äº§å“çš„æ—¥çº¿å›¾
       - ES: `ES1!` æˆ– `ESH2025`
       - NQ: `NQ1!` æˆ– `NQH2025`
    2. ç¡®ä¿æ—¶é—´æ¡†æ¶é€‰æ‹© **1D (æ—¥çº¿)**
    3. å›¾è¡¨å³ä¸Šè§’èœå• â†’ **Export chart data**
    4. ä¸‹è½½CSVæ–‡ä»¶å¹¶ä¸Šä¼ åˆ°è¿™é‡Œ
    
    ### CSVæ ¼å¼è¦æ±‚
    ```
    time,open,high,low,close,Volume
    2025/6/2,5898.75,5955.5,5867.5,5947.25,1194125
    ...
    ```
    
    ### ES vs NQ å‚è€ƒ
    | äº§å“ | ä»·æ ¼èŒƒå›´ | ATRèŒƒå›´ | Zoneå®½åº¦ |
    |------|----------|---------|----------|
    | ES | 6000-7000 | 15-25ç‚¹ | ~6ç‚¹ |
    | NQ | 20000-22000 | 60-100ç‚¹ | ~24ç‚¹ |
    """)
    

# ============================================================================
# ğŸ“Š èµ„é‡‘è½®åŠ¨è¯„åˆ†ç³»ç»Ÿ (Rotation Score System)
# æ·»åŠ åˆ°ç°æœ‰ app.py æœ«å°¾
# ============================================================================

st.divider()
st.header("10. ğŸ“Š èµ„é‡‘è½®åŠ¨è¶‹åŠ¿è¯„åˆ† (Rotation Score)")

st.markdown("""
<div class="summary-box summary-neutral">
<b>ğŸ“ˆ è¶‹åŠ¿è¯„åˆ†ç³»ç»Ÿ</b>ï¼šåŸºäºå¤šå› å­æ¨¡å‹è®¡ç®—å¸‚åœºèµ„é‡‘æµå‘ï¼Œè¾“å‡º -100 åˆ° +100 çš„ç»¼åˆè¯„åˆ†ã€‚
æ­£å€¼ = Risk-On (è¿›æ”»)ï¼Œè´Ÿå€¼ = Risk-Off (é˜²å¾¡)ã€‚ç»“åˆ Gamma ç¯å¢ƒä½¿ç”¨æ•ˆæœæœ€ä½³ã€‚
</div>
""", unsafe_allow_html=True)

# ============================================================================
# é…ç½®åŒºï¼šå› å­å®šä¹‰
# ============================================================================

ROTATION_FACTORS = {
    'risk_appetite': {
        'name': 'é£é™©åå¥½',
        'weight': 0.35,
        'pairs': [
            {'name': 'Beta_Trade', 'numerator': 'SPHB', 'denominator': 'SPLV', 'weight': 0.3, 'desc': 'é«˜è´å¡”/ä½æ³¢åŠ¨'},
            {'name': 'Growth_Value', 'numerator': 'IWF', 'denominator': 'IWD', 'weight': 0.25, 'desc': 'æˆé•¿/ä»·å€¼'},
            {'name': 'Credit_Spread', 'numerator': 'HYG', 'denominator': 'IEF', 'weight': 0.25, 'desc': 'åƒåœ¾å€º/å›½å€º'},
            {'name': 'Speculative', 'numerator': 'ARKK', 'denominator': 'QQQ', 'weight': 0.2, 'desc': 'æŠ•æœº/ä¸»æµ'},
        ]
    },
    'sector_rotation': {
        'name': 'æ¿å—è½®åŠ¨',
        'weight': 0.40,
        'pairs': [
            {'name': 'Tech_Staples', 'numerator': 'XLK', 'denominator': 'XLP', 'weight': 0.25, 'desc': 'ç§‘æŠ€/å¿…éœ€'},
            {'name': 'Semis_Alpha', 'numerator': 'SMH', 'denominator': 'QQQ', 'weight': 0.25, 'desc': 'åŠå¯¼ä½“/çº³æŒ‡'},
            {'name': 'Software_Alpha', 'numerator': 'IGV', 'denominator': 'QQQ', 'weight': 0.20, 'desc': 'è½¯ä»¶/çº³æŒ‡'},
            {'name': 'Cyclical_Defensive', 'numerator': 'XLY', 'denominator': 'XLU', 'weight': 0.15, 'desc': 'å¯é€‰/å…¬ç”¨'},
            {'name': 'Financials', 'numerator': 'XLF', 'denominator': 'SPY', 'weight': 0.15, 'desc': 'é‡‘è/å¤§ç›˜'},
        ]
    },
    'liquidity': {
        'name': 'æµåŠ¨æ€§å¹¿åº¦',
        'weight': 0.25,
        'pairs': [
            {'name': 'Small_Large', 'numerator': 'IWM', 'denominator': 'SPY', 'weight': 0.35, 'desc': 'å°ç›˜/å¤§ç›˜'},
            {'name': 'Equal_Cap', 'numerator': 'RSP', 'denominator': 'SPY', 'weight': 0.35, 'desc': 'ç­‰æƒ/å¸‚å€¼'},
            {'name': 'EM_US', 'numerator': 'EEM', 'denominator': 'SPY', 'weight': 0.30, 'desc': 'æ–°å…´/ç¾è‚¡'},
        ]
    }
}

LOOKBACK_PERIOD = 20  # Z-Score è®¡ç®—çª—å£
Z_SCORE_CLIP = 3.0    # æå€¼å¤„ç†

# ============================================================================
# æ•°æ®è·å–å‡½æ•°
# ============================================================================

@st.cache_data(ttl=3600)  # ç¼“å­˜1å°æ—¶
def get_rotation_data(tickers: list, period: str = "60d") -> pd.DataFrame:
    """è·å–æ‰€æœ‰éœ€è¦çš„ ETF æ•°æ®"""
    try:
        data = yf.download(tickers, period=period, progress=False)
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç©º
        if data.empty:
            st.warning("Yahoo Finance è¿”å›ç©ºæ•°æ®")
            return pd.DataFrame()
        
        # å¤„ç† MultiIndex æ ¼å¼ (æ–°ç‰ˆ yfinance)
        # Level 0 = ä»·æ ¼ç±»å‹ (Close, Adj Close, etc.)
        # Level 1 = Ticker åç§°
        if isinstance(data.columns, pd.MultiIndex):
            # ä¼˜å…ˆä½¿ç”¨ Adj Closeï¼Œå¦åˆ™ç”¨ Close
            if 'Adj Close' in data.columns.get_level_values(0):
                return data['Adj Close']
            elif 'Close' in data.columns.get_level_values(0):
                return data['Close']
            else:
                st.warning("æ•°æ®ä¸­æ²¡æœ‰ Close æˆ– Adj Close åˆ—")
                return pd.DataFrame()
        else:
            # å• ticker æˆ–æ—§ç‰ˆæ ¼å¼
            if 'Adj Close' in data.columns:
                return data[['Adj Close']].rename(columns={'Adj Close': tickers[0]})
            elif 'Close' in data.columns:
                return data[['Close']].rename(columns={'Close': tickers[0]})
            return data
            
    except Exception as e:
        st.warning(f"æ•°æ®è·å–å¤±è´¥: {e}")
        return pd.DataFrame()

def calculate_z_score(series: pd.Series, lookback: int = 20) -> float:
    """è®¡ç®— Z-Score"""
    if len(series) < lookback:
        return 0.0
    
    recent = series.iloc[-lookback:]
    current = series.iloc[-1]
    mean = recent.mean()
    std = recent.std()
    
    if std == 0:
        return 0.0
    
    z = (current - mean) / std
    return np.clip(z, -Z_SCORE_CLIP, Z_SCORE_CLIP)

def calculate_ratio_z_score(data: pd.DataFrame, numerator: str, denominator: str, lookback: int = 20) -> tuple:
    """è®¡ç®—æ¯”ç‡çš„ Z-Score"""
    if numerator not in data.columns or denominator not in data.columns:
        return 0.0, 0.0, 0.0
    
    ratio = data[numerator] / data[denominator]
    ratio = ratio.dropna()
    
    if len(ratio) < lookback:
        return 0.0, 0.0, 0.0
    
    current_ratio = ratio.iloc[-1]
    z_score = calculate_z_score(ratio, lookback)
    
    # è®¡ç®—5æ—¥å˜åŒ–
    if len(ratio) >= 5:
        change_5d = (ratio.iloc[-1] / ratio.iloc[-5] - 1) * 100
    else:
        change_5d = 0.0
    
    return z_score, current_ratio, change_5d

def calculate_rotation_score(data: pd.DataFrame) -> dict:
    """è®¡ç®—ç»¼åˆ Rotation Score"""
    results = {
        'total_score': 0.0,
        'categories': {},
        'factors': [],
        'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M')
    }
    
    total_score = 0.0
    
    for cat_key, category in ROTATION_FACTORS.items():
        cat_score = 0.0
        cat_factors = []
        
        for pair in category['pairs']:
            z_score, ratio, change_5d = calculate_ratio_z_score(
                data, pair['numerator'], pair['denominator'], LOOKBACK_PERIOD
            )
            
            weighted_z = z_score * pair['weight']
            cat_score += weighted_z
            
            factor_result = {
                'name': pair['name'],
                'desc': pair['desc'],
                'pair': f"{pair['numerator']}/{pair['denominator']}",
                'ratio': ratio,
                'z_score': z_score,
                'change_5d': change_5d,
                'weighted': weighted_z,
                'signal': 'bullish' if z_score > 0.5 else 'bearish' if z_score < -0.5 else 'neutral'
            }
            cat_factors.append(factor_result)
            results['factors'].append(factor_result)
        
        # å½’ä¸€åŒ–åˆ° -100 ~ +100
        cat_normalized = (cat_score / Z_SCORE_CLIP) * 100
        results['categories'][cat_key] = {
            'name': category['name'],
            'score': cat_normalized,
            'weight': category['weight'],
            'factors': cat_factors
        }
        
        total_score += cat_normalized * category['weight']
    
    results['total_score'] = np.clip(total_score, -100, 100)
    
    return results

# ============================================================================
# Gamma æ•°æ®è§£æ
# ============================================================================

def parse_gamma_input(text: str) -> dict:
    """è§£æ SpotGamma ç²˜è´´æ•°æ®"""
    result = {
        'zero_gamma': None,
        'call_wall': None,
        'put_wall': None,
        'vol_trigger': None,
        'dex': None,
        'gex': None,
        'levels': []
    }
    
    if not text or not text.strip():
        return result
    
    lines = text.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # å°è¯•è§£æ DEX/GEX
        line_lower = line.lower()
        if 'dex' in line_lower:
            try:
                # æå–æ•°å­—
                import re
                numbers = re.findall(r'-?\d+\.?\d*', line)
                if numbers:
                    result['dex'] = float(numbers[0])
            except:
                pass
            continue
        
        if 'gex' in line_lower and 'zero' not in line_lower:
            try:
                import re
                numbers = re.findall(r'-?\d+\.?\d*', line)
                if numbers:
                    result['gex'] = float(numbers[0])
            except:
                pass
            continue
        
        # è§£æä»·ä½æ•°æ® (Tab æˆ–ç©ºæ ¼åˆ†éš”)
        parts = line.replace('\t', ' ').split()
        if len(parts) >= 2:
            try:
                price = float(parts[0].replace(',', ''))
                level_name = ' '.join(parts[1:]).lower()
                
                result['levels'].append({'price': price, 'name': ' '.join(parts[1:])})
                
                if 'zero gamma' in level_name:
                    result['zero_gamma'] = price
                elif 'call wall' in level_name:
                    result['call_wall'] = price
                elif 'put wall' in level_name:
                    result['put_wall'] = price
                elif 'vol' in level_name and 'trigger' in level_name:
                    result['vol_trigger'] = price
            except ValueError:
                continue
    
    return result

# ============================================================================
# ç­–ç•¥å»ºè®®ç”Ÿæˆ
# ============================================================================

def generate_strategy_recommendation(rotation_score: float, gamma_data: dict, current_price: float = None) -> dict:
    """åŸºäº Rotation Score å’Œ Gamma ç¯å¢ƒç”Ÿæˆç­–ç•¥å»ºè®®"""
    
    rec = {
        'market_state': '',
        'gamma_env': '',
        'strategy': '',
        'reasoning': [],
        'risk_level': ''
    }
    
    # åˆ¤æ–­ Rotation çŠ¶æ€
    if rotation_score > 60:
        rec['market_state'] = 'å¼ºåŠ›è¿›æ”» (Strong Risk-On)'
        rot_bias = 'very_bullish'
    elif rotation_score > 20:
        rec['market_state'] = 'éœ‡è¡åå¤š (Mild Risk-On)'
        rot_bias = 'bullish'
    elif rotation_score > -20:
        rec['market_state'] = 'æ— åºéœ‡è¡ (Neutral)'
        rot_bias = 'neutral'
    elif rotation_score > -60:
        rec['market_state'] = 'é¿é™©è°ƒæ•´ (Mild Risk-Off)'
        rot_bias = 'bearish'
    else:
        rec['market_state'] = 'ææ…ŒæŠ›å”® (Strong Risk-Off)'
        rot_bias = 'very_bearish'
    
    # åˆ¤æ–­ Gamma ç¯å¢ƒ
    gamma_env = 'unknown'
    if gamma_data.get('zero_gamma') and current_price:
        if current_price > gamma_data['zero_gamma']:
            gamma_env = 'positive'
            rec['gamma_env'] = 'æ­£ Gamma (åšå¸‚å•†é«˜æŠ›ä½å¸)'
        else:
            gamma_env = 'negative'
            rec['gamma_env'] = 'è´Ÿ Gamma (åšå¸‚å•†è¿½æ¶¨æ€è·Œ)'
    
    # ç”Ÿæˆç­–ç•¥å»ºè®®
    strategy_matrix = {
        ('very_bullish', 'positive'): {
            'strategy': 'Bull Call Spread',
            'reasoning': ['èµ„é‡‘å¼ºåŠ¿æµå…¥è¿›æ”»æ¿å—', 'æ­£ Gamma å‹åˆ¶æš´æ¶¨ï¼ŒSpread åˆé€‚', 'ç›®æ ‡ Call Wall'],
            'risk': 'ä¸­ç­‰'
        },
        ('very_bullish', 'negative'): {
            'strategy': 'Long Call',
            'reasoning': ['èµ„é‡‘å¼ºåŠ¿æµå…¥', 'è´Ÿ Gamma å¯èƒ½æš´æ¶¨', 'ä¸é™åˆ¶ä¸Šæ¶¨æ”¶ç›Š'],
            'risk': 'è¾ƒé«˜'
        },
        ('bullish', 'positive'): {
            'strategy': 'Bull Call Spread',
            'reasoning': ['èµ„é‡‘åå¤š', 'æ­£ Gamma éœ‡è¡ä¸Šè¡Œ', 'æ§åˆ¶æˆæœ¬'],
            'risk': 'ä¸­ä½'
        },
        ('bullish', 'negative'): {
            'strategy': 'Bull Call Spread / Long Call',
            'reasoning': ['èµ„é‡‘åå¤š', 'è´Ÿ Gamma æ³¢åŠ¨å¤§', 'è§†é£é™©åå¥½é€‰æ‹©'],
            'risk': 'ä¸­é«˜'
        },
        ('neutral', 'positive'): {
            'strategy': 'Iron Condor / è§‚æœ›',
            'reasoning': ['èµ„é‡‘æ–¹å‘ä¸æ˜', 'æ­£ Gamma éœ‡è¡', 'å–ä¸¤è¾¹æ”¶æƒåˆ©é‡‘'],
            'risk': 'ä¸­ç­‰'
        },
        ('neutral', 'negative'): {
            'strategy': 'Long Straddle / è§‚æœ›',
            'reasoning': ['æ–¹å‘ä¸æ˜ä½†æ³¢åŠ¨å¤§', 'è´Ÿ Gamma ç­‰çªç ´', 'ä¹°ä¸¤è¾¹'],
            'risk': 'è¾ƒé«˜'
        },
        ('bearish', 'positive'): {
            'strategy': 'Bear Put Spread',
            'reasoning': ['èµ„é‡‘æµå‡º', 'æ­£ Gamma æ…¢è·Œ', 'Spread æ§åˆ¶æˆæœ¬'],
            'risk': 'ä¸­ç­‰'
        },
        ('bearish', 'negative'): {
            'strategy': 'Long Put',
            'reasoning': ['èµ„é‡‘æµå‡º', 'è´Ÿ Gamma å¯èƒ½æš´è·Œ', 'ä¸é™åˆ¶ä¸‹è·Œæ”¶ç›Š'],
            'risk': 'è¾ƒé«˜'
        },
        ('very_bearish', 'positive'): {
            'strategy': 'Bear Put Spread',
            'reasoning': ['èµ„é‡‘ææ…Œæµå‡º', 'ä½†æ­£ Gamma æœ‰æ”¯æ’‘', 'æ§åˆ¶é£é™©'],
            'risk': 'ä¸­é«˜'
        },
        ('very_bearish', 'negative'): {
            'strategy': 'Long Put / Long Straddle',
            'reasoning': ['æåº¦ææ…Œ', 'è´Ÿ Gamma å¯èƒ½å´©ç›˜', 'åšç©ºæˆ–åšæ³¢åŠ¨ç‡'],
            'risk': 'é«˜'
        },
    }
    
    key = (rot_bias, gamma_env)
    if key in strategy_matrix:
        rec['strategy'] = strategy_matrix[key]['strategy']
        rec['reasoning'] = strategy_matrix[key]['reasoning']
        rec['risk_level'] = strategy_matrix[key]['risk']
    else:
        rec['strategy'] = 'è§‚æœ› / è½»ä»“è¯•æ¢'
        rec['reasoning'] = ['Gamma æ•°æ®ä¸å®Œæ•´', 'å»ºè®®ç­‰å¾…æ›´å¤šä¿¡æ¯']
        rec['risk_level'] = 'æœªçŸ¥'
    
    return rec

# ============================================================================
# å¯¼å‡ºå‡½æ•°
# ============================================================================

def generate_rotation_export(results: dict, gamma_qqq: dict, gamma_nq: dict, gamma_ndx: dict, 
                            recommendation: dict, current_prices: dict) -> str:
    """ç”Ÿæˆ Claude å¯¼å‡ºæ–‡æœ¬"""
    
    export_lines = [
        "# ğŸ“Š èµ„é‡‘è½®åŠ¨åˆ†ææŠ¥å‘Š",
        f"ç”Ÿæˆæ—¶é—´: {results['timestamp']}",
        "",
        "## ä¸€ã€ç»¼åˆè¯„åˆ†",
        f"**Rotation Score: {results['total_score']:.1f}** (-100 åˆ° +100)",
        "",
    ]
    
    # åˆ†ç±»è¯„åˆ†
    export_lines.append("## äºŒã€åˆ†ç±»è¯„åˆ†")
    for cat_key, cat_data in results['categories'].items():
        export_lines.append(f"### {cat_data['name']} (æƒé‡ {cat_data['weight']*100:.0f}%)")
        export_lines.append(f"è¯„åˆ†: {cat_data['score']:.1f}")
        export_lines.append("")
        for factor in cat_data['factors']:
            signal_emoji = 'ğŸŸ¢' if factor['signal'] == 'bullish' else 'ğŸ”´' if factor['signal'] == 'bearish' else 'âšª'
            export_lines.append(f"- {signal_emoji} {factor['desc']} ({factor['pair']}): Z={factor['z_score']:.2f}, 5Då˜åŒ–={factor['change_5d']:.2f}%")
        export_lines.append("")
    
    # Gamma æ•°æ®
    export_lines.append("## ä¸‰ã€Gamma ç¯å¢ƒ")
    
    if gamma_qqq.get('zero_gamma'):
        export_lines.append("### QQQ")
        export_lines.append(f"- å½“å‰ä»·: ${current_prices.get('QQQ', 'N/A')}")
        export_lines.append(f"- Zero Gamma: ${gamma_qqq.get('zero_gamma')}")
        export_lines.append(f"- Call Wall: ${gamma_qqq.get('call_wall')}")
        export_lines.append(f"- Put Wall: ${gamma_qqq.get('put_wall')}")
        if gamma_qqq.get('dex'):
            export_lines.append(f"- DEX: {gamma_qqq.get('dex')}M")
        if gamma_qqq.get('gex'):
            export_lines.append(f"- GEX: {gamma_qqq.get('gex')}M")
        export_lines.append("")
    
    if gamma_nq.get('zero_gamma'):
        export_lines.append("### NQ")
        export_lines.append(f"- å½“å‰ä»·: {current_prices.get('NQ', 'N/A')}")
        export_lines.append(f"- Zero Gamma: {gamma_nq.get('zero_gamma')}")
        export_lines.append(f"- Call Wall: {gamma_nq.get('call_wall')}")
        export_lines.append(f"- Put Wall: {gamma_nq.get('put_wall')}")
        export_lines.append("")
    
    if gamma_ndx.get('zero_gamma'):
        export_lines.append("### NDX")
        export_lines.append(f"- Zero Gamma: {gamma_ndx.get('zero_gamma')}")
        export_lines.append(f"- Call Wall: {gamma_ndx.get('call_wall')}")
        export_lines.append(f"- Put Wall: {gamma_ndx.get('put_wall')}")
        if gamma_ndx.get('dex'):
            export_lines.append(f"- DEX: {gamma_ndx.get('dex')}M")
        if gamma_ndx.get('gex'):
            export_lines.append(f"- GEX: {gamma_ndx.get('gex')}M")
        export_lines.append("")
    
    # ç­–ç•¥å»ºè®®
    export_lines.append("## å››ã€ç­–ç•¥å»ºè®®")
    export_lines.append(f"- å¸‚åœºçŠ¶æ€: {recommendation['market_state']}")
    export_lines.append(f"- Gamma ç¯å¢ƒ: {recommendation['gamma_env']}")
    export_lines.append(f"- æ¨èç­–ç•¥: **{recommendation['strategy']}**")
    export_lines.append(f"- é£é™©ç­‰çº§: {recommendation['risk_level']}")
    export_lines.append("- ç†ç”±:")
    for reason in recommendation['reasoning']:
        export_lines.append(f"  - {reason}")
    
    export_lines.append("")
    export_lines.append("---")
    export_lines.append("è¯·åŸºäºä»¥ä¸Šæ•°æ®è¿›è¡Œæ·±åº¦åˆ†æ:")
    export_lines.append("1. èµ„é‡‘æµå‘æ˜¯å¦æ”¯æŒå½“å‰è¶‹åŠ¿ï¼Ÿ")
    export_lines.append("2. å“ªäº›å› å­æ˜¯ä¸»è¦é©±åŠ¨åŠ›ï¼Ÿ")
    export_lines.append("3. Gamma ç¯å¢ƒä¸èµ„é‡‘æµå‘æ˜¯å¦å…±æŒ¯ï¼Ÿ")
    export_lines.append("4. å»ºè®®çš„æœŸæƒç­–ç•¥è¡Œæƒä»·ï¼Ÿ")
    
    return '\n'.join(export_lines)

# ============================================================================
# UI éƒ¨åˆ†
# ============================================================================

# Rotation Score è¾“å…¥åŒºåŸŸ (ä¸»åŒºåŸŸå†…)
with st.expander("âš™ï¸ Rotation Score è®¾ç½® & SpotGamma æ•°æ®è¾“å…¥", expanded=True):
    col_price1, col_price2, col_price3 = st.columns([1, 1, 2])
    
    with col_price1:
        st.markdown("**å½“å‰ä»·æ ¼**")
        input_qqq_price = st.number_input("QQQ ä»·æ ¼", value=622.0, step=0.5, format="%.2f", key="rot_qqq_price")
        input_nq_price = st.number_input("NQ ä»·æ ¼", value=25800.0, step=10.0, format="%.2f", key="rot_nq_price")
    
    with col_price2:
        st.markdown("**QQQ Gamma**")
        gamma_qqq_input = st.text_area(
            "ç²˜è´´ QQQ SpotGamma",
            height=180,
            placeholder="621  Zero Gamma\n625  Call Wall\n590  Put Wall\nDEX: -1219.8\nGEX: 513",
            key="gamma_qqq_rot"
        )
    
    with col_price3:
        st.markdown("**NQ/NDX Gamma (ä¸‰åˆ—æ ¼å¼)**")
        gamma_nq_ndx_input = st.text_area(
            "ç²˜è´´ NQ/NDX SpotGamma",
            height=180,
            placeholder="NDX      /NQ      Level ID\n25480    25718    Large Gamma 4\n25470    25708    Call Wall\n25250    25488    Large Gamma 1\n25170    25408    Volatility Trigger\n25150    25388    Put Wall\n25092    25330    Zero Gamma",
            key="gamma_nq_ndx_rot"
        )
        st.caption("æ ¼å¼: NDX [Tab/ç©ºæ ¼] NQ [Tab/ç©ºæ ¼] Level ID")

# è§£æ Gamma æ•°æ®
gamma_qqq = parse_gamma_input(gamma_qqq_input)

# è§£æ NQ/NDX åˆå¹¶æ ¼å¼
def parse_nq_ndx_combined(text: str) -> tuple:
    """è§£æ NQ/NDX ä¸‰åˆ—æ ¼å¼æ•°æ®"""
    result_nq = {
        'zero_gamma': None, 'call_wall': None, 'put_wall': None,
        'vol_trigger': None, 'levels': []
    }
    result_ndx = {
        'zero_gamma': None, 'call_wall': None, 'put_wall': None,
        'vol_trigger': None, 'levels': []
    }
    
    if not text or not text.strip():
        return result_nq, result_ndx
    
    lines = text.strip().split('\n')
    
    for line in lines:
        line = line.strip()
        if not line or 'NDX' in line.upper() and '/NQ' in line.upper():  # è·³è¿‡æ ‡é¢˜è¡Œ
            continue
        
        # åˆ†å‰²è¡Œ (Tab æˆ–å¤šç©ºæ ¼)
        import re
        parts = re.split(r'\t+|\s{2,}', line)
        
        if len(parts) >= 3:
            try:
                ndx_price = float(parts[0].replace(',', ''))
                nq_price = float(parts[1].replace(',', '').replace('/',''))
                level_name = ' '.join(parts[2:]).lower()
                
                # å­˜å‚¨åˆ°å¯¹åº”çš„ç»“æœ
                result_ndx['levels'].append({'price': ndx_price, 'name': parts[2]})
                result_nq['levels'].append({'price': nq_price, 'name': parts[2]})
                
                # è¯†åˆ«å…³é”®ä½ç½®
                if 'zero gamma' in level_name:
                    result_ndx['zero_gamma'] = ndx_price
                    result_nq['zero_gamma'] = nq_price
                elif 'call wall' in level_name:
                    result_ndx['call_wall'] = ndx_price
                    result_nq['call_wall'] = nq_price
                elif 'put wall' in level_name:
                    result_ndx['put_wall'] = ndx_price
                    result_nq['put_wall'] = nq_price
                elif 'vol' in level_name and 'trigger' in level_name:
                    result_ndx['vol_trigger'] = ndx_price
                    result_nq['vol_trigger'] = nq_price
            except ValueError:
                continue
    
    return result_nq, result_ndx

gamma_nq, gamma_ndx = parse_nq_ndx_combined(gamma_nq_ndx_input)

# å­˜å‚¨åˆ° session_state ä¾›å¯¼å‡ºä½¿ç”¨
st.session_state['gamma_qqq_data'] = gamma_qqq
st.session_state['gamma_nq_data'] = gamma_nq
st.session_state['gamma_ndx_data'] = gamma_ndx

current_prices = {
    'QQQ': input_qqq_price,
    'NQ': input_nq_price
}

# æ”¶é›†æ‰€æœ‰éœ€è¦çš„ ticker
all_tickers = set()
for category in ROTATION_FACTORS.values():
    for pair in category['pairs']:
        all_tickers.add(pair['numerator'])
        all_tickers.add(pair['denominator'])

all_tickers = list(all_tickers)

# è·å–æ•°æ®å¹¶è®¡ç®—
with st.spinner("æ­£åœ¨è·å– ETF æ•°æ®..."):
    rotation_data = get_rotation_data(all_tickers)

if not rotation_data.empty:
    results = calculate_rotation_score(rotation_data)
    st.session_state['rotation_results'] = results  # å­˜å‚¨åˆ° session_state ä¾›å¯¼å‡ºä½¿ç”¨
    
    # ç”Ÿæˆç­–ç•¥å»ºè®®
    recommendation = generate_strategy_recommendation(
        results['total_score'], 
        gamma_qqq, 
        input_qqq_price
    )
    
    # ========================================
    # ä¸»ä»ªè¡¨ç›˜
    # ========================================
    
    st.subheader("ğŸ“ˆ ç»¼åˆè¯„åˆ†ä»ªè¡¨ç›˜")
    
    col_gauge, col_status = st.columns([2, 1])
    
    with col_gauge:
        # åˆ›å»ºä»ªè¡¨ç›˜
        fig_gauge = go.Figure(go.Indicator(
            mode="gauge+number+delta",
            value=results['total_score'],
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "Rotation Score", 'font': {'size': 24}},
            delta={'reference': 0, 'increasing': {'color': "green"}, 'decreasing': {'color': "red"}},
            gauge={
                'axis': {'range': [-100, 100], 'tickwidth': 1, 'tickcolor': "darkblue"},
                'bar': {'color': "darkblue"},
                'bgcolor': "white",
                'borderwidth': 2,
                'bordercolor': "gray",
                'steps': [
                    {'range': [-100, -60], 'color': '#dc3545'},
                    {'range': [-60, -20], 'color': '#fd7e14'},
                    {'range': [-20, 20], 'color': '#ffc107'},
                    {'range': [20, 60], 'color': '#90EE90'},
                    {'range': [60, 100], 'color': '#28a745'}
                ],
                'threshold': {
                    'line': {'color': "black", 'width': 4},
                    'thickness': 0.75,
                    'value': results['total_score']
                }
            }
        ))
        
        fig_gauge.update_layout(height=300, margin=dict(l=20, r=20, t=50, b=20))
        st.plotly_chart(fig_gauge, use_container_width=True)
    
    with col_status:
        # çŠ¶æ€å¡ç‰‡
        score = results['total_score']
        if score > 60:
            status_class = "summary-bull"
            status_emoji = "ğŸš€"
            status_text = "å¼ºåŠ›è¿›æ”»"
        elif score > 20:
            status_class = "summary-bull"
            status_emoji = "ğŸ“ˆ"
            status_text = "éœ‡è¡åå¤š"
        elif score > -20:
            status_class = "summary-neutral"
            status_emoji = "âš–ï¸"
            status_text = "æ— åºéœ‡è¡"
        elif score > -60:
            status_class = "summary-bear"
            status_emoji = "ğŸ“‰"
            status_text = "é¿é™©è°ƒæ•´"
        else:
            status_class = "summary-bear"
            status_emoji = "ğŸ”»"
            status_text = "ææ…ŒæŠ›å”®"
        
        st.markdown(f"""
        <div class="summary-box {status_class}">
        <h2>{status_emoji} {status_text}</h2>
        <p><b>è¯„åˆ†ï¼š{score:.1f}</b></p>
        <p>æ›´æ–°æ—¶é—´ï¼š{results['timestamp']}</p>
        </div>
        """, unsafe_allow_html=True)
        
        # åˆ†ç±»è¯„åˆ†
        st.markdown("**åˆ†ç±»è¯„åˆ†ï¼š**")
        for cat_key, cat_data in results['categories'].items():
            cat_score = cat_data['score']
            color = "green" if cat_score > 10 else "red" if cat_score < -10 else "gray"
            st.markdown(f"- {cat_data['name']}: <span style='color:{color}'><b>{cat_score:.1f}</b></span>", unsafe_allow_html=True)
    
    # ========================================
    # å› å­è¯¦æƒ…
    # ========================================
    
    st.subheader("ğŸ“Š å› å­åˆ†è§£")
    
    # æ°´å¹³æ¡å½¢å›¾
    factor_names = []
    factor_zscores = []
    factor_colors = []
    
    for factor in results['factors']:
        factor_names.append(f"{factor['desc']}")
        factor_zscores.append(factor['z_score'])
        factor_colors.append('#28a745' if factor['z_score'] > 0 else '#dc3545')
    
    fig_factors = go.Figure()
    fig_factors.add_trace(go.Bar(
        y=factor_names,
        x=factor_zscores,
        orientation='h',
        marker_color=factor_colors,
        text=[f"{z:.2f}" for z in factor_zscores],
        textposition='outside'
    ))
    
    fig_factors.add_vline(x=0, line_dash="dash", line_color="gray")
    fig_factors.add_vline(x=0.5, line_dash="dot", line_color="green", opacity=0.5)
    fig_factors.add_vline(x=-0.5, line_dash="dot", line_color="red", opacity=0.5)
    
    fig_factors.update_layout(
        title="å› å­ Z-Score (åç¦»å‡å€¼ç¨‹åº¦)",
        xaxis_title="Z-Score",
        yaxis_title="",
        height=400,
        xaxis=dict(range=[-3.5, 3.5]),
        showlegend=False
    )
    
    st.plotly_chart(fig_factors, use_container_width=True)
    
    # å› å­è¯¦æƒ…è¡¨æ ¼
    with st.expander("ğŸ“‹ å› å­è¯¦æƒ…è¡¨"):
        factor_df = pd.DataFrame(results['factors'])
        factor_df = factor_df[['desc', 'pair', 'ratio', 'z_score', 'change_5d', 'signal']]
        factor_df.columns = ['å› å­', 'æ¯”ç‡å¯¹', 'å½“å‰å€¼', 'Z-Score', '5æ—¥å˜åŒ–%', 'ä¿¡å·']
        factor_df['å½“å‰å€¼'] = factor_df['å½“å‰å€¼'].apply(lambda x: f"{x:.4f}" if x else "N/A")
        factor_df['Z-Score'] = factor_df['Z-Score'].apply(lambda x: f"{x:.2f}")
        factor_df['5æ—¥å˜åŒ–%'] = factor_df['5æ—¥å˜åŒ–%'].apply(lambda x: f"{x:.2f}%")
        factor_df['ä¿¡å·'] = factor_df['ä¿¡å·'].map({'bullish': 'ğŸŸ¢ çœ‹æ¶¨', 'bearish': 'ğŸ”´ çœ‹è·Œ', 'neutral': 'âšª ä¸­æ€§'})
        st.dataframe(factor_df, use_container_width=True, hide_index=True)
    
    # ========================================
    # Gamma ç¯å¢ƒä¸ç­–ç•¥å»ºè®®
    # ========================================
    
    st.subheader("ğŸ¯ Gamma ç¯å¢ƒä¸ç­–ç•¥å»ºè®®")
    
    col_gamma, col_strategy = st.columns([1, 1])
    
    with col_gamma:
        st.markdown("**Gamma å…³é”®ä½ï¼š**")
        
        # QQQ
        if gamma_qqq.get('zero_gamma'):
            qqq_pos = "âœ… æ­£ Gamma" if input_qqq_price > gamma_qqq['zero_gamma'] else "âš ï¸ è´Ÿ Gamma"
            st.markdown(f"""
            **QQQ** ${input_qqq_price:.2f} | {qqq_pos}
            - Zero Gamma: ${gamma_qqq.get('zero_gamma')}
            - Call Wall: ${gamma_qqq.get('call_wall')}
            - Put Wall: ${gamma_qqq.get('put_wall')}
            """)
            if gamma_qqq.get('dex'):
                dex_sign = "ğŸ“ˆ" if gamma_qqq['dex'] > 0 else "ğŸ“‰"
                st.markdown(f"- DEX: {dex_sign} {gamma_qqq['dex']}M")
            if gamma_qqq.get('gex'):
                gex_sign = "ğŸŸ¢" if gamma_qqq['gex'] > 0 else "ğŸ”´"
                st.markdown(f"- GEX: {gex_sign} {gamma_qqq['gex']}M")
        else:
            st.info("ğŸ‘ˆ è¯·åœ¨ä¾§è¾¹æ ç²˜è´´ QQQ Gamma æ•°æ®")
        
        st.markdown("---")
        
        # NQ
        if gamma_nq.get('zero_gamma'):
            nq_pos = "âœ… æ­£ Gamma" if input_nq_price > gamma_nq['zero_gamma'] else "âš ï¸ è´Ÿ Gamma"
            st.markdown(f"""
            **NQ** {input_nq_price:.2f} | {nq_pos}
            - Zero Gamma: {gamma_nq.get('zero_gamma')}
            - Call Wall: {gamma_nq.get('call_wall')}
            - Put Wall: {gamma_nq.get('put_wall')}
            """)
        else:
            st.info("ğŸ‘ˆ è¯·åœ¨ä¾§è¾¹æ ç²˜è´´ NQ Gamma æ•°æ®")
    
    with col_strategy:
        st.markdown("**ğŸ“‹ ç­–ç•¥å»ºè®®ï¼š**")
        
        if recommendation['strategy']:
            risk_color = {
                'ä¸­ä½': 'green',
                'ä¸­ç­‰': 'orange', 
                'ä¸­é«˜': 'darkorange',
                'è¾ƒé«˜': 'red',
                'é«˜': 'darkred'
            }.get(recommendation['risk_level'], 'gray')
            
            st.markdown(f"""
            <div class="summary-box summary-neutral">
            <h3>ğŸ’¡ {recommendation['strategy']}</h3>
            <p><b>å¸‚åœºçŠ¶æ€ï¼š</b>{recommendation['market_state']}</p>
            <p><b>Gamma ç¯å¢ƒï¼š</b>{recommendation['gamma_env'] or 'æ•°æ®ä¸è¶³'}</p>
            <p><b>é£é™©ç­‰çº§ï¼š</b><span style='color:{risk_color}'>{recommendation['risk_level']}</span></p>
            </div>
            """, unsafe_allow_html=True)
            
            st.markdown("**ç†ç”±ï¼š**")
            for reason in recommendation['reasoning']:
                st.markdown(f"- {reason}")
        else:
            st.info("è¯·è¾“å…¥ Gamma æ•°æ®ä»¥è·å–ç­–ç•¥å»ºè®®")
    
    # [å·²ç§»è‡³é¡µé¢åº•éƒ¨ç»Ÿä¸€å¯¼å‡º]

else:
    st.warning("âš ï¸ æ— æ³•è·å– ETF æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•")
    st.info("ğŸ’¡ å¦‚æœé—®é¢˜æŒç»­ï¼Œå¯èƒ½æ˜¯ Yahoo Finance API æš‚æ—¶ä¸å¯ç”¨")
    results = None

# ============================================================================
# å¸‚åœºå¹¿åº¦é›·è¾¾å›¾ (å¯é€‰)
# ============================================================================

if results is not None and 'categories' in results:
    with st.expander("ğŸ“¡ å¸‚åœºå¹¿åº¦é›·è¾¾å›¾", expanded=False):
        # æå–å„åˆ†ç±»çš„åˆ†æ•°
        categories = list(results['categories'].keys())
        cat_scores = [results['categories'][c]['score'] for c in categories]
        cat_names = [results['categories'][c]['name'] for c in categories]
        
        # é—­åˆé›·è¾¾å›¾
        cat_names_closed = cat_names + [cat_names[0]]
        cat_scores_closed = cat_scores + [cat_scores[0]]
        
        fig_radar = go.Figure()
        
        fig_radar.add_trace(go.Scatterpolar(
            r=cat_scores_closed,
            theta=cat_names_closed,
            fill='toself',
            name='å½“å‰',
            line_color='blue'
        ))
        
        # æ·»åŠ é›¶çº¿
        fig_radar.add_trace(go.Scatterpolar(
            r=[0] * len(cat_names_closed),
            theta=cat_names_closed,
            mode='lines',
            line=dict(color='gray', dash='dash'),
            name='ä¸­æ€§çº¿'
        ))
        
        fig_radar.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[-100, 100]
                )
            ),
            showlegend=True,
            title="èµ„é‡‘æµå‘é›·è¾¾å›¾"
        )
        
        st.plotly_chart(fig_radar, use_container_width=True)

st.divider()
st.caption("ğŸ“Š Rotation Score ç³»ç»Ÿ v1.0 | æ•°æ®æ¥æº: Yahoo Finance | ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®")


# ============================================================================
# 11. ğŸ“Š ETF æ¿å—èµ„é‡‘æµå…¥æ‰«æ
# ============================================================================

st.divider()
st.header("11. ğŸ“Š ETF æ¿å—èµ„é‡‘æµå…¥æ‰«æ")

# æ ¸å¿ƒæ¿å—ETFåˆ—è¡¨
SECTOR_ETFS = {
    'XLK': 'ç§‘æŠ€', 'SMH': 'åŠå¯¼ä½“', 'XLF': 'é‡‘è', 'XLE': 'èƒ½æº',
    'XLV': 'åŒ»ç–—å¥åº·', 'XBI': 'ç”Ÿç‰©ç§‘æŠ€', 'XLI': 'å·¥ä¸š', 'XLY': 'å¯é€‰æ¶ˆè´¹',
    'XLP': 'å¿…éœ€æ¶ˆè´¹', 'XLU': 'å…¬ç”¨äº‹ä¸š', 'XLRE': 'æˆ¿åœ°äº§', 'XLB': 'ææ–™',
    'XLC': 'é€šä¿¡æœåŠ¡', 'IWM': 'å°ç›˜è‚¡', 'QQQ': 'çº³æŒ‡100', 'SPY': 'S&P500',
}

@st.cache_data(ttl=300)
def get_etf_flow_data(ticker: str, period: str = "3mo"):
    """è·å–ETFæ•°æ®ç”¨äºèµ„é‡‘æµåˆ†æ"""
    try:
        data = yf.download(ticker, period=period, progress=False)
        if isinstance(data.columns, pd.MultiIndex):
            data.columns = data.columns.get_level_values(0)
        return data
    except:
        return None

def calculate_etf_signals(ticker: str, data: pd.DataFrame) -> dict:
    """è®¡ç®—å•ä¸ªETFçš„èµ„é‡‘æµå…¥ä¿¡å·"""
    try:
        if data is None or data.empty or len(data) < 25:
            return None
        
        df = data.copy()
        df['SMA20'] = df['Close'].rolling(20).mean()
        df['SMA50'] = df['Close'].rolling(50).mean()
        df['Vol_SMA20'] = df['Volume'].rolling(20).mean()
        df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
        
        latest = df.iloc[-1]
        prev_5d = df.iloc[-5]
        prev_20d = df.iloc[-20] if len(df) >= 20 else df.iloc[0]
        
        close = float(latest['Close'])
        sma20 = float(latest['SMA20'])
        sma50 = float(latest['SMA50']) if not pd.isna(latest['SMA50']) else sma20
        vol_sma20 = float(latest['Vol_SMA20'])
        
        price_above_sma20 = close > sma20
        price_above_sma50 = close > sma50
        volume_expanding = float(latest['Volume']) > vol_sma20
        obv_rising = float(latest['OBV']) > float(prev_5d['OBV'])
        returns_20d = (close / float(prev_20d['Close']) - 1) * 100
        vol_ratio = float(latest['Volume']) / vol_sma20 if vol_sma20 > 0 else 1
        
        score = sum([price_above_sma20, price_above_sma50, volume_expanding, obv_rising, returns_20d > 0])
        
        return {
            'ETF': ticker, 'æ¿å—': SECTOR_ETFS.get(ticker, ticker),
            'ä»·æ ¼': round(close, 2),
            '>SMA20': 'âœ…' if price_above_sma20 else 'âŒ',
            '>SMA50': 'âœ…' if price_above_sma50 else 'âŒ',
            'æ”¾é‡': 'âœ…' if volume_expanding else 'âŒ',
            'OBVâ†‘': 'âœ…' if obv_rising else 'âŒ',
            'é‡æ¯”': round(vol_ratio, 2),
            '20æ—¥æ¶¨å¹…%': round(returns_20d, 2),
            'è¯„åˆ†': score,
        }
    except:
        return None

col_etf1, col_etf2 = st.columns([3, 1])
with col_etf2:
    min_score_etf = st.slider("æœ€ä½è¯„åˆ†", 0, 5, 4, key="etf_min_score")

if st.button("ğŸ” æ‰«æ ETF èµ„é‡‘æµå‘", type="primary"):
    etf_results = []
    progress = st.progress(0)
    etf_list = list(SECTOR_ETFS.keys())
    
    for i, ticker in enumerate(etf_list):
        progress.progress((i + 1) / len(etf_list))
        data = get_etf_flow_data(ticker)
        if data is not None and not data.empty:
            result = calculate_etf_signals(ticker, data)
            if result:
                etf_results.append(result)
    
    progress.empty()
    
    if etf_results:
        etf_df = pd.DataFrame(etf_results).sort_values('è¯„åˆ†', ascending=False)
        st.session_state['etf_scan_results'] = etf_df
        
        # æ˜¾ç¤ºç»“æœ
        st.dataframe(etf_df, use_container_width=True, hide_index=True)
        
        # èµ„é‡‘æµå…¥æ¿å—
        inflow = etf_df[etf_df['è¯„åˆ†'] >= min_score_etf]
        if len(inflow) > 0:
            st.success(f"ğŸ”¥ èµ„é‡‘æµå…¥æ¿å— ({len(inflow)} ä¸ª): " + ", ".join(inflow['æ¿å—'].tolist()))
        
        # å¼±åŠ¿æ¿å—
        weak = etf_df[etf_df['è¯„åˆ†'] <= 2]
        if len(weak) > 0:
            st.warning(f"âš ï¸ å¼±åŠ¿æ¿å—: " + ", ".join(weak['æ¿å—'].tolist()))
else:
    if 'etf_scan_results' in st.session_state:
        st.dataframe(st.session_state['etf_scan_results'], use_container_width=True, hide_index=True)

# ============================================================================
# ğŸ“¤ ç»Ÿä¸€å¯¼å‡ºåˆ° Claude
# ============================================================================

st.divider()
st.header("ğŸ“¤ å¯¼å‡ºå®Œæ•´æ•°æ®åˆ° Claude")

def generate_unified_export():
    """ç”Ÿæˆç»Ÿä¸€çš„å¯¼å‡ºæ–‡æœ¬ï¼ŒåŒ…å«æ‰€æœ‰æ¨¡å—æ•°æ®"""
    timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    export = f"""# ğŸ¦… å®è§‚æˆ˜æƒ…è§‚å¯Ÿå®¤ - å®Œæ•´æ•°æ®å¿«ç…§
ç”Ÿæˆæ—¶é—´: {timestamp} EST

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## ä¸€ã€æµåŠ¨æ€§æŒ‡æ ‡
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- SOFR: {ny_fed['SOFR']:.2f}%
- Repo (TGCR): {ny_fed['TGCR']:.2f}%
- SOFR-Repo åˆ©å·®: {(ny_fed['SOFR'] - ny_fed['TGCR']):.3f}%
- RRP: ${fed_liq['RRP']:.0f}B (æ—¥å˜åŒ–: {fed_liq['RRP_Chg']:.0f}B)
- TGA: ${fed_liq['TGA']:.0f}B (æ—¥å˜åŒ–: {fed_liq['TGA_Chg']:.0f}B)
- HYG/LQD: {credit[0]:.3f} (æ—¥å˜åŒ–: {credit[1]:.2f}%)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## äºŒã€ç¾å€ºä¸æ±‡ç‡
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- 10Y æ”¶ç›Šç‡: {rates['Yield_10Y']:.2f}%
- 3M æ”¶ç›Šç‡: {rates['Yield_Short']:.2f}%
- 10Y-3M åˆ©å·®: {rates['Inversion']:.2f}%
- MOVE æŒ‡æ•°: {rates['MOVE']:.1f}
- DXY: {rates['DXY']:.2f}
- USDJPY: {rates['USDJPY']:.2f}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## ä¸‰ã€ææ…Œä¸æƒ…ç»ªæŒ‡æ ‡
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- VIX: {vol['VIX']:.2f}
- å¸åœˆææ…Œè´ªå©ª: {vol['Crypto_Val']} ({vol['Crypto_Text']})
- PCR: {opt['PCR']:.2f}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## å››ã€äº¤æ˜“å¾®è§‚ç»“æ„
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- æœŸè´§åŸºå·®: {deriv['Futures_Basis']:.1f} ({deriv['Basis_Status']})
- Gamma ç¯å¢ƒ: {deriv['GEX_Net']}
- Vanna çŠ¶æ€: {deriv['Vanna_Status']}
- Put Wall: ${deriv['Put_Wall']:.0f}
- Call Wall: ${deriv['Call_Wall']:.0f}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## äº”ã€GEX åˆ†æ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- å½“å‰ä»·æ ¼: ${gex_data['spot_price']:.2f}
- å‡€ GEX: {gex_data['total_gex']:.2f}B
- Gamma Flip Point: ${gex_data['gamma_flip']:.2f}
- Max Pain: ${gex_data['max_pain']:.2f}
- GEX Put Wall: ${gex_data['put_wall']:.2f}
- GEX Call Wall: ${gex_data['call_wall']:.2f}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## å…­ã€è§„åˆ™å¼•æ“ä¿¡å·
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
å¸‚åœºçŠ¶æ€: {regime_analysis['regime'].upper()}
ç»¼åˆè¯„åˆ†: {regime_analysis['score']:.1f}

å…³é”®ä¿¡å·:
"""
    for sig in regime_analysis['signals']:
        export += f"- [{sig['level']}] {sig['msg']}\n"
    
    export += """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## ä¸ƒã€é‡ç‚¹æ–°é—»
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    for item in processed_news[:10]:
        cats = ", ".join(item.get('Categories', ['general']))
        export += f"- [{cats}] {item['Title']} (æƒ…ç»ª: {item.get('Sentiment', 'Neutral')})\n"
    
    # æ·»åŠ  Rotation Score æ•°æ®
    export += """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## å…«ã€èµ„é‡‘è½®åŠ¨è¯„åˆ† (Rotation Score)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    if 'rotation_results' in st.session_state and st.session_state['rotation_results']:
        rot = st.session_state['rotation_results']
        export += f"**ç»¼åˆè¯„åˆ†: {rot['total_score']:.1f}** (-100 åˆ° +100)\n\n"
        for cat_key, cat_data in rot['categories'].items():
            export += f"### {cat_data['name']} (è¯„åˆ†: {cat_data['score']:.1f})\n"
            for factor in cat_data['factors']:
                signal = 'ğŸŸ¢' if factor['signal'] == 'bullish' else 'ğŸ”´' if factor['signal'] == 'bearish' else 'âšª'
                export += f"- {signal} {factor['desc']}: Z={factor['z_score']:.2f}\n"
    else:
        export += "(è¯·å…ˆåˆ·æ–° Rotation Score æ•°æ®)\n"
    
    # æ·»åŠ  Gamma è¾“å…¥æ•°æ®
    export += """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## ä¹ã€SpotGamma æ•°æ® (æ‰‹åŠ¨è¾“å…¥)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    if 'gamma_qqq_data' in st.session_state and st.session_state['gamma_qqq_data'].get('zero_gamma'):
        g = st.session_state['gamma_qqq_data']
        export += f"**QQQ**\n"
        export += f"- Zero Gamma: ${g.get('zero_gamma')}\n"
        export += f"- Call Wall: ${g.get('call_wall')}\n"
        export += f"- Put Wall: ${g.get('put_wall')}\n"
    else:
        export += "(è¯·åœ¨ä¾§è¾¹æ è¾“å…¥ SpotGamma æ•°æ®)\n"
    
    # æ·»åŠ  ETF æ‰«æç»“æœ
    export += """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## åã€ETF èµ„é‡‘æµå‘æ‰«æ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    if 'etf_scan_results' in st.session_state:
        etf_df = st.session_state['etf_scan_results']
        strong = etf_df[etf_df['è¯„åˆ†'] >= 4]
        weak = etf_df[etf_df['è¯„åˆ†'] <= 2]
        export += f"**èµ„é‡‘æµå…¥æ¿å—**: {', '.join(strong['æ¿å—'].tolist()) if len(strong) > 0 else 'æ— '}\n"
        export += f"**å¼±åŠ¿æ¿å—**: {', '.join(weak['æ¿å—'].tolist()) if len(weak) > 0 else 'æ— '}\n"
    else:
        export += "(è¯·å…ˆæ‰§è¡Œ ETF æ‰«æ)\n"
    
    export += """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
## åˆ†æè¯·æ±‚
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
è¯·åŸºäºä»¥ä¸Šå®Œæ•´æ•°æ®è¿›è¡Œæ·±åº¦åˆ†æ:
1. å½“å‰å¸‚åœºå¤„äºä»€ä¹ˆå®è§‚å‘¨æœŸï¼ŸæµåŠ¨æ€§ç¯å¢ƒå¦‚ä½•ï¼Ÿ
2. Gamma ç¯å¢ƒä¸èµ„é‡‘æµå‘æ˜¯å¦å…±æŒ¯ï¼Ÿ
3. æœ‰å“ªäº›æ½œåœ¨çš„é£é™©ç‚¹éœ€è¦å…³æ³¨ï¼Ÿ
4. ä»Šæ—¥ QQQ æœŸæƒäº¤æ˜“çš„æœ€ä½³ç­–ç•¥æ˜¯ä»€ä¹ˆï¼Ÿå»ºè®®çš„è¡Œæƒä»·ï¼Ÿ
5. å“ªäº›æ¿å—å€¼å¾—é‡ç‚¹å…³æ³¨ï¼Ÿ
"""
    return export

with st.expander("ğŸ“‹ ç‚¹å‡»å±•å¼€å®Œæ•´æ•°æ®å¯¼å‡º", expanded=False):
    st.markdown("""
    <div class="export-box">
    <p>ğŸ“‹ ç‚¹å‡»ä¸‹æ–¹æ–‡æœ¬æ¡†ï¼Œå…¨é€‰ (Ctrl+A) å¹¶å¤åˆ¶ (Ctrl+C)ï¼Œç„¶åç²˜è´´ç»™ Claude è¿›è¡Œæ·±åº¦åˆ†æ</p>
    </div>
    """, unsafe_allow_html=True)
    
    unified_export = generate_unified_export()
    st.text_area("å®Œæ•´æ•°æ®å¿«ç…§", unified_export, height=500, key="unified_export")

st.divider()
st.caption("ğŸ¦… å®è§‚æˆ˜æƒ…è§‚å¯Ÿå®¤ v2.0 | æ•°æ®æ¥æº: NY Fed, Yahoo Finance, SpotGamma | ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®")
