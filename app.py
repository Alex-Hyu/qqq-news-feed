import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import requests
import datetime
from datetime import timedelta
import pytz
import feedparser
from io import StringIO
from transformers import pipeline
from streamlit_autorefresh import st_autorefresh

# --- 0. å…¨å±€é…ç½® ---
st.set_page_config(page_title="QQQ å®è§‚æˆ˜æƒ…å®¤ Pro", layout="wide", page_icon="ğŸ¦…")

st.markdown("""
    <style>
    .metric-card {background-color: #f9f9f9; border-radius: 5px; padding: 10px; border: 1px solid #e0e0e0;}
    .news-card {padding: 10px; margin-bottom: 5px; border-radius: 5px; border-left: 5px solid #ccc;}
    .news-bull {background-color: #e6fffa; border-left-color: #00c04b;}
    .news-bear {background-color: #fff5f5; border-left-color: #ff4b4b;}
    </style>
    """, unsafe_allow_html=True)

# --- [ä¾§è¾¹æ ] é…ç½®ä¸åˆ·æ–° ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    
    # [ä¿®æ”¹] è¿™é‡Œå·²ç»å¡«å…¥äº†ä½ çš„ API Keyï¼Œé»˜è®¤éšè—æ˜¾ç¤º
    av_api_key = st.text_input(
        "AlphaVantage API Key", 
        value="UMWB63OXOOCIZHXR", 
        type="password", 
        help="ç”¨äºè·å–çœŸå®å®è§‚æ—¥å†æ•°æ®"
    )
    
    st.divider()
    
    st.subheader("ç³»ç»ŸçŠ¶æ€")
    # 30åˆ†é’Ÿè‡ªåŠ¨åˆ·æ–°
    count = st_autorefresh(interval=30 * 60 * 1000, key="data_refresher")
    st.caption(f"ğŸŸ¢ è‡ªåŠ¨åˆ·æ–°: å¼€å¯ (30åˆ†é’Ÿ)")
    if st.button("ğŸ”„ ç«‹å³åˆ·æ–°"):
        st.rerun()

# --- 1. æ ¸å¿ƒæ¨¡å‹ä¸æ•°æ®è·å– ---

@st.cache_resource
def load_ai_model():
    return pipeline("sentiment-analysis", model="ProsusAI/finbert")

# å®è§‚æ•°æ®
@st.cache_data(ttl=3600)
def get_ny_fed_data():
    try:
        url = "https://markets.newyorkfed.org/api/rates/all/latest.json"
        r = requests.get(url, timeout=5).json()
        rates = {'SOFR': 5.3, 'TGCR': 5.3} 
        for item in r.get('refRates', []):
            if item['type'] == 'SOFR': rates['SOFR'] = float(item['percentRate'])
            if item['type'] == 'TGCR': rates['TGCR'] = float(item['percentRate'])
        return rates
    except: return {'SOFR': 5.33, 'TGCR': 5.32}

# RRP/TGA
@st.cache_data(ttl=3600)
def get_fed_liquidity():
    res = {"RRP": 0, "RRP_Chg": 0, "TGA": 0, "TGA_Chg": 0}
    try:
        rrp_df = pd.read_csv("https://fred.stlouisfed.org/graph/fredgraph.csv?id=RRPONTSYD")
        res['RRP'] = rrp_df.iloc[-1]['RRPONTSYD']
        res['RRP_Chg'] = res['RRP'] - rrp_df.iloc[-2]['RRPONTSYD']
        tga_df = pd.read_csv("https://fred.stlouisfed.org/graph/fredgraph.csv?id=WTREGEN")
        res['TGA'] = tga_df.iloc[-1]['WTREGEN']
        res['TGA_Chg'] = res['TGA'] - tga_df.iloc[-2]['WTREGEN']
    except: pass
    return res

# å¸‚åœºæ•°æ®
@st.cache_data(ttl=1800)
def get_credit_spreads():
    try:
        data = yf.download(["HYG", "LQD"], period="5d", progress=False)['Close']
        if isinstance(data.columns, pd.MultiIndex): data.columns = data.columns.droplevel(0)
        ratio = data['HYG'] / data['LQD']
        curr = ratio.iloc[-1]
        pct = ((curr - ratio.iloc[-2]) / ratio.iloc[-2]) * 100
        return curr, pct
    except: return 0, 0

@st.cache_data(ttl=1800)
def get_rates_and_fx():
    tickers = ["^IRX", "^TNX", "^TYX", "DX-Y.NYB", "JPY=X", "^MOVE"] 
    res = {}
    try:
        df = yf.download(tickers, period="5d", progress=False)['Close']
        if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.droplevel(0)
        res['Yield_2Y'] = df.get('^IRX', pd.Series([5.2])).iloc[-1]
        res['Yield_10Y'] = df.get('^TNX', pd.Series([4.2])).iloc[-1]
        res['Yield_30Y'] = df.get('^TYX', pd.Series([4.4])).iloc[-1]
        res['DXY'] = df.get('DX-Y.NYB', pd.Series([104])).iloc[-1]
        res['USDJPY'] = df.get('JPY=X', pd.Series([150])).iloc[-1]
        res['MOVE'] = df.get('^MOVE', pd.Series([100.0])).iloc[-1]
        res['Inversion'] = res['Yield_10Y'] - res['Yield_2Y']
    except:
        res = {'Yield_2Y':5.0, 'Yield_10Y':4.2, 'Yield_30Y':4.3, 'DXY':104, 'USDJPY':150, 'MOVE':100, 'Inversion':-0.8}
    return res

@st.cache_data(ttl=1800)
def get_volatility_indices():
    data = {}
    try:
        vix = yf.Ticker("^VIX").history(period="2d")['Close'].iloc[-1]
        data['VIX'] = vix
    except: data['VIX'] = 15.0
    try:
        r = requests.get("https://api.alternative.me/fng/").json()
        data['Crypto_Val'] = int(r['data'][0]['value'])
        data['Crypto_Text'] = r['data'][0]['value_classification']
    except: 
        data['Crypto_Val'] = 50; data['Crypto_Text'] = "Unknown"
    return data

# GEX/Flip Line
@st.cache_data(ttl=1800)
def get_derivatives_structure():
    res = {
        "Futures_Basis": 0, "Basis_Status": "Normal", 
        "GEX_Net": "Neutral", "Call_Wall": 0, "Put_Wall": 0, 
        "Flip_Line": 0, "Current_Price": 0,
        "Vanna_Charm_Proxy": "Neutral"
    }
    try:
        market_data = yf.download(["NQ=F", "^NDX", "QQQ"], period="2d", progress=False)['Close']
        if isinstance(market_data.columns, pd.MultiIndex): market_data.columns = market_data.columns.droplevel(0)
        
        fut = market_data['NQ=F'].iloc[-1]
        spot = market_data['^NDX'].iloc[-1]
        qqq_price = market_data['QQQ'].iloc[-1]
        res['Current_Price'] = qqq_price
        
        basis = fut - spot
        res['Futures_Basis'] = basis
        if basis < -10: res['Basis_Status'] = "ğŸ”´ Backwardation"
        elif basis > 50: res['Basis_Status'] = "ğŸŸ¢ Contango"
        else: res['Basis_Status'] = "âšª Flat"
        
        qqq = yf.Ticker("QQQ")
        exp = qqq.options[0]
        chain = qqq.option_chain(exp)
        calls = chain.calls
        puts = chain.puts
        
        res['Call_Wall'] = calls.loc[calls['openInterest'].idxmax()]['strike']
        res['Put_Wall'] = puts.loc[puts['openInterest'].idxmax()]['strike']
        
        calls['G_Contribution'] = calls['openInterest']
        puts['G_Contribution'] = puts['openInterest'] * -1
        merged = pd.concat([calls[['strike', 'G_Contribution']], puts[['strike', 'G_Contribution']]])
        gamma_profile = merged.groupby('strike').sum().sort_index()
        
        flip_strike = 0
        for index, row in gamma_profile.iterrows():
            if row['G_Contribution'] < 0:
                flip_strike = index
                break
        
        if flip_strike == 0: res['Flip_Line'] = res['Put_Wall']
        else: res['Flip_Line'] = (res['Put_Wall'] + flip_strike) / 2
        
        if abs(res['Flip_Line'] - qqq_price) > 50: res['Flip_Line'] = res['Put_Wall']
        if qqq_price < res['Flip_Line']: res['GEX_Net'] = "ğŸ”´ Negative Gamma"
        else: res['GEX_Net'] = "ğŸŸ¢ Positive Gamma"
            
        if market_data['^NDX'].iloc[-1] > market_data['^NDX'].iloc[-2]:
            res['Vanna_Charm_Proxy'] = "Tailwind (åŠ©æ¶¨)"
        else: res['Vanna_Charm_Proxy'] = "Headwind (é˜»åŠ›)"
    except Exception as e: pass
    return res

@st.cache_data(ttl=1800)
def get_qqq_options_data():
    qqq = yf.Ticker("QQQ")
    res = {"PCR": 0.0, "Unusual": []}
    try:
        exp = qqq.options[0]
        chain = qqq.option_chain(exp)
        calls, puts = chain.calls, chain.puts
        if calls['volume'].sum() > 0: 
            res['PCR'] = round(puts['volume'].sum() / calls['volume'].sum(), 2)
        
        unusual = []
        for opt_type, df, icon in [("CALL", calls, "ğŸŸ¢"), ("PUT", puts, "ğŸ”´")]:
            hot = df[(df['volume'] > 500) & (df['volume'] > df['openInterest'] * 1.2)]
            for _, row in hot.iterrows():
                unusual.append({
                    "Type": f"{icon} {opt_type}", "Strike": row['strike'],
                    "Vol": int(row['volume']), "OI": int(row['openInterest']),
                    "Ratio": round(row['volume'] / (row['openInterest']+1), 1)
                })
        res['Unusual'] = sorted(unusual, key=lambda x: x['Vol'], reverse=True)[:10]
    except: pass
    return res

# --- åŒé‡ä¿éšœçš„å®è§‚æ—¥å† ---
@st.cache_data(ttl=3600)
def get_macro_calendar(api_key=""):
    """
    ä¼˜å…ˆä½¿ç”¨ Alpha Vantage API (Keyå·²å†…ç½®)
    å¤±è´¥åˆ™ä½¿ç”¨ç®—æ³•ä¼°ç®—
    """
    # æ–¹æ¡ˆ A: API æ¨¡å¼
    if api_key:
        try:
            url = f"https://www.alphavantage.co/query?function=ECONOMIC_CALENDAR&apikey={api_key}"
            r = requests.get(url, timeout=5)
            df = pd.read_csv(StringIO(r.text))
            
            # è¿‡æ»¤ç¾å…ƒæ•°æ®
            df = df[df['currency'] == 'USD']
            
            # æ™ºèƒ½ç­›é€‰å…³é”®è¯
            keywords = ["GDP", "Unemployment", "CPI", "Interest Rate", "Payroll", "FOMC", "PCE", "Inventories"]
            df['is_important'] = df['event'].apply(lambda x: any(k in x for k in keywords))
            df = df[df['is_important']]
            
            # åªè¦æœªæ¥çš„
            today = datetime.date.today().strftime("%Y-%m-%d")
            df = df[df['date'] >= today].sort_values('date').head(10)
            
            display_df = df[['date', 'time', 'event', 'estimate', 'previous']].copy()
            display_df.columns = ['Date', 'Time', 'Event', 'Est', 'Prev']
            
            # å¦‚æœæ²¡æ•°æ® (æ¯”å¦‚å‘¨æœ«æˆ–å‡æœŸ)ï¼Œå¯èƒ½è¿”å›ç©ºï¼Œè¿™æ—¶è§¦å‘æ–¹æ¡ˆ B
            if not display_df.empty:
                return display_df, "API Data (AlphaVantage)"
            
        except Exception as e:
            pass # å¤±è´¥åˆ™é™é»˜è¿›å…¥æ–¹æ¡ˆ B

    # æ–¹æ¡ˆ B: ç®—æ³•ä¼°ç®—å…œåº•
    today = datetime.date.today()
    events = []
    
    # ä¼°ç®— CPI (æ¯æœˆ12å·å·¦å³)
    next_month = today.replace(day=28) + datetime.timedelta(days=4)
    next_cpi = today.replace(day=12) 
    if today.day > 12: next_cpi = (next_month - datetime.timedelta(days=1)).replace(day=12)
    events.append({"Date": next_cpi, "Event": "CPI é€šèƒ€æ•°æ® (ä¼°ç®—)", "Type": "Inflation"})
    
    # ä¼°ç®— éå†œ (æ¯æœˆ5å·å·¦å³)
    next_nfp = today.replace(day=5)
    if today.day > 5: next_nfp = (next_month - datetime.timedelta(days=1)).replace(day=5)
    events.append({"Date": next_nfp, "Event": "Nonfarm Payrolls (ä¼°ç®—)", "Type": "Jobs"})
    
    # ä¼°ç®— FOMC
    known_fomc = ["2025-01-29", "2025-03-19", "2025-05-07", "2025-06-18", "2025-07-30", "2025-09-17", "2025-12-10"]
    for d_str in known_fomc:
        d = datetime.datetime.strptime(d_str, "%Y-%m-%d").date()
        if d >= today:
            events.append({"Date": d, "Event": "FOMC åˆ©ç‡å†³è®® (é¢„è®¾)", "Type": "Fed"})
            break 
            
    events.append({"Date": datetime.date(today.year, 6, 15), "Event": "Q2 ç¼´ç¨æ—¥ (æµåŠ¨æ€§æŠ½æ°´)", "Type": "Liquidity"})
    
    events = sorted(events, key=lambda x: x['Date'])
    df = pd.DataFrame(events)
    df = df[df['Date'] >= today].head(5)
    
    display_df = df.copy()
    display_df['Time'] = "N/A"
    display_df['Est'] = "--"
    display_df['Prev'] = "--"
    display_df = display_df[['Date', 'Time', 'Event', 'Est', 'Prev']]
    
    return display_df, "å¤‡ç”¨æ•°æ® (Estimated)"

@st.cache_data(ttl=1800)
def get_macro_news():
    feeds = [
        ("CNBC Economy", "https://search.cnbc.com/rs/search/combinedcms/view.xml?partnerId=wrss01&id=20910258"),
        ("MarketWatch", "http://feeds.marketwatch.com/marketwatch/topstories/"),
        ("WSJ Markets", "https://feeds.a.dj.com/rss/RSSMarketsMain.xml")
    ]
    articles = []
    for src, url in feeds:
        try:
            f = feedparser.parse(url)
            for e in f.entries[:4]:
                articles.append({"Title": e.title, "Link": e.link, "Source": src})
        except: pass
    return pd.DataFrame(articles)

# --- 2. æ ¸å¿ƒç®—æ³• ---

def calculate_macro_score(ny_fed, fed_liq, credit, rates, vol, opt, deriv, news_score_val):
    score = 0
    details = []
    
    # 1. æµåŠ¨æ€§ (25%)
    liq_score = 0
    spread = ny_fed['SOFR'] - ny_fed['TGCR']
    if spread > 0.05: liq_score -= 1.0; details.append("ğŸ”´ SOFR å¼‚å¸¸")
    elif spread < 0.02: liq_score += 0.5
    if fed_liq['RRP_Chg'] > 20: liq_score -= 0.5; details.append("ğŸ”´ RRP æŠ½æ°´")
    if fed_liq['TGA_Chg'] > 20: liq_score -= 0.5; details.append("ğŸ”´ TGA æŠ½æ°´")
    if credit[1] < -0.5: liq_score -= 0.5
    elif credit[1] > 0.2: liq_score += 0.5
    score += max(-2.5, min(2.5, liq_score))
    
    # 2. ç¾å€º (25%)
    bond_score = 0
    if rates['Yield_10Y'] > 4.5: bond_score -= 1.0
    elif rates['Yield_10Y'] < 4.0: bond_score += 1.0
    if rates['MOVE'] > 110: bond_score -= 1.5
    score += max(-2.5, min(2.5, bond_score))
    
    # 3. ææ…Œ (15%)
    fear_score = 0
    if vol['VIX'] > 25: fear_score -= 1.0
    elif vol['VIX'] < 13: fear_score -= 0.5
    if vol['Crypto_Val'] < 20: fear_score += 0.5
    score += fear_score
    
    # 4. äº¤æ˜“ä¸å¾®è§‚ç»“æ„ (20%)
    trade_score = 0
    if opt['PCR'] > 1.1: trade_score -= 0.5; details.append("ğŸ“‰ PCR åç©º")
    elif opt['PCR'] < 0.7: trade_score += 0.5
    if deriv['Basis_Status'].startswith("ğŸ”´"): trade_score -= 1.0; details.append("ğŸ”´ æœŸè´§è´´æ°´")
    if deriv['GEX_Net'].startswith("ğŸ”´"): trade_score -= 0.5; details.append("ğŸ”´ è·Œç ´ Gamma Flip")
    elif deriv['GEX_Net'].startswith("ğŸŸ¢"): trade_score += 0.5
    score += max(-2.0, min(2.0, trade_score))
    
    # 5. æ–°é—» (15%)
    news_con = news_score_val * 1.5
    score += news_con
    if news_con < -0.5: details.append("ğŸ”´ èˆ†æƒ…åç©º")
    
    return round(score * (10 / 7.5), 1), details

# --- 3. UI ---

with st.spinner("æ­£åœ¨åŒæ­¥å…¨çƒå¸‚åœºæ•°æ® (30åˆ†é’Ÿåˆ·æ–°)..."):
    ai_model = load_ai_model()
    ny_fed = get_ny_fed_data()
    fed_liq = get_fed_liquidity()
    credit = get_credit_spreads()
    rates = get_rates_and_fx()
    vol = get_volatility_indices()
    opt = get_qqq_options_data()
    deriv = get_derivatives_structure()
    # ä¼ å…¥ API Key
    cal_df, cal_source = get_macro_calendar(av_api_key)
    raw_news = get_macro_news()

    processed_news = []
    sentiment_total = 0
    if not raw_news.empty:
        for i, row in raw_news.head(8).iterrows():
            try:
                res = ai_model(row['Title'][:512])[0]
                label = res['label']
                score = res['score']
                sent = "Neutral"; val = 0
                if label == 'positive' and score > 0.5: sent="Bullish"; val=1
                elif label == 'negative' and score > 0.5: sent="Bearish"; val=-1
                sentiment_total += val
                processed_news.append({**row, "Sentiment": sent})
            except: pass
        avg_news_score = sentiment_total / max(1, len(processed_news))
    else: avg_news_score = 0

    final_score, reasons = calculate_macro_score(ny_fed, fed_liq, credit, rates, vol, opt, deriv, avg_news_score)

# --- HEADER ---
st.title("ğŸ¦… QQQ å®è§‚æˆ˜æƒ…å®¤ Pro (Live)")
current_time = datetime.datetime.now(pytz.timezone('US/Eastern')).strftime('%Y-%m-%d %H:%M EST')
st.caption(f"ä¸Šæ¬¡æ›´æ–°: {current_time} | è‡ªåŠ¨åˆ·æ–°: å¼€å¯ (30åˆ†é’Ÿ)")

col_score, col_text = st.columns([1, 3])
with col_score:
    color = "red" if final_score < -3 else "green" if final_score > 3 else "gray"
    st.metric("å¤§ç›˜å¤šç©ºç»¼è¯„ (-10 ~ +10)", f"{final_score}", delta_color="off")
    if final_score > 3: st.success("### åå¤š (Bullish)")
    elif final_score < -3: st.error("### åç©º (Bearish)")
    else: st.info("### ä¸­æ€§éœ‡è¡ (Neutral)")

with col_text:
    st.markdown("#### ğŸ›¡ï¸ æˆ˜æƒ…ç»¼è¿°")
    st.write("é©±åŠ¨å› å­: " + " | ".join(reasons))
    if fed_liq['RRP_Chg'] > 100:
        st.warning("âš ï¸ ä¸¥é‡è­¦å‘Š: RRP æ¿€å¢ï¼Œå¸‚åœºæµåŠ¨æ€§æ­£åœ¨å¿«é€Ÿæ¯ç«­ï¼")

st.divider()

# 1. æµåŠ¨æ€§
st.subheader("1. æµåŠ¨æ€§ç›‘æ§ (Liquidity)")
l1, l2, l3, l4, l5 = st.columns(5)
l1.metric("SOFR", f"{ny_fed['SOFR']:.2f}%", f"Spread: {ny_fed['SOFR'] - ny_fed['TGCR']:.3f}")
l2.metric("Repo (TGCR)", f"{ny_fed['TGCR']:.2f}%")
l3.metric("RRP (é€†å›è´­)", f"${fed_liq['RRP']:.0f}B", f"{fed_liq['RRP_Chg']:.0f}B", delta_color="inverse")
l4.metric("TGA (è´¢æ”¿éƒ¨)", f"${fed_liq['TGA']:.0f}B", f"{fed_liq['TGA_Chg']:.0f}B", delta_color="inverse")
l5.metric("HYG/LQD", f"{credit[0]:.3f}", f"{credit[1]:.2f}%")

st.divider()

# 2. ç¾å€º
st.subheader("2. ç¾å€ºä¸æ±‡ç‡ (Rates & FX)")
r1, r2, r3, r4, r5 = st.columns(5)
r1.metric("10Y ç¾å€ºæ”¶ç›Šç‡", f"{rates['Yield_10Y']:.2f}%")
r2.metric("MOVE (å€ºå¸‚ææ…Œ)", f"{rates['MOVE']:.2f}")
r3.metric("2Y/10Y å€’æŒ‚", f"{rates['Inversion']:.2f}%")
r4.metric("ç¾å…ƒæŒ‡æ•° (DXY)", f"{rates['DXY']:.2f}")
r5.metric("ç¾å…ƒ/æ—¥å…ƒ", f"{rates['USDJPY']:.2f}")

st.divider()

# 3. äº¤æ˜“ä¸å¾®è§‚ç»“æ„
st.subheader("3. äº¤æ˜“ä¸å¾®è§‚ç»“æ„ (Gamma Flip & GEX)")
t1, t2, t3, t4 = st.columns(4)

t1.metric("QQQ æœŸæƒ PCR", f"{opt['PCR']}", "Put/Call Ratio")
t2.metric("VIX è‚¡å¸‚ææ…Œ", f"{vol['VIX']:.2f}")
t3.metric("å¸åœˆææ…ŒæŒ‡æ•°", f"{vol['Crypto_Val']}", f"{vol['Crypto_Text']}")
t4.metric("æœŸè´§åŸºå·® (Basis)", f"{deriv['Futures_Basis']:.2f}", deriv['Basis_Status'])

g1, g2, g3 = st.columns(3)
g1.metric("Gamma Flip Line (è‡ªç®—)", f"${deriv['Flip_Line']:.2f}", deriv['GEX_Net'], delta_color="off")
g2.metric("Put Wall (å¼ºæ”¯æ’‘)", f"${deriv['Put_Wall']}", "æœ€å¤§ç©ºå¤´Gamma")
g3.metric("Call Wall (å¼ºé˜»åŠ›)", f"${deriv['Call_Wall']}", "æœ€å¤§å¤šå¤´Gamma")

with st.expander("ğŸ“š äº¤æ˜“å‘˜å‚è€ƒæ‰‹å†Œï¼šå¦‚ä½•è§£è¯» PCR (OI)ï¼Ÿ", expanded=False):
    st.markdown("""
    #### 1. æ•°å€¼ > 1.2 (é«˜ä½ - æåº¦æ‚²è§‚)
    *   **ç›´è§‚æ„Ÿè§‰**: å¤§å®¶éƒ½çœ‹ç©ºã€‚åšå¸‚å•†æ‰‹é‡Œå…¨æ˜¯ Short Put (Long Delta)ã€‚
    *   **ğŸ›¡ï¸ æ“ä½œ**: åªè¦ QQQ æ²¡å´©ï¼Œæ„å‘³ç€åº•éƒ¨æ”¯æ’‘å¼ºã€‚åå¼¹æ—¶åšå¸‚å•†å¿…é¡»ä¹°å›å¯¹å†²ã€‚**åå‘åšå¤šä¿¡å·ã€‚**
    #### 2. æ•°å€¼ < 0.7 (ä½ä½ - æåº¦è´ªå©ª)
    *   **ç›´è§‚æ„Ÿè§‰**: å¤§å®¶éƒ½çœ‹å¤šã€‚åšå¸‚å•†æ‰‹é‡Œå…¨æ˜¯ Short Call (Short Delta)ã€‚
    *   **âš ï¸ æ“ä½œ**: ä¸Šæ¶¨åƒåŠ› (Call Wall é˜»åŠ›)ã€‚**åå‘åšç©º/æ­¢ç›ˆä¿¡å·ã€‚**
    """)

with st.expander("æŸ¥çœ‹ QQQ å¼‚åŠ¨é›·è¾¾ä¸ Vanna/Charm çŠ¶æ€", expanded=True):
    c_ex1, c_ex2 = st.columns([2, 1])
    with c_ex1:
        st.write("**âš¡ å¼‚åŠ¨é›·è¾¾ (Unusual Volume > OI)**")
        if opt['Unusual']: st.dataframe(pd.DataFrame(opt['Unusual']), use_container_width=True)
        else: st.info("ä»Šæ—¥æ— æ˜¾è‘—å¼‚åŠ¨ã€‚")
    with c_ex2:
        st.write("**Greek Flows (Proxy)**")
        st.info(f"ğŸ”® Vanna/Charm çŠ¶æ€: **{deriv['Vanna_Charm_Proxy']}**")
        st.caption("æ³¨: è‹¥VIXä¸‹è·Œï¼ŒDealerè§£å¥—Callï¼Œå½¢æˆVannaåŠ©æ¶¨ï¼›è‹¥VIXæš´æ¶¨åˆ™åä¹‹ã€‚")

st.divider()

# 4. æ–°é—»
st.subheader("4. å®è§‚æ–°é—»æƒ…æŠ¥ (AI Sentiment)")
col_news_list, col_news_stat = st.columns([3, 1])
with col_news_list:
    if processed_news:
        for item in processed_news:
            css_class = "news-card"
            icon = "âšª"
            if item['Sentiment'] == "Bullish": css_class += " news-bull"; icon = "ğŸŸ¢"
            elif item['Sentiment'] == "Bearish": css_class += " news-bear"; icon = "ğŸ”´"
            st.markdown(f"""<div class="{css_class}"><strong>{icon} {item['Sentiment']}</strong> | <a href="{item['Link']}" target="_blank">{item['Title']}</a><br><span style="font-size:0.8em;color:gray;">{item['Source']}</span></div>""", unsafe_allow_html=True)
    else: st.write("æš‚æ— æœ€æ–°æ–°é—»æ•°æ®ã€‚")
with col_news_stat:
    st.metric("æ–°é—»æƒ…ç»ªåˆ†", f"{avg_news_score:.2f}", "(-1 ç©º ~ 1 å¤š)")

st.divider()

# 5. æ—¥å†
st.subheader(f"5. å®è§‚æ—¥å† ({cal_source})")
c1, c2 = st.columns([3, 1])
with c1:
    if not cal_df.empty:
        st.dataframe(
            cal_df,
            column_config={
                "Date": "æ—¥æœŸ", "Time": "æ—¶é—´", "Event": "äº‹ä»¶",
                "Est": "é¢„æœŸ", "Prev": "å‰å€¼"
            },
            hide_index=True, use_container_width=True
        )
    else: st.write("è¿‘æœŸæ— é‡è¦æ•°æ®ã€‚")

with c2:
    st.markdown("""
    **Fed è§‚å¯Ÿ**:
    - ğŸ¦… **é¹°æ´¾**: Waller
    - ğŸ•Šï¸ **é¸½æ´¾**: Goolsbee
    - âš–ï¸ **ä¸­æ€§**: Powell
    """)
    # ... (ä¸Šé¢æ‰€æœ‰åŸæœ‰ä»£ç ä¿æŒä¸å˜) ...

# --- [æ–°å¢] æ¨¡å— 6: æ—¥å†…æˆ˜æœ¯é¢æ¿ (Intraday Tactical) ---
st.subheader("6. æ—¥å†…äº¤æ˜“æˆ˜æœ¯é¢æ¿ (0DTE & Micro Structure)")

@st.cache_data(ttl=60) # 1åˆ†é’Ÿåˆ·æ–°ï¼Œæ—¥å†…è¦æ±‚é«˜æ—¶æ•ˆ
def get_intraday_tactics():
    res = {
        "VWAP": 0, "Price": 0, "Trend": "Neutral",
        "Exp_Move": 0, "Upper_Band": 0, "Lower_Band": 0,
        "0DTE_Call_Vol": 0, "0DTE_Put_Vol": 0, "0DTE_Sentiment": "Neutral"
    }
    try:
        # 1. è·å– QQQ æ—¥å†… 1åˆ†é’Ÿ æ•°æ®è®¡ç®— VWAP
        # æ³¨æ„: yfinance å…è´¹ç‰ˆæ—¥å†…æ•°æ®å¯èƒ½å»¶è¿Ÿï¼Œå®ç›˜è¯·ä»¥æ­¤ä¸ºå‚è€ƒè¶‹åŠ¿
        df = yf.download("QQQ", period="1d", interval="5m", progress=False)
        if not df.empty:
            # è®¡ç®— VWAP = Cumulative(Price * Vol) / Cumulative(Vol)
            df['TP'] = (df['High'] + df['Low'] + df['Close']) / 3
            df['PV'] = df['TP'] * df['Volume']
            vwap = df['PV'].sum() / df['Volume'].sum()
            
            current_price = df['Close'].iloc[-1]
            res['VWAP'] = vwap
            res['Price'] = current_price
            
            if current_price > vwap * 1.001: res['Trend'] = "ğŸŸ¢ å¤šå¤´æ§ç›˜ (Above VWAP)"
            elif current_price < vwap * 0.999: res['Trend'] = "ğŸ”´ ç©ºå¤´æ§ç›˜ (Below VWAP)"
            else: res['Trend'] = "âšª éœ‡è¡ (At VWAP)"
            
        # 2. è®¡ç®—ä»Šæ—¥é¢„æœŸæ³¢åŠ¨ (Expected Move)
        # ç®€åŒ–å…¬å¼: 0DTE ATM Straddle Price (Call + Put)
        # è¿™é‡Œç”¨ VIX å€’æ¨: Exp Move = Price * (VIX/16) * sqrt(1/252)
        # VIX/16 è¿‘ä¼¼æ—¥æ³¢åŠ¨ç‡
        vix = yf.Ticker("^VIX").history(period="1d")['Close'].iloc[-1]
        daily_vol = (vix / 100) / np.sqrt(252)
        exp_move = res['Price'] * daily_vol
        
        res['Exp_Move'] = exp_move
        res['Upper_Band'] = res['Price'] + exp_move
        res['Lower_Band'] = res['Price'] - exp_move
        
        # 3. 0DTE æƒ…ç»ª (è¿‘ä¼¼)
        qqq = yf.Ticker("QQQ")
        # æ‰¾æœ€è¿‘çš„è¿‡æœŸæ—¥
        today_str = datetime.datetime.now().strftime("%Y-%m-%d")
        dates = qqq.options
        target_date = dates[0] # æœ€è¿‘çš„ä¸€æœŸï¼Œå¯èƒ½æ˜¯ä»Šå¤©æˆ–æ˜å¤©
        
        chain = qqq.option_chain(target_date)
        c_vol = chain.calls['volume'].sum()
        p_vol = chain.puts['volume'].sum()
        
        res['0DTE_Call_Vol'] = c_vol
        res['0DTE_Put_Vol'] = p_vol
        
        if c_vol > p_vol: res['0DTE_Sentiment'] = "ğŸŸ¢ Call ä¸»å¯¼ (è¿½æ¶¨)"
        else: res['0DTE_Sentiment'] = "ğŸ”´ Put ä¸»å¯¼ (æ€è·Œ/é¿é™©)"
        
        res['Expiry_Date'] = target_date

    except Exception as e: pass
    return res

# UI æ¸²æŸ“
with st.spinner("æ­£åœ¨è®¡ç®—æ—¥å†… VWAP ä¸ 0DTE æ•°æ®..."):
    tactics = get_intraday_tactics()

c_day1, c_day2, c_day3, c_day4 = st.columns(4)

# 1. VWAP è¶‹åŠ¿
c_day1.metric("æ—¥å†…è¶‹åŠ¿ (VWAP)", f"${tactics['VWAP']:.2f}", tactics['Trend'], delta_color="off")

# 2. é¢„æœŸæ³¢åŠ¨
c_day2.metric("ä»Šæ—¥é¢„æœŸæ³¢åŠ¨", f"Â±${tactics['Exp_Move']:.2f}", f"VIXæ¨ç®—")

# 3. 0DTE æƒ…ç»ª
c_day3.metric(f"çŸ­æœŸæœŸæƒ ({tactics.get('Expiry_Date','')})", tactics['0DTE_Sentiment'], f"C/P Vol: {int(tactics['0DTE_Call_Vol']/1000)}k / {int(tactics['0DTE_Put_Vol']/1000)}k")

# 4. äº¤æ˜“åŒºé—´
c_day4.metric("ä»Šæ—¥å®‰å…¨è¾¹ç•Œ", f"${tactics['Lower_Band']:.2f} - ${tactics['Upper_Band']:.2f}", "è¶…è·Œ/è¶…ä¹°åŒºåŸŸ")

# äº¤æ˜“å»ºè®®å±•ç¤º
with st.expander("ğŸ¹ æ—¥å†…æœŸæƒç‹™å‡»æŒ‡å— (Intraday Cheat Sheet)", expanded=True):
    st.markdown(f"""
    *   **å½“å‰ä»·æ ¼**: `${tactics['Price']:.2f}` vs **VWAP**: `${tactics['VWAP']:.2f}`
    *   **ç­–ç•¥**:
        *   è‹¥ä»·æ ¼ > VWAP ä¸” Gamma Positive (ğŸŸ¢): **é€¢ä½åšå¤š (Buy Calls on Dips)**.
        *   è‹¥ä»·æ ¼ < VWAP ä¸” Gamma Negative (ğŸ”´): **é€¢é«˜åšç©º (Buy Puts on Rallies)**.
        *   è‹¥ä»·æ ¼è§¦åŠ `${tactics['Upper_Band']:.2f}` (ä¸Šè½¨): è€ƒè™‘ **åå‘åšç©º/æ­¢ç›ˆ (Fade the move)**.
        *   è‹¥ä»·æ ¼è§¦åŠ `${tactics['Lower_Band']:.2f}` (ä¸‹è½¨): è€ƒè™‘ **åå‘åšå¤š/æ­¢ç›ˆ (Buy the dip)**.
    """)
